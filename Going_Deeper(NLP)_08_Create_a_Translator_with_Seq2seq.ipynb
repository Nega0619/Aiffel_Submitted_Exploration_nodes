{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nega0619/Aiffel_Submitted_Exploration_nodes/blob/main/Going_Deeper(NLP)_08_Create_a_Translator_with_Seq2seq.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XdSnXWdjzO0F",
        "outputId": "dc82fb79-ecc1-4c1c-bde3-f50210bdcd11"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_8KhNNSF5uv5",
        "outputId": "8dee4fa7-23e2-49f0-d6c3-8f38b720d06a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/GoingDeeper(NLP)\n"
          ]
        }
      ],
      "source": [
        "cd /content/drive/MyDrive/GoingDeeper(NLP)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "PYeZWhh85u0i",
        "outputId": "6ae0f0b8-46b1-46ea-bea4-2771fbf7f3f5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/GoingDeeper(NLP)'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tFqQ4QA5zUAK"
      },
      "outputs": [],
      "source": [
        "file_path = '/content/drive/MyDrive/GoingDeeper(NLP)'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tZ9gfO07uJRQ"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cn56ObIZuJTj"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "juWXR7Maw0M_"
      },
      "source": [
        "오늘은 seq2seq로 번역기를 만들어 보았습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0hd7Vm1Mv8N6",
        "outputId": "8f9f5d8d-3441-4801-e751-5b1e258fcb86"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "완료!\n"
          ]
        }
      ],
      "source": [
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        " \n",
        "%config InlineBackend.figure_format = 'retina'\n",
        " \n",
        "import matplotlib.font_manager as fm\n",
        "fontpath = '/usr/share/fonts/truetype/nanum/NanumBarunGothic.ttf'\n",
        "font = fm.FontProperties(fname=fontpath, size=9)\n",
        "plt.rc('font', family='NanumBarunGothic') \n",
        "mpl.font_manager.findfont(font)\n",
        "\n",
        "print(\"완료!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CZq2RZ7kuJia"
      },
      "source": [
        "# 1. 데이터 전처리"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-V2jjkSmuJkM",
        "outputId": "f858cee9-4d6a-427a-aa93-39523ea16eb5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.8.0\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import matplotlib.ticker as ticker\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import time\n",
        "import re\n",
        "import os\n",
        "import io\n",
        "\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9W0eo_EjuJnC",
        "outputId": "84fe2247-0020-4880-c5af-4a51b867a279"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip\n",
            "2646016/2638744 [==============================] - 0s 0us/step\n",
            "2654208/2638744 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "path_to_zip = tf.keras.utils.get_file(\n",
        "    'spa-eng.zip',\n",
        "    origin='http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip',\n",
        "    extract=True)\n",
        "\n",
        "path_to_file = os.path.dirname(path_to_zip)+\"/spa-eng/spa.txt\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d6nBGDeguJpX",
        "outputId": "556a0279-8d8b-4c9f-e395-6965479b28a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data Size: 118964\n",
            "Example:\n",
            ">> Go.\tVe.\n",
            ">> Wait.\tEsperen.\n",
            ">> Hug me.\tAbrázame.\n",
            ">> No way!\t¡Ni cagando!\n",
            ">> Call me.\tLlamame.\n"
          ]
        }
      ],
      "source": [
        "with open(path_to_file, \"r\") as f:\n",
        "    raw = f.read().splitlines()\n",
        "\n",
        "print(\"Data Size:\", len(raw))\n",
        "print(\"Example:\")\n",
        "\n",
        "for sen in raw[0:100][::20]: print(\">>\", sen)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FzTY3gAquJrt"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WXr-0gXluJuD"
      },
      "source": [
        "## 데이터 전처리 : 정제하기\n",
        "\n",
        "1. 데이터는 ` \\t`기호를 기준으로 영어와 스페인어가 병렬 쌍을 이루고 있음 -> 해당 기호를 기준으로 split함수를 이용하여 소스문장과 타겟문장을 분리할 예정\n",
        "\n",
        "2. 특수문자는 불필요한 노이즈로 작용할 수 있기 때문에 정제 과정에서 삭제할 예정"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bjvXYpVkuJ0z",
        "outputId": "0ce2a9c2-897e-4b66-fa65-9e0340a1e036"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "슝~\n"
          ]
        }
      ],
      "source": [
        "def preprocess_sentence(sentence, s_token=False, e_token=False):\n",
        "    sentence = sentence.lower().strip()\n",
        "\n",
        "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
        "    sentence = re.sub(r'[\" \"]+', \" \", sentence)\n",
        "    sentence = re.sub(r\"[^a-zA-Z?.!,]+\", \" \", sentence)\n",
        "\n",
        "    sentence = sentence.strip()\n",
        "\n",
        "    if s_token:\n",
        "        sentence = '<start> ' + sentence\n",
        "\n",
        "    if e_token:\n",
        "        sentence += ' <end>'\n",
        "    \n",
        "    return sentence\n",
        "\n",
        "print(\"슝~\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R2bwLiCsuJ3J",
        "outputId": "d5f4c212-720e-42a6-b635-f6ee12db73ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "English: go away !\n",
            "Spanish: <start> salga de aqu ! <end>\n"
          ]
        }
      ],
      "source": [
        "enc_corpus = []\n",
        "dec_corpus = []\n",
        "\n",
        "num_examples = 30000\n",
        "\n",
        "for pair in raw[:num_examples]:\n",
        "    eng, spa = pair.split(\"\\t\")\n",
        "\n",
        "    enc_corpus.append(preprocess_sentence(eng))\n",
        "    dec_corpus.append(preprocess_sentence(spa, s_token=True, e_token=True))\n",
        "\n",
        "print(\"English:\", enc_corpus[100])   # go away !\n",
        "print(\"Spanish:\", dec_corpus[100])   # <start> salga de aqu ! <end>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TAvtpgSAuJ5-"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YTB7H1KhuJ8a"
      },
      "source": [
        "## 데이터 전처리 : 토큰화"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pd7z6aGbuJ_Q"
      },
      "outputs": [],
      "source": [
        "def tokenize(corpus):\n",
        "    tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='')\n",
        "    tokenizer.fit_on_texts(corpus)\n",
        "\n",
        "    tensor = tokenizer.texts_to_sequences(corpus)\n",
        "\n",
        "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='post')\n",
        "\n",
        "    return tensor, tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tBbFTVmXuKBi"
      },
      "outputs": [],
      "source": [
        "enc_tensor, enc_tokenizer = tokenize(enc_corpus)\n",
        "dec_tensor, dec_tokenizer = tokenize(dec_corpus)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rhrHJoxruKD4"
      },
      "outputs": [],
      "source": [
        "enc_train, enc_val, dec_train, dec_val = train_test_split(enc_tensor, dec_tensor, test_size=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HhkMcTDTuKGu"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qy3WJqa2uKJH"
      },
      "source": [
        "# 2. 모델 설계"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YiYcofhjuKLe",
        "outputId": "26818146-2c86-41a1-a5d4-ab275eaac7fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "슝~\n"
          ]
        }
      ],
      "source": [
        "class BahdanauAttention(tf.keras.layers.Layer):\n",
        "    def __init__(self, units):\n",
        "        super(BahdanauAttention, self).__init__()\n",
        "        self.w_dec = tf.keras.layers.Dense(units)\n",
        "        self.w_enc = tf.keras.layers.Dense(units)\n",
        "        self.w_com = tf.keras.layers.Dense(1)\n",
        "    \n",
        "    def call(self, h_enc, h_dec):\n",
        "        # h_enc shape: [batch x length x units]\n",
        "        # h_dec shape: [batch x units]\n",
        "\n",
        "        h_enc = self.w_enc(h_enc)\n",
        "        h_dec = tf.expand_dims(h_dec, 1)\n",
        "        h_dec = self.w_dec(h_dec)\n",
        "\n",
        "        score = self.w_com(tf.nn.tanh(h_dec + h_enc))\n",
        "        \n",
        "        attn = tf.nn.softmax(score, axis=1)\n",
        "\n",
        "        context_vec = attn * h_enc\n",
        "        context_vec = tf.reduce_sum(context_vec, axis=1)\n",
        "\n",
        "        return context_vec, attn\n",
        "\n",
        "print(\"슝~\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mshYXHp8uKNv"
      },
      "outputs": [],
      "source": [
        "class Encoder(tf.keras.Model):\n",
        "    def __init__(self, vocab_size, embedding_dim, enc_units):\n",
        "        super(Encoder, self).__init__()\n",
        "        \n",
        "        self.enc_units = enc_units\n",
        "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "        self.gru = tf.keras.layers.GRU(enc_units,\n",
        "                                       return_sequences=True)\n",
        "        \n",
        "    def call(self, x):\n",
        "        out = self.embedding(x)\n",
        "        out = self.gru(out)\n",
        "        \n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_erwC74suKQg"
      },
      "outputs": [],
      "source": [
        "class Decoder(tf.keras.Model):\n",
        "    def __init__(self, vocab_size, embedding_dim, dec_units):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.dec_units = dec_units\n",
        "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "        self.gru = tf.keras.layers.GRU(dec_units,\n",
        "                                       return_sequences=True,\n",
        "                                       return_state=True)\n",
        "        self.fc = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "        self.attention = BahdanauAttention(self.dec_units)\n",
        "\n",
        "    def call(self, x, h_dec, enc_out):\n",
        "        context_vec, attn = self.attention(enc_out, h_dec)\n",
        "\n",
        "        out = self.embedding(x)\n",
        "        out = tf.concat([tf.expand_dims(context_vec, 1), out], axis=-1)\n",
        "        \n",
        "        out, h_dec = self.gru(out)\n",
        "        out = tf.reshape(out, (-1, out.shape[2]))\n",
        "        out = self.fc(out)\n",
        "\n",
        "        return out, h_dec, attn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sCt1tNy-uKTT",
        "outputId": "6b1605ae-f676-4458-a519-69e209c8437e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoder Output: (64, 30, 1024)\n",
            "Decoder Output: (64, 8894)\n",
            "Decoder Hidden State: (64, 1024)\n",
            "Attention: (64, 30, 1)\n"
          ]
        }
      ],
      "source": [
        "# 코드를 실행하세요.\n",
        "\n",
        "BATCH_SIZE     = 64\n",
        "SRC_VOCAB_SIZE = len(enc_tokenizer.index_word) + 1\n",
        "TGT_VOCAB_SIZE = len(dec_tokenizer.index_word) + 1\n",
        "\n",
        "units         = 1024\n",
        "embedding_dim = 512\n",
        "\n",
        "encoder = Encoder(SRC_VOCAB_SIZE, embedding_dim, units)\n",
        "decoder = Decoder(TGT_VOCAB_SIZE, embedding_dim, units)\n",
        "\n",
        "# sample input\n",
        "sequence_len = 30\n",
        "\n",
        "sample_enc = tf.random.uniform((BATCH_SIZE, sequence_len))\n",
        "sample_output = encoder(sample_enc)\n",
        "\n",
        "print ('Encoder Output:', sample_output.shape)\n",
        "\n",
        "sample_state = tf.random.uniform((BATCH_SIZE, units))\n",
        "\n",
        "sample_logits, h_dec, attn = decoder(tf.random.uniform((BATCH_SIZE, 1)),\n",
        "                                     sample_state, sample_output)\n",
        "\n",
        "print ('Decoder Output:', sample_logits.shape)\n",
        "print ('Decoder Hidden State:', h_dec.shape)\n",
        "print ('Attention:', attn.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ikW04V4uuKXC"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ssuyVKlajGVs"
      },
      "source": [
        "# 3. 훈련하기 \n",
        "\n",
        "## Optimizer & Loss\n",
        "대부분의 Optimizer는 Adam을 사용하지만, 현재는 배울게 많아 그냥 Adam을 가장 많이 쓴다는 것만 알고 넘어가기로 합니다. 하지만 꼭 Adam을 제외한 나머지 Optimizer에 대한 것도 꼭 공부할것입니다.\n",
        "\n",
        "\n",
        "모델에게 `<PAD>`토큰이 패딩을 위한 토큰이라고 명시하지 않으면, 모델은 데이터의 상당부분이 `<PAD>`로 이루어진다고 이해할 것입니다. 예를 들자면 정답이 대체로 `<PAD>`로 이루어져있다고 착각하는 정도?\n",
        "\n",
        "그렇기 때문에 모델에게 `<PAD>`가 유의미한 데이터가 아니라는 것을 알려주기 위해 mask라는 방법을 이용합니다. mask는 정답지에서 `<PAD>`라는 토큰을 발견하여 그부분에 대한 LOSS는 구하지 않게 하는 역할을 합니다. equal()함수에 정확히는 0이 아닌 `<PAD>`토큰 인덱스가 전달되지만 대체로 해당 토큰은 0으로 인덱싱되기 때문에 0을 전달해주었습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1RmxLV6GuKYs",
        "outputId": "886201a6-8acb-436c-9295-70e238663a71"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "슝~\n"
          ]
        }
      ],
      "source": [
        "optimizer = tf.keras.optimizers.Adam()\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True, reduction='none')\n",
        "\n",
        "def loss_function(real, pred):\n",
        "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "    loss = loss_object(real, pred)\n",
        "    \n",
        "    mask = tf.cast(mask, dtype=loss.dtype)\n",
        "    loss *= mask\n",
        "    \n",
        "    return tf.reduce_mean(loss)\n",
        "\n",
        "print(\"슝~\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q4NIcvQYoBay"
      },
      "source": [
        "## train_step 구현하기\n",
        "\n",
        "`@tf.function`데코레이터는 훈련 외적인 텐서플로우 연산을 GPU에서 동작하도록 해주어 훈련을 가속할 수 있도록 도와줍니다. 이 작업은 1Epoch에서 수행되므로 첫번째 Epoch시간이 다른 Epoch시간보다 더 오래걸립니다.\n",
        "\n",
        "`tf.GradientTape()`는 학습하며 발생한 모든 연산을 기록하는 테이프\n",
        "모델이 각 스텝의 최종 단계에서 미분값을 구하는데에 사용됩니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "og2pcE9JqaPk"
      },
      "source": [
        "train_step의 학습과정 : "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xwBPQ4J7qaT5"
      },
      "source": [
        "1. Encoder에 소스 문장을 전달해 컨텍스트 벡터인 enc_out 을 생성\n",
        "2. t=0일 때, Decoder의 Hidden State는 Encoder의 Final State로 정의. h_dec = enc_out[:, -1]\n",
        "3. Decoder에 입력으로 전달할 <start> 토큰 문장 생성\n",
        "4. <start> 문장과 enc_out, Hidden State를 기반으로 다음 단어(t=1)를 예측. pred\n",
        "5. 예측된 단어와 정답 간의 Loss를 구한 후, t=1의 정답 단어를 다음 입력으로 사용 (예측 단어 X)\n",
        "6. 반복!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S8v9-tQ7uKbg",
        "outputId": "80766704-2a35-460f-e936-6ef2a0be8647"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "슝~\n"
          ]
        }
      ],
      "source": [
        "@tf.function\n",
        "def train_step(src, tgt, encoder, decoder, optimizer, dec_tok):\n",
        "    bsz = src.shape[0]\n",
        "    loss = 0\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "        enc_out = encoder(src)\n",
        "        h_dec = enc_out[:, -1]\n",
        "        \n",
        "        dec_src = tf.expand_dims([dec_tok.word_index['<start>']] * bsz, 1)\n",
        "\n",
        "        for t in range(1, tgt.shape[1]):\n",
        "            pred, h_dec, _ = decoder(dec_src, h_dec, enc_out)\n",
        "\n",
        "            loss += loss_function(tgt[:, t], pred)\n",
        "            dec_src = tf.expand_dims(tgt[:, t], 1)\n",
        "        \n",
        "    batch_loss = (loss / int(tgt.shape[1]))\n",
        "\n",
        "    variables = encoder.trainable_variables + decoder.trainable_variables\n",
        "    gradients = tape.gradient(loss, variables)\n",
        "    optimizer.apply_gradients(zip(gradients, variables))\n",
        "    \n",
        "    return batch_loss\n",
        "\n",
        "print(\"슝~\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-zEv6980uKd1"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v0pj87t5yxb2"
      },
      "source": [
        "## 훈련하기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4mfo8DGjuKgO",
        "outputId": "da458111-6734-4ec9-c5d8-c194bbdf1a04"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch  1: 100%|██████████| 375/375 [04:04<00:00,  1.53it/s, Loss 1.3486]\n",
            "Epoch  2: 100%|██████████| 375/375 [03:44<00:00,  1.67it/s, Loss 0.8816]\n",
            "Epoch  3: 100%|██████████| 375/375 [03:41<00:00,  1.70it/s, Loss 0.6186]\n",
            "Epoch  4: 100%|██████████| 375/375 [03:37<00:00,  1.72it/s, Loss 0.4428]\n",
            "Epoch  5: 100%|██████████| 375/375 [03:36<00:00,  1.73it/s, Loss 0.3261]\n",
            "Epoch  6: 100%|██████████| 375/375 [03:35<00:00,  1.74it/s, Loss 0.2542]\n",
            "Epoch  7: 100%|██████████| 375/375 [03:43<00:00,  1.68it/s, Loss 0.2062]\n",
            "Epoch  8: 100%|██████████| 375/375 [03:40<00:00,  1.70it/s, Loss 0.1755]\n",
            "Epoch  9: 100%|██████████| 375/375 [03:36<00:00,  1.74it/s, Loss 0.1529]\n",
            "Epoch 10: 100%|██████████| 375/375 [03:38<00:00,  1.72it/s, Loss 0.1405]\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm    # tqdm\n",
        "import random\n",
        "\n",
        "EPOCHS = 10\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    total_loss = 0\n",
        "    \n",
        "    idx_list = list(range(0, enc_train.shape[0], BATCH_SIZE))\n",
        "    random.shuffle(idx_list)\n",
        "    t = tqdm(idx_list)    # tqdm\n",
        "\n",
        "    for (batch, idx) in enumerate(t):\n",
        "        batch_loss = train_step(enc_train[idx:idx+BATCH_SIZE],\n",
        "                                dec_train[idx:idx+BATCH_SIZE],\n",
        "                                encoder,\n",
        "                                decoder,\n",
        "                                optimizer,\n",
        "                                dec_tokenizer)\n",
        "    \n",
        "        total_loss += batch_loss\n",
        "        \n",
        "        t.set_description_str('Epoch %2d' % (epoch + 1))    # tqdm\n",
        "        t.set_postfix_str('Loss %.4f' % (total_loss.numpy() / (batch + 1)))    # tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rx4TrWIJuKi6"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q-sDiFyK1im6"
      },
      "source": [
        "# 4. 평가하기\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IiNVbd7ruKlP",
        "outputId": "14093313-994d-43cb-ffe8-fb8351e9816c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch  1: 100%|██████████| 375/375 [03:39<00:00,  1.71it/s, Loss 0.1288]\n",
            "Test Epoch  1: 100%|██████████| 94/94 [00:32<00:00,  2.94it/s, Test Loss 0.6887]\n",
            "Epoch  2: 100%|██████████| 375/375 [03:52<00:00,  1.61it/s, Loss 0.1174]\n",
            "Test Epoch  2: 100%|██████████| 94/94 [00:17<00:00,  5.50it/s, Test Loss 0.6932]\n",
            "Epoch  3: 100%|██████████| 375/375 [03:53<00:00,  1.61it/s, Loss 0.1125]\n",
            "Test Epoch  3: 100%|██████████| 94/94 [00:17<00:00,  5.38it/s, Test Loss 0.7044]\n",
            "Epoch  4: 100%|██████████| 375/375 [03:52<00:00,  1.62it/s, Loss 0.1072]\n",
            "Test Epoch  4: 100%|██████████| 94/94 [00:16<00:00,  5.74it/s, Test Loss 0.7061]\n",
            "Epoch  5: 100%|██████████| 375/375 [03:51<00:00,  1.62it/s, Loss 0.1004]\n",
            "Test Epoch  5: 100%|██████████| 94/94 [00:16<00:00,  5.73it/s, Test Loss 0.7259]\n",
            "Epoch  6: 100%|██████████| 375/375 [03:46<00:00,  1.66it/s, Loss 0.0975]\n",
            "Test Epoch  6: 100%|██████████| 94/94 [00:16<00:00,  5.72it/s, Test Loss 0.7227]\n",
            "Epoch  7: 100%|██████████| 375/375 [03:46<00:00,  1.66it/s, Loss 0.0946]\n",
            "Test Epoch  7: 100%|██████████| 94/94 [00:16<00:00,  5.75it/s, Test Loss 0.7498]\n",
            "Epoch  8: 100%|██████████| 375/375 [03:45<00:00,  1.67it/s, Loss 0.0919]\n",
            "Test Epoch  8: 100%|██████████| 94/94 [00:16<00:00,  5.69it/s, Test Loss 0.7439]\n",
            "Epoch  9: 100%|██████████| 375/375 [03:51<00:00,  1.62it/s, Loss 0.0895]\n",
            "Test Epoch  9: 100%|██████████| 94/94 [00:16<00:00,  5.58it/s, Test Loss 0.7485]\n",
            "Epoch 10: 100%|██████████| 375/375 [04:06<00:00,  1.52it/s, Loss 0.0912]\n",
            "Test Epoch 10: 100%|██████████| 94/94 [00:17<00:00,  5.51it/s, Test Loss 0.7448]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Define eval_step\n",
        "\n",
        "@tf.function\n",
        "def eval_step(src, tgt, encoder, decoder, dec_tok):\n",
        "    bsz = src.shape[0]\n",
        "    loss = 0\n",
        "\n",
        "    enc_out = encoder(src)\n",
        "\n",
        "    h_dec = enc_out[:, -1]\n",
        "    \n",
        "    dec_src = tf.expand_dims([dec_tok.word_index['<start>']] * bsz, 1)\n",
        "\n",
        "    for t in range(1, tgt.shape[1]):\n",
        "        pred, h_dec, _ = decoder(dec_src, h_dec, enc_out)\n",
        "\n",
        "        loss += loss_function(tgt[:, t], pred)\n",
        "        dec_src = tf.expand_dims(tgt[:, t], 1)\n",
        "        \n",
        "    batch_loss = (loss / int(tgt.shape[1]))\n",
        "    \n",
        "    return batch_loss\n",
        "\n",
        "\n",
        "# Training Process\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "EPOCHS = 10\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    total_loss = 0\n",
        "    \n",
        "    idx_list = list(range(0, enc_train.shape[0], BATCH_SIZE))\n",
        "    random.shuffle(idx_list)\n",
        "    t = tqdm(idx_list)\n",
        "\n",
        "    for (batch, idx) in enumerate(t):\n",
        "        batch_loss = train_step(enc_train[idx:idx+BATCH_SIZE],\n",
        "                                dec_train[idx:idx+BATCH_SIZE],\n",
        "                                encoder,\n",
        "                                decoder,\n",
        "                                optimizer,\n",
        "                                dec_tokenizer)\n",
        "    \n",
        "        total_loss += batch_loss\n",
        "        \n",
        "        t.set_description_str('Epoch %2d' % (epoch + 1))\n",
        "        t.set_postfix_str('Loss %.4f' % (total_loss.numpy() / (batch + 1)))\n",
        "    \n",
        "    test_loss = 0\n",
        "    \n",
        "    idx_list = list(range(0, enc_val.shape[0], BATCH_SIZE))\n",
        "    random.shuffle(idx_list)\n",
        "    t = tqdm(idx_list)\n",
        "\n",
        "    for (test_batch, idx) in enumerate(t):\n",
        "        test_batch_loss = eval_step(enc_val[idx:idx+BATCH_SIZE],\n",
        "                                    dec_val[idx:idx+BATCH_SIZE],\n",
        "                                    encoder,\n",
        "                                    decoder,\n",
        "                                    dec_tokenizer)\n",
        "    \n",
        "        test_loss += test_batch_loss\n",
        "\n",
        "        t.set_description_str('Test Epoch %2d' % (epoch + 1))\n",
        "        t.set_postfix_str('Test Loss %.4f' % (test_loss.numpy() / (test_batch + 1)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zb7KuqHGuKni",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 683
        },
        "outputId": "21f905bd-f11c-4286-d385-244935304910"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "findfont: Font family ['NanumBarunGothic'] not found. Falling back to DejaVu Sans.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: can i have some coffee ?\n",
            "Predicted translation: puedo tomar un poco de leche ? <end> \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "image/png": {
              "width": 478,
              "height": 611
            },
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "def evaluate(sentence, encoder, decoder):\n",
        "    attention = np.zeros((dec_train.shape[-1], enc_train.shape[-1]))\n",
        "    \n",
        "    sentence = preprocess_sentence(sentence)\n",
        "    inputs = enc_tokenizer.texts_to_sequences([sentence.split()])\n",
        "    inputs = tf.keras.preprocessing.sequence.pad_sequences(inputs,\n",
        "                                                           maxlen=enc_train.shape[-1],\n",
        "                                                           padding='post')\n",
        "\n",
        "    result = ''\n",
        "\n",
        "    enc_out = encoder(inputs)\n",
        "\n",
        "    dec_hidden = enc_out[:, -1]\n",
        "    dec_input = tf.expand_dims([dec_tokenizer.word_index['<start>']], 0)\n",
        "\n",
        "    for t in range(dec_train.shape[-1]):\n",
        "        predictions, dec_hidden, attention_weights = decoder(dec_input,\n",
        "                                                             dec_hidden,\n",
        "                                                             enc_out)\n",
        "\n",
        "        attention_weights = tf.reshape(attention_weights, (-1, ))\n",
        "        attention[t] = attention_weights.numpy()\n",
        "\n",
        "        predicted_id = \\\n",
        "        tf.argmax(tf.math.softmax(predictions, axis=-1)[0]).numpy()\n",
        "\n",
        "        result += dec_tokenizer.index_word[predicted_id] + ' '\n",
        "\n",
        "        if dec_tokenizer.index_word[predicted_id] == '<end>':\n",
        "            return result, sentence, attention\n",
        "\n",
        "        dec_input = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "    return result, sentence, attention\n",
        " \n",
        "\n",
        "def plot_attention(attention, sentence, predicted_sentence):\n",
        "    fig = plt.figure(figsize=(10,10))\n",
        "    ax = fig.add_subplot(1, 1, 1)\n",
        "    ax.matshow(attention, cmap='viridis')\n",
        "\n",
        "    fontdict = {'fontsize': 14}\n",
        "\n",
        "    ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
        "    ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
        "\n",
        "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def translate(sentence, encoder, decoder):\n",
        "    result, sentence, attention = evaluate(sentence, encoder, decoder)\n",
        "\n",
        "    print('Input: %s' % (sentence))\n",
        "    print('Predicted translation: {}'.format(result))\n",
        "    \n",
        "    attention = attention[:len(result.split()), :len(sentence.split())]\n",
        "    plot_attention(attention, sentence.split(), result.split(' '))\n",
        "\n",
        "\n",
        "translate(\"Can I have some coffee?\", encoder, decoder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w8cnRXw1uKqc"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7vTooYSs3DpA"
      },
      "source": [
        " # 5. 한영 프로젝트 만들기\n",
        "\n",
        " 위 프로젝트를 한-영 버전으로 다시 시도해보았습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x7UjdWfOuKsv"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "urf-yOOC3Qcc",
        "outputId": "f7052645-7161-403b-f23b-4feaf007ce1a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "완료!\n"
          ]
        }
      ],
      "source": [
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        " \n",
        "%config InlineBackend.figure_format = 'retina'\n",
        " \n",
        "import matplotlib.font_manager as fm\n",
        "fontpath = '/usr/share/fonts/truetype/nanum/NanumBarunGothic.ttf'\n",
        "font = fm.FontProperties(fname=fontpath, size=9)\n",
        "plt.rc('font', family='NanumBarunGothic') \n",
        "mpl.font_manager.findfont(font)\n",
        "\n",
        "print(\"완료!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZWICKZOJ3Qcd"
      },
      "source": [
        "# 1. 데이터 전처리"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5dpg_0Ix3Qcd",
        "outputId": "8a087339-a0f8-4b8a-de7c-1577ef4c8712"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.8.0\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import matplotlib.ticker as ticker\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import time\n",
        "import re\n",
        "import os\n",
        "import io\n",
        "\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zdPzGUKAuqjZ"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zbxQxcqK3Qce",
        "outputId": "cf7093f9-d119-4f0f-af78-a8506287914a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://raw.githubusercontent.com/jungyeul/korean-parallel-corpora/master/korean-english-news-v1/korean-english-park.train.tar.gz\n",
            "8724480/8718893 [==============================] - 0s 0us/step\n",
            "8732672/8718893 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "path_to_zip = tf.keras.utils.get_file(\n",
        "    'train.zip',\n",
        "    origin='https://raw.githubusercontent.com/jungyeul/korean-parallel-corpora/master/korean-english-news-v1/korean-english-park.train.tar.gz',\n",
        "    extract=True)\n",
        "\n",
        "path_to_file_ko = os.path.dirname(path_to_zip)+\"/korean-english-park.train.ko\"\n",
        "path_to_file_en = os.path.dirname(path_to_zip)+\"/korean-english-park.train.en\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7a892ZfYsqJi",
        "outputId": "57685853-0fc1-4829-f9d9-36d5cd73b9be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data Size: 94123\n",
            "Example:\n",
            ">> 개인용 컴퓨터 사용의 상당 부분은 \"이것보다 뛰어날 수 있느냐?\"\n",
            ">> 북한의 핵무기 계획을 포기하도록 하려는 압력이 거세지고 있는 가운데, 일본과 북한의 외교관들이 외교 관계를 정상화하려는 회담을 재개했다.\n",
            ">> \"경호 로보트가 침입자나 화재를 탐지하기 위해서 개인적으로, 그리고 전문적으로 사용되고 있습니다.\"\n",
            ">> 수자원부 당국은 논란이 되고 있고, 막대한 비용이 드는 이 사업에 대해 내년에 건설을 시작할 계획이다.\n",
            ">> 또한 근력 운동은 활발하게 걷는 것이나 최소한 20분 동안 뛰는 것과 같은 유산소 활동에서 얻는 운동 효과를 심장과 폐에 주지 않기 때문에, 연구학자들은 근력 운동이 심장에 큰 영향을 미치는지 여부에 대해 논쟁을 해왔다.\n"
          ]
        }
      ],
      "source": [
        "with open(path_to_file_ko, \"r\") as f:\n",
        "    raw_ko = f.read().splitlines()\n",
        "\n",
        "print(\"Data Size:\", len(raw_ko))\n",
        "print(\"Example:\")\n",
        "\n",
        "for sen in raw_ko[0:100][::20]: print(\">>\", sen)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "glxTQ_wx3Qce",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b2fb938-1caa-43cd-c6dc-3be8f6d86fb3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data Size: 94123\n",
            "Example:\n",
            ">> Much of personal computing is about \"can you top this?\"\n",
            ">> Amid mounting pressure on North Korea to abandon its nuclear weapons program Japanese and North Korean diplomats have resumed talks on normalizing diplomatic relations.\n",
            ">> “Guard robots are used privately and professionally to detect intruders or fire,” Karlsson said.\n",
            ">> Authorities from the Water Resources Ministry plan to begin construction next year on the controversial and hugely expensive project.\n",
            ">> Researchers also have debated whether weight-training has a big impact on the heart, since it does not give the heart and lungs the kind of workout they get from aerobic activities such as brisk walking or running for at least 20 minutes.\n"
          ]
        }
      ],
      "source": [
        "with open(path_to_file_en, \"r\") as f:\n",
        "    raw_en = f.read().splitlines()\n",
        "\n",
        "print(\"Data Size:\", len(raw_en))\n",
        "print(\"Example:\")\n",
        "\n",
        "for sen in raw_en[0:100][::20]: print(\">>\", sen)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jvwFPGKY3Qce"
      },
      "source": [
        "## 데이터 전처리 : 정제하기\n",
        "\n",
        "1. 데이터는 ` \\t`기호를 기준으로 영어와 스페인어가 병렬 쌍을 이루고 있음 -> 해당 기호를 기준으로 split함수를 이용하여 소스문장과 타겟문장을 분리할 예정\n",
        "\n",
        "2. 특수문자는 불필요한 노이즈로 작용할 수 있기 때문에 정제 과정에서 삭제할 예정"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "py4-QtXW3Qce",
        "outputId": "2c1ee044-34c6-4086-b0fb-3c7138a650b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "슝~\n"
          ]
        }
      ],
      "source": [
        "def preprocess_sentence(sentence, s_token=False, e_token=False):\n",
        "    sentence = sentence.lower().strip()\n",
        "\n",
        "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
        "    sentence = re.sub(r'[\" \"]+', \" \", sentence)\n",
        "    sentence = re.sub(r\"[^a-zA-Z?.!,]+\", \" \", sentence)\n",
        "\n",
        "    sentence = sentence.strip()\n",
        "\n",
        "    if s_token:\n",
        "        sentence = '<start> ' + sentence\n",
        "\n",
        "    if e_token:\n",
        "        sentence += ' <end>'\n",
        "    \n",
        "    return sentence\n",
        "\n",
        "print(\"슝~\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m60DBO3w3Qce",
        "outputId": "d58387cd-1187-48b0-e383-14ed2dec3bde"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "korean data size: 92064\n",
            "english data size: 92064\n",
            "Korean: ?\n",
            "English: <start> much of personal computing is about can you top this ? <end>\n"
          ]
        }
      ],
      "source": [
        "enc_corpus = []\n",
        "dec_corpus = []\n",
        "\n",
        "for ko, en in zip(raw_ko, raw_en):\n",
        "    temp_ko = preprocess_sentence(ko)\n",
        "    temp_en = preprocess_sentence(en, s_token=True, e_token=True)\n",
        "\n",
        "    if len(temp_ko) <= 40:\n",
        "        enc_corpus.append(temp_ko)\n",
        "        dec_corpus.append(temp_en)\n",
        "    \n",
        "print('korean data size:', len(enc_corpus))\n",
        "print('english data size:', len(dec_corpus))\n",
        "print(\"Korean:\", enc_corpus[0])   \n",
        "print(\"English:\", dec_corpus[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8-kXjLfY3Qce"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qszr1iIS3Qcf"
      },
      "source": [
        "## 데이터 전처리 : 토큰화"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6FH6gys93Qcf"
      },
      "outputs": [],
      "source": [
        "def tokenize(corpus):\n",
        "    tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='')\n",
        "    tokenizer.fit_on_texts(corpus)\n",
        "\n",
        "    tensor = tokenizer.texts_to_sequences(corpus)\n",
        "\n",
        "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='post')\n",
        "\n",
        "    return tensor, tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PgREyiKA3Qcf"
      },
      "outputs": [],
      "source": [
        "enc_tensor, enc_tokenizer = tokenize(enc_corpus)\n",
        "dec_tensor, dec_tokenizer = tokenize(dec_corpus)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fDez1a-X3Qcf"
      },
      "outputs": [],
      "source": [
        "enc_train, enc_val, dec_train, dec_val = train_test_split(enc_tensor, dec_tensor, test_size=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nTT1IVAh3Qcf"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VpEZPAhs3Qcf"
      },
      "source": [
        "# 2. 모델 설계"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TNF2vJ1E3Qcg",
        "outputId": "b2ae363f-7773-45de-8c74-c3519277a53e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "슝~\n"
          ]
        }
      ],
      "source": [
        "class BahdanauAttention(tf.keras.layers.Layer):\n",
        "    def __init__(self, units):\n",
        "        super(BahdanauAttention, self).__init__()\n",
        "        self.w_dec = tf.keras.layers.Dense(units)\n",
        "        self.w_enc = tf.keras.layers.Dense(units)\n",
        "        self.w_com = tf.keras.layers.Dense(1)\n",
        "    \n",
        "    def call(self, h_enc, h_dec):\n",
        "        # h_enc shape: [batch x length x units]\n",
        "        # h_dec shape: [batch x units]\n",
        "\n",
        "        h_enc = self.w_enc(h_enc)\n",
        "        h_dec = tf.expand_dims(h_dec, 1)\n",
        "        h_dec = self.w_dec(h_dec)\n",
        "\n",
        "        score = self.w_com(tf.nn.tanh(h_dec + h_enc))\n",
        "        \n",
        "        attn = tf.nn.softmax(score, axis=1)\n",
        "\n",
        "        context_vec = attn * h_enc\n",
        "        context_vec = tf.reduce_sum(context_vec, axis=1)\n",
        "\n",
        "        return context_vec, attn\n",
        "\n",
        "print(\"슝~\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FiM-Mtuo3Qcg"
      },
      "outputs": [],
      "source": [
        "class Encoder(tf.keras.Model):\n",
        "    def __init__(self, vocab_size, embedding_dim, enc_units):\n",
        "        super(Encoder, self).__init__()\n",
        "        \n",
        "        self.enc_units = enc_units\n",
        "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "        self.gru = tf.keras.layers.GRU(enc_units,\n",
        "                                       return_sequences=True)\n",
        "        \n",
        "    def call(self, x):\n",
        "        out = self.embedding(x)\n",
        "        out = self.gru(out)\n",
        "        \n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4bjomxv23Qcg"
      },
      "outputs": [],
      "source": [
        "class Decoder(tf.keras.Model):\n",
        "    def __init__(self, vocab_size, embedding_dim, dec_units):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.dec_units = dec_units\n",
        "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "        self.gru = tf.keras.layers.GRU(dec_units,\n",
        "                                       return_sequences=True,\n",
        "                                       return_state=True)\n",
        "        self.fc = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "        self.attention = BahdanauAttention(self.dec_units)\n",
        "\n",
        "    def call(self, x, h_dec, enc_out):\n",
        "        context_vec, attn = self.attention(enc_out, h_dec)\n",
        "\n",
        "        out = self.embedding(x)\n",
        "        out = tf.concat([tf.expand_dims(context_vec, 1), out], axis=-1)\n",
        "        \n",
        "        out, h_dec = self.gru(out)\n",
        "        out = tf.reshape(out, (-1, out.shape[2]))\n",
        "        out = self.fc(out)\n",
        "\n",
        "        return out, h_dec, attn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sF_0irkB3Qch",
        "outputId": "4e18b0ba-503f-4ae6-9884-2ba62be8d77a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoder Output: (64, 30, 1024)\n",
            "Decoder Output: (64, 44289)\n",
            "Decoder Hidden State: (64, 1024)\n",
            "Attention: (64, 30, 1)\n"
          ]
        }
      ],
      "source": [
        "# 코드를 실행하세요.\n",
        "\n",
        "BATCH_SIZE     = 64\n",
        "SRC_VOCAB_SIZE = len(enc_tokenizer.index_word) + 1\n",
        "TGT_VOCAB_SIZE = len(dec_tokenizer.index_word) + 1\n",
        "\n",
        "units         = 1024\n",
        "embedding_dim = 512\n",
        "\n",
        "encoder = Encoder(SRC_VOCAB_SIZE, embedding_dim, units)\n",
        "decoder = Decoder(TGT_VOCAB_SIZE, embedding_dim, units)\n",
        "\n",
        "# sample input\n",
        "sequence_len = 30\n",
        "\n",
        "sample_enc = tf.random.uniform((BATCH_SIZE, sequence_len))\n",
        "sample_output = encoder(sample_enc)\n",
        "\n",
        "print ('Encoder Output:', sample_output.shape)\n",
        "\n",
        "sample_state = tf.random.uniform((BATCH_SIZE, units))\n",
        "\n",
        "sample_logits, h_dec, attn = decoder(tf.random.uniform((BATCH_SIZE, 1)),\n",
        "                                     sample_state, sample_output)\n",
        "\n",
        "print ('Decoder Output:', sample_logits.shape)\n",
        "print ('Decoder Hidden State:', h_dec.shape)\n",
        "print ('Attention:', attn.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0R0VskLS3Qch"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GaB5WPj-3Qch"
      },
      "source": [
        "# 3. 훈련하기 \n",
        "\n",
        "## Optimizer & Loss\n",
        "대부분의 Optimizer는 Adam을 사용하지만, 현재는 배울게 많아 그냥 Adam을 가장 많이 쓴다는 것만 알고 넘어가기로 합니다. 하지만 꼭 Adam을 제외한 나머지 Optimizer에 대한 것도 꼭 공부할것입니다.\n",
        "\n",
        "\n",
        "모델에게 `<PAD>`토큰이 패딩을 위한 토큰이라고 명시하지 않으면, 모델은 데이터의 상당부분이 `<PAD>`로 이루어진다고 이해할 것입니다. 예를 들자면 정답이 대체로 `<PAD>`로 이루어져있다고 착각하는 정도?\n",
        "\n",
        "그렇기 때문에 모델에게 `<PAD>`가 유의미한 데이터가 아니라는 것을 알려주기 위해 mask라는 방법을 이용합니다. mask는 정답지에서 `<PAD>`라는 토큰을 발견하여 그부분에 대한 LOSS는 구하지 않게 하는 역할을 합니다. equal()함수에 정확히는 0이 아닌 `<PAD>`토큰 인덱스가 전달되지만 대체로 해당 토큰은 0으로 인덱싱되기 때문에 0을 전달해주었습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RqZ900fv3Qch"
      },
      "outputs": [],
      "source": [
        "optimizer = tf.keras.optimizers.Adam()\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True, reduction='none')\n",
        "\n",
        "def loss_function(real, pred):\n",
        "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "    loss = loss_object(real, pred)\n",
        "    \n",
        "    mask = tf.cast(mask, dtype=loss.dtype)\n",
        "    loss *= mask\n",
        "    \n",
        "    return tf.reduce_mean(loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jiu_sMnx3Qci"
      },
      "source": [
        "## train_step 구현하기\n",
        "\n",
        "`@tf.function`데코레이터는 훈련 외적인 텐서플로우 연산을 GPU에서 동작하도록 해주어 훈련을 가속할 수 있도록 도와줍니다. 이 작업은 1Epoch에서 수행되므로 첫번째 Epoch시간이 다른 Epoch시간보다 더 오래걸립니다.\n",
        "\n",
        "`tf.GradientTape()`는 학습하며 발생한 모든 연산을 기록하는 테이프\n",
        "모델이 각 스텝의 최종 단계에서 미분값을 구하는데에 사용됩니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z3q670f23Qci"
      },
      "source": [
        "train_step의 학습과정 : "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LhVosvwi3Qci"
      },
      "source": [
        "1. Encoder에 소스 문장을 전달해 컨텍스트 벡터인 enc_out 을 생성\n",
        "2. t=0일 때, Decoder의 Hidden State는 Encoder의 Final State로 정의. h_dec = enc_out[:, -1]\n",
        "3. Decoder에 입력으로 전달할 <start> 토큰 문장 생성\n",
        "4. <start> 문장과 enc_out, Hidden State를 기반으로 다음 단어(t=1)를 예측. pred\n",
        "5. 예측된 단어와 정답 간의 Loss를 구한 후, t=1의 정답 단어를 다음 입력으로 사용 (예측 단어 X)\n",
        "6. 반복!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A09Uxa3h3Qci"
      },
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def train_step(src, tgt, encoder, decoder, optimizer, dec_tok):\n",
        "    bsz = src.shape[0]\n",
        "    loss = 0\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "        enc_out = encoder(src)\n",
        "        h_dec = enc_out[:, -1]\n",
        "        \n",
        "        dec_src = tf.expand_dims([dec_tok.word_index['<start>']] * bsz, 1)\n",
        "\n",
        "        for t in range(1, tgt.shape[1]):\n",
        "            pred, h_dec, _ = decoder(dec_src, h_dec, enc_out)\n",
        "\n",
        "            loss += loss_function(tgt[:, t], pred)\n",
        "            dec_src = tf.expand_dims(tgt[:, t], 1)\n",
        "        \n",
        "    batch_loss = (loss / int(tgt.shape[1]))\n",
        "\n",
        "    variables = encoder.trainable_variables + decoder.trainable_variables\n",
        "    gradients = tape.gradient(loss, variables)\n",
        "    optimizer.apply_gradients(zip(gradients, variables))\n",
        "    \n",
        "    return batch_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ISvrttj13Qci"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ujUwBa8-3Qci"
      },
      "source": [
        "## 훈련하기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7UFV1nUJ3Qci",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8b8e543-9b7b-4838-c8d2-8b8ce55fb628"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch  1: 100%|██████████| 1151/1151 [2:43:01<00:00,  8.50s/it, Loss 1.7935]\n",
            "Epoch  2:  29%|██▉       | 335/1151 [47:26<1:49:32,  8.06s/it, Loss 1.7913]"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm  # tqdm\n",
        "import random\n",
        "\n",
        "EPOCHS = 10\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    total_loss = 0\n",
        "    \n",
        "    idx_list = list(range(0, enc_train.shape[0], BATCH_SIZE))\n",
        "    random.shuffle(idx_list)\n",
        "    t = tqdm(idx_list)  # tqdm\n",
        "\n",
        "    for (batch, idx) in enumerate(t):\n",
        "        batch_loss = train_step(enc_train[idx:idx+BATCH_SIZE],\n",
        "                                dec_train[idx:idx+BATCH_SIZE],\n",
        "                                encoder,\n",
        "                                decoder,\n",
        "                                optimizer,\n",
        "                                dec_tokenizer)\n",
        "    \n",
        "        total_loss += batch_loss\n",
        "        \n",
        "        t.set_description_str('Epoch %2d' % (epoch + 1))  # tqdm\n",
        "        t.set_postfix_str('Loss %.4f' % (total_loss.numpy() / (batch + 1)))  # tqdm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "CJNg48Wbaja4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lBdKSfLU3Qcj"
      },
      "source": [
        "# 4. 평가하기\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "JNx_Rbg5YCSe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vNBmKhPk3Qcj"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Define eval_step\n",
        "\n",
        "@tf.function\n",
        "def eval_step(src, tgt, encoder, decoder, dec_tok):\n",
        "    bsz = src.shape[0]\n",
        "    loss = 0\n",
        "\n",
        "    enc_out = encoder(src)\n",
        "\n",
        "    h_dec = enc_out[:, -1]\n",
        "    \n",
        "    dec_src = tf.expand_dims([dec_tok.word_index['<start>']] * bsz, 1)\n",
        "\n",
        "    for t in range(1, tgt.shape[1]):\n",
        "        pred, h_dec, _ = decoder(dec_src, h_dec, enc_out)\n",
        "\n",
        "        loss += loss_function(tgt[:, t], pred)\n",
        "        dec_src = tf.expand_dims(tgt[:, t], 1)\n",
        "        \n",
        "    batch_loss = (loss / int(tgt.shape[1]))\n",
        "    \n",
        "    return batch_loss\n",
        "\n",
        "\n",
        "# Training Process\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "EPOCHS = 10\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    total_loss = 0\n",
        "    \n",
        "    idx_list = list(range(0, enc_train.shape[0], BATCH_SIZE))\n",
        "    random.shuffle(idx_list)\n",
        "    t = tqdm(idx_list)\n",
        "\n",
        "    for (batch, idx) in enumerate(t):\n",
        "        batch_loss = train_step(enc_train[idx:idx+BATCH_SIZE],\n",
        "                                dec_train[idx:idx+BATCH_SIZE],\n",
        "                                encoder,\n",
        "                                decoder,\n",
        "                                optimizer,\n",
        "                                dec_tokenizer)\n",
        "    \n",
        "        total_loss += batch_loss\n",
        "        \n",
        "        t.set_description_str('Epoch %2d' % (epoch + 1))\n",
        "        t.set_postfix_str('Loss %.4f' % (total_loss.numpy() / (batch + 1)))\n",
        "    \n",
        "    test_loss = 0\n",
        "    \n",
        "    idx_list = list(range(0, enc_val.shape[0], BATCH_SIZE))\n",
        "    random.shuffle(idx_list)\n",
        "    t = tqdm(idx_list)\n",
        "\n",
        "    for (test_batch, idx) in enumerate(t):\n",
        "        test_batch_loss = eval_step(enc_val[idx:idx+BATCH_SIZE],\n",
        "                                    dec_val[idx:idx+BATCH_SIZE],\n",
        "                                    encoder,\n",
        "                                    decoder,\n",
        "                                    dec_tokenizer)\n",
        "    \n",
        "        test_loss += test_batch_loss\n",
        "\n",
        "        t.set_description_str('Test Epoch %2d' % (epoch + 1))\n",
        "        t.set_postfix_str('Test Loss %.4f' % (test_loss.numpy() / (test_batch + 1)))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "0KZqRffTYOfo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Tg-cRbmhYQ7-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "brxxZyXlYTYL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "iKUg2CLmYMDd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "_Re_Ti8wYHK5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L0bsl6hf3Qcj"
      },
      "outputs": [],
      "source": [
        "def evaluate(sentence, encoder, decoder):\n",
        "    attention = np.zeros((dec_train.shape[-1], enc_train.shape[-1]))\n",
        "    \n",
        "    sentence = preprocess_sentence(sentence)\n",
        "    inputs = enc_tokenizer.texts_to_sequences([sentence.split()])\n",
        "    inputs = tf.keras.preprocessing.sequence.pad_sequences(inputs,\n",
        "                                                           maxlen=enc_train.shape[-1],\n",
        "                                                           padding='post')\n",
        "\n",
        "    result = ''\n",
        "\n",
        "    enc_out = encoder(inputs)\n",
        "\n",
        "    dec_hidden = enc_out[:, -1]\n",
        "    dec_input = tf.expand_dims([dec_tokenizer.word_index['<start>']], 0)\n",
        "\n",
        "    for t in range(dec_train.shape[-1]):\n",
        "        predictions, dec_hidden, attention_weights = decoder(dec_input,\n",
        "                                                             dec_hidden,\n",
        "                                                             enc_out)\n",
        "\n",
        "        attention_weights = tf.reshape(attention_weights, (-1, ))\n",
        "        attention[t] = attention_weights.numpy()\n",
        "\n",
        "        predicted_id = \\\n",
        "        tf.argmax(tf.math.softmax(predictions, axis=-1)[0]).numpy()\n",
        "\n",
        "        result += dec_tokenizer.index_word[predicted_id] + ' '\n",
        "\n",
        "        if dec_tokenizer.index_word[predicted_id] == '<end>':\n",
        "            return result, sentence, attention\n",
        "\n",
        "        dec_input = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "    return result, sentence, attention\n",
        "\n",
        "\n",
        "def plot_attention(attention, sentence, predicted_sentence):\n",
        "    fig = plt.figure(figsize=(10,10))\n",
        "    ax = fig.add_subplot(1, 1, 1)\n",
        "    ax.matshow(attention, cmap='viridis')\n",
        "\n",
        "    fontdict = {'fontsize': 14}\n",
        "\n",
        "    ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
        "    ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
        "\n",
        "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def translate(sentence, encoder, decoder):\n",
        "    result, sentence, attention = evaluate(sentence, encoder, decoder)\n",
        "\n",
        "    print('Input: %s' % (sentence))\n",
        "    print('Predicted translation: {}'.format(result))\n",
        "    \n",
        "    attention = attention[:len(result.split()), :len(sentence.split())]\n",
        "    plot_attention(attention, sentence.split(), result.split(' '))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qhK-emzfuKvS"
      },
      "outputs": [],
      "source": [
        "!sudo apt-get install -y fonts-nanum\n",
        "!sudo fc-cache -fv\n",
        "!rm ~/.cache/matplotlib -rf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        " \n",
        "%config InlineBackend.figure_format = 'retina'\n",
        " \n",
        "import matplotlib.font_manager as fm\n",
        "fontpath = '/usr/share/fonts/truetype/nanum/NanumBarunGothic.ttf'\n",
        "font = fm.FontProperties(fname=fontpath, size=9)\n",
        "plt.rc('font', family='NanumBarunGothic') \n",
        "mpl.font_manager.findfont(font)"
      ],
      "metadata": {
        "id": "68ZWfY527drl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "translate(\"헬로우 시드니?\", encoder, decoder)"
      ],
      "metadata": {
        "id": "WmHafwa97do8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "translate(\"김광호씨는 젤다의 전설 처돌이다.\", encoder, decoder)"
      ],
      "metadata": {
        "id": "ROvpfSJG7dk2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "translate(\"언제 젤다의 전설 뺏어오지.\", encoder, decoder)"
      ],
      "metadata": {
        "id": "C7fEQ55-7dhJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "translate(\"언젠가 돌려받으면 나도 라이넬 잡을래...\", encoder, decoder)"
      ],
      "metadata": {
        "id": "oHx9gLLz8ZWS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "XK7e-TOBYV0b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "sYKzGeOiYYQ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "0kfjNiCfiHJw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "heW2UxXpo-mt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "1tzzTpHTv2D9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "lwOCAzjhYa4C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "dW94AUBWZXvZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "fjAM799VZaLp"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "Going Deeper(NLP) 08. Create a Translator with Seq2seq",
      "provenance": [],
      "mount_file_id": "1FJRKoPW8ifyFM30AF1QrzWn7LxEpnl6h",
      "authorship_tag": "ABX9TyOOaLxpAaNL4rAYaNSQUT+L",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}