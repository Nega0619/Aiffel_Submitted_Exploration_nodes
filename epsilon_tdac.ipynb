{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "epsilon_tdac",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMAkA3DSXYXfcvztNb+JGmJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nega0619/Aiffel_Submitted_Exploration_nodes/blob/main/epsilon_tdac.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eA8EpS-A7skG",
        "outputId": "6c73f006-f416-4a76-bdef-3157170da37d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/drive/MyDrive/agileSoda/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Epf-frN08f3r",
        "outputId": "0e4e2d71-63b7-4f44-8991-6cdb660ec7b0"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/agileSoda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ! pip install -r requirements.txt"
      ],
      "metadata": {
        "id": "Pj0ND3L88jMB"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sim.py\n",
        "from string import ascii_uppercase\n",
        "# from draw_utils import *\n",
        "# from pyglet.gl import *\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "\n",
        "# reward\n",
        "move_reward = -1\n",
        "obs_reward = -100\n",
        "goal_reward = 1000\n",
        "print('reward:' , move_reward, obs_reward, goal_reward)\n",
        "\n",
        "__file__ = '/content/drive/MyDrive/agileSoda/'\n",
        "local_path = os.path.abspath(os.path.join(os.path.dirname(__file__)))\n",
        "\n",
        "\n",
        "class Simulator:\n",
        "    def __init__(self):\n",
        "        '''\n",
        "        height : 그리드 높이\n",
        "        width : 그리드 너비 \n",
        "        inds : A ~ Q alphabet list\n",
        "        '''\n",
        "        # Load train data\n",
        "        self.files = pd.read_csv(os.path.join(local_path, \"./data/factory_order_train.csv\"))\n",
        "        self.height = 10\n",
        "        self.width = 9\n",
        "        self.inds = list(ascii_uppercase)[:17]\n",
        "\n",
        "    def set_box(self):\n",
        "        '''\n",
        "        아이템들이 있을 위치를 미리 정해놓고 그 위치 좌표들에 아이템이 들어올 수 있으므로 그리드에 100으로 표시한다.\n",
        "        데이터 파일에서 이번 에피소드 아이템 정보를 받아 가져와야 할 아이템이 있는 좌표만 -100으로 표시한다.\n",
        "        self.local_target에 에이전트가 이번에 방문해야할 좌표들을 저장한다.\n",
        "        따라서 가져와야하는 아이템 좌표와 end point 좌표(처음 시작했던 좌표로 돌아와야하므로)가 들어가게 된다.\n",
        "        '''\n",
        "        box_data = pd.read_csv(os.path.join(local_path, \"./data/box.csv\"))\n",
        "\n",
        "        # 물건이 들어있을 수 있는 경우\n",
        "        for box in box_data.itertuples(index = True, name ='Pandas'):\n",
        "            self.grid[getattr(box, \"row\")][getattr(box, \"col\")] = 100\n",
        "\n",
        "        # 물건이 실제 들어있는 경우\n",
        "        order_item = list(set(self.inds) & set(self.items))\n",
        "        order_csv = box_data[box_data['item'].isin(order_item)]\n",
        "\n",
        "        for order_box in order_csv.itertuples(index = True, name ='Pandas'):\n",
        "            self.grid[getattr(order_box, \"row\")][getattr(order_box, \"col\")] = -100\n",
        "            # local target에 가야 할 위치 좌표 넣기\n",
        "            self.local_target.append(\n",
        "                [getattr(order_box, \"row\"),\n",
        "                 getattr(order_box, \"col\")]\n",
        "                )\n",
        "\n",
        "        # self.local_target.sort()\n",
        "        self.local_target.append([9,4])\n",
        "        # print(self.local_target)\n",
        "\n",
        "        # 알파벳을 Grid에 넣어서 -> grid에 2Dconv 적용 가능\n",
        "\n",
        "    def set_obstacle(self):\n",
        "        '''\n",
        "        장애물이 있어야하는 위치는 미리 obstacles.csv에 정의되어 있다. 이 좌표들을 0으로 표시한다.\n",
        "        '''\n",
        "        obstacles_data = pd.read_csv(os.path.join(local_path, \"./data/obstacles.csv\"))\n",
        "        for obstacle in obstacles_data.itertuples(index = True, name ='Pandas'):\n",
        "            self.grid[getattr(obstacle, \"row\")][getattr(obstacle, \"col\")] = 0\n",
        "\n",
        "    def reset(self, epi):\n",
        "        '''\n",
        "        reset()은 첫 스텝에서 사용되며 그리드에서 에이전트 위치가 start point에 있게 한다.\n",
        "\n",
        "        :param epi: episode, 에피소드 마다 가져와야 할 아이템 리스트를 불러올 때 사용\n",
        "        :return: 초기셋팅 된 그리드\n",
        "        :rtype: numpy.ndarray\n",
        "        _____________________________________________________________________________________\n",
        "        items : 이번 에피소드에서 가져와야하는 아이템들\n",
        "        terminal_location : 현재 에이전트가 찾아가야하는 목적지\n",
        "        local_target : 한 에피소드에서 찾아가야하는 아이템 좌표, 마지막 엔드 포인트 등의 위치좌표들\n",
        "        actions: visualization을 위해 에이전트 action을 저장하는 리스트\n",
        "        curloc : 현재 위치\n",
        "        '''\n",
        "\n",
        "        # initial episode parameter setting\n",
        "        self.epi = epi\n",
        "        self.items = list(self.files.iloc[self.epi])[0]\n",
        "        self.cumulative_reward = 0\n",
        "        self.terminal_location = None\n",
        "        self.local_target = []\n",
        "        self.actions = []\n",
        "\n",
        "        # initial grid setting\n",
        "        self.grid = np.ones((self.height, self.width), dtype=\"float16\")\n",
        "\n",
        "        # set information about the gridworld\n",
        "        self.set_box()\n",
        "        self.set_obstacle()\n",
        "\n",
        "        # start point를 grid에 표시\n",
        "        self.curloc = [9, 4]\n",
        "        self.grid[int(self.curloc[0])][int(self.curloc[1])] = -5\n",
        "        \n",
        "        self.done = False\n",
        "        \n",
        "        return self.local_target\n",
        "\n",
        "    def apply_action(self, action, cur_x, cur_y):\n",
        "        '''\n",
        "        에이전트가 행한 action대로 현 에이전트의 위치좌표를 바꾼다.\n",
        "        action은 discrete하며 4가지 up,down,left,right으로 정의된다.\n",
        "        \n",
        "        :param x: 에이전트의 현재 x 좌표\n",
        "        :param y: 에이전트의 현재 y 좌표\n",
        "        :return: action에 따라 변한 에이전트의 x 좌표, y 좌표\n",
        "        :rtype: int, int\n",
        "        '''\n",
        "        new_x = cur_x\n",
        "        new_y = cur_y\n",
        "        # up\n",
        "        if action == 0:\n",
        "            new_x = cur_x - 1\n",
        "            # print('위위 0: x-1')\n",
        "        # down\n",
        "        elif action == 1:\n",
        "            new_x = cur_x + 1\n",
        "            # print('아래 1 : x+1')\n",
        "        # left\n",
        "        elif action == 2:\n",
        "            new_y = cur_y - 1\n",
        "            # print('왼쪽 2 : y-1')\n",
        "        # right\n",
        "        elif action == 3:\n",
        "            new_y = cur_y + 1\n",
        "            # print('오른 3 : y+1')\n",
        "        else :\n",
        "            print('그런 행동은 없다.')\n",
        "\n",
        "\n",
        "        return int(new_x), int(new_y)\n",
        "\n",
        "\n",
        "    def get_reward(self, new_x, new_y, out_of_boundary):\n",
        "        '''\n",
        "        get_reward함수는 리워드를 계산하는 함수이며, 상황에 따라 에이전트가 action을 옳게 했는지 판단하는 지표가 된다.\n",
        "\n",
        "        :param new_x: action에 따른 에이전트 새로운 위치좌표 x\n",
        "        :param new_y: action에 따른 에이전트 새로운 위치좌표 y\n",
        "        :param out_of_boundary: 에이전트 위치가 그리드 밖이 되지 않도록 제한\n",
        "        :return: action에 따른 리워드\n",
        "        :rtype: float\n",
        "        '''\n",
        "\n",
        "        # 바깥으로 나가는 경우\n",
        "        if any(out_of_boundary):\n",
        "            reward = obs_reward\n",
        "        else:\n",
        "            # 장애물에 부딪히는 경우 \n",
        "            if self.grid[new_x][new_y] == 0:\n",
        "                reward = obs_reward  \n",
        "\n",
        "            # 현재 목표에 도달한 경우\n",
        "            elif new_x == self.terminal_location[0] and new_y == self.terminal_location[1]:\n",
        "                reward = goal_reward\n",
        "\n",
        "            # 그냥 움직이는 경우 \n",
        "            else:\n",
        "                reward = move_reward\n",
        "\n",
        "        return reward\n",
        "\n",
        "    def step(self, action):\n",
        "        ''' \n",
        "        에이전트의 action에 따라 step을 진행한다.\n",
        "        action에 따라 에이전트 위치를 변환하고, action에 대해 리워드를 받고, 어느 상황에 에피소드가 종료되어야 하는지 등을 판단한다.\n",
        "        에이전트가 endpoint에 도착하면 gif로 에피소드에서 에이전트의 행동이 저장된다.\n",
        "\n",
        "        :param action: 에이전트 행동\n",
        "        :return:\n",
        "            grid, 그리드\n",
        "            reward, 리워드\n",
        "            cumulative_reward, 누적 리워드\n",
        "            done, 종료 여부\n",
        "            goal_ob_reward, goal까지 아이템을 모두 가지고 돌아오는 finish율 계산을 위한 파라미터\n",
        "\n",
        "        :rtype: numpy.ndarray, float, float, bool, bool/str\n",
        "\n",
        "        (Hint : 시작 위치 (9,4)에서 up말고 다른 action은 전부 장애물이므로 action을 고정하는 것이 좋음)\n",
        "        '''\n",
        "\n",
        "        self.terminal_location = self.local_target[0]\n",
        "        cur_x,cur_y = self.curloc\n",
        "        self.actions.append((cur_x, cur_y))\n",
        "\n",
        "        goal_ob_reward = False\n",
        "        \n",
        "        new_x, new_y = self.apply_action(action, cur_x, cur_y)\n",
        "\n",
        "        out_of_boundary = [new_x < 0, new_x >= self.height, new_y < 0, new_y >= self.width]\n",
        "\n",
        "        # 바깥으로 나가는 경우 종료\n",
        "        if any(out_of_boundary):\n",
        "            self.done = True\n",
        "            goal_ob_reward = False\n",
        "            self.curloc = [new_x, new_y]\n",
        "        else:\n",
        "            # 장애물에 부딪히는 경우 종료\n",
        "            if self.grid[new_x][new_y] == 0:\n",
        "                self.done = True\n",
        "                goal_ob_reward = False\n",
        "                self.curloc = [new_x, new_y]\n",
        "\n",
        "            # 현재 목표에 도달한 경우, 다음 목표설정\n",
        "            elif new_x == self.terminal_location[0] and new_y == self.terminal_location[1]:\n",
        "\n",
        "                # end point 일 때\n",
        "                if [new_x, new_y] == [9,4]:\n",
        "                    self.done = False\n",
        "\n",
        "                self.local_target.remove(self.local_target[0])\n",
        "                self.grid[cur_x][cur_y] = 1\n",
        "                self.grid[new_x][new_y] = -5\n",
        "                goal_ob_reward = True\n",
        "                self.curloc = [new_x, new_y]\n",
        "            else:\n",
        "                # 그냥 움직이는 경우 \n",
        "                self.grid[cur_x][cur_y] = 1\n",
        "                self.grid[new_x][new_y] = -5\n",
        "                self.curloc = [new_x,new_y]\n",
        "                \n",
        "        reward = self.get_reward(new_x, new_y, out_of_boundary)\n",
        "        self.cumulative_reward += reward\n",
        "\n",
        "#         print('현재는 gif가 만들어지지 않습니다.')\n",
        "        # if self.done == True:\n",
        "        #     if [new_x, new_y] == [9, 4]:\n",
        "        #         if self.terminal_location == [9, 4]:\n",
        "        #             # 완료되면 GIFS 저장\n",
        "        #             goal_ob_reward = 'finish'\n",
        "        #             height = 10\n",
        "        #             width = 9\n",
        "        #             display = Display(visible=False, size=(width, height))\n",
        "        #             display.start()\n",
        "        \n",
        "        #             start_point = (9, 4)\n",
        "        #             unit = 50\n",
        "        #             screen_height = height * unit\n",
        "        #             screen_width = width * unit\n",
        "        #             log_path = \"./logs\"\n",
        "        #             data_path = \"./data\"\n",
        "        #             render_cls = Render(screen_width, screen_height, unit, start_point, data_path, log_path)\n",
        "        #             for idx, new_pos in enumerate(self.actions):\n",
        "        #                 render_cls.update_movement(new_pos, idx+1)\n",
        "        \n",
        "        #             render_cls.save_gif(self.epi, '_성공')\n",
        "        #             render_cls.viewer.close()\n",
        "        #             display.stop()\n",
        "        # else:\n",
        "        #     # 완료되면 GIFS 저장\n",
        "        #             height = 10\n",
        "        #             width = 9\n",
        "        #             display = Display(visible=False, size=(width, height))\n",
        "        #             display.start()\n",
        "        \n",
        "        #             start_point = (9, 4)\n",
        "        #             unit = 50\n",
        "        #             screen_height = height * unit\n",
        "        #             screen_width = width * unit\n",
        "        #             log_path = \"./logs\"\n",
        "        #             data_path = \"./data\"\n",
        "        #             render_cls = Render(screen_width, screen_height, unit, start_point, data_path, log_path)\n",
        "        #             for idx, new_pos in enumerate(self.actions):\n",
        "        #                 render_cls.update_movement(new_pos, idx+1)\n",
        "        \n",
        "        #             render_cls.save_gif(self.epi, '_실패')\n",
        "        #             render_cls.viewer.close()\n",
        "        #             display.stop()\n",
        "\n",
        "        return self.get_current_state(), reward, self.cumulative_reward, self.done, goal_ob_reward\n",
        "\n",
        "    def get_current_state(self):\n",
        "        state = (self.curloc[0], self.curloc[1], self.local_target[0][0], self.local_target[0][1])\n",
        "        return np.array(state)\n",
        "\n",
        "    def get_grid(self):\n",
        "        # print(self.grid)\n",
        "        return self.grid\n",
        "\n",
        "\n",
        "# if __name__ == \"__main__\":\n",
        "\n",
        "#     sim = Simulator()\n",
        "#     files = pd.read_csv(\"./data/factory_order_train.csv\")\n",
        "   \n",
        "#     for epi in range(2): # len(files)):\n",
        "#         items = list(files.iloc[epi])[0]\n",
        "#         done = False\n",
        "#         i = 0\n",
        "#         obs = sim.reset(epi)\n",
        "#         actions = [0, 0, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 1]\n",
        "\n",
        "#         while done == False:\n",
        "            \n",
        "#             i += 1\n",
        "#             next_obs, reward, cumul ,done, goal_reward = sim.step(actions[i])\n",
        "\n",
        "#             obs = next_obs\n",
        "\n",
        "#             if (done == True) or (i == (len(actions)-1)):\n",
        "#                 i =0\n",
        "\n",
        "\n",
        "            \n"
      ],
      "metadata": {
        "id": "QfbcCD6VMnJR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0fe17d73-e8dc-488d-dcf5-4c9f02929223"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "reward: -1 -100 1000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# policy.py\n",
        "\n",
        "import gym\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.distributions import Categorical\n",
        "\n",
        "#Hyperparameters\n",
        "learning_rate = 0.0002\n",
        "gamma         = 0.98\n",
        "\n",
        "class TD_ActorCritic(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(TD_ActorCritic, self).__init__()\n",
        "        self.data = []\n",
        "        \n",
        "        self.fc1 = nn.Linear(4,256) # 공유되는 layer \n",
        "        self.fc_pi = nn.Linear(256, 4)\n",
        "        self.fc_v = nn.Linear(256,1)\n",
        "        self.optimizer = optim.Adam(self.parameters(), lr=learning_rate)\n",
        "      \n",
        "    # 두개의 NN\n",
        "    def pi(self, x, softmax_dim = 0): # pi NN\n",
        "        print('input x' , x)\n",
        "        # print('self.fc1(x)',self.fc1(x))\n",
        "        x = F.relu(self.fc1(x))\n",
        "        print('x F.relu output', x)\n",
        "        # print('F.relu(self.fc1(x))',F.relu(self.fc1(x)))\n",
        "        x = self.fc_pi(x)\n",
        "        print('x fc_pi output', x)\n",
        "        # print('self.fc_pi', self.fc_pi(x))\n",
        "        prob = F.softmax(x, dim=softmax_dim) # softmax\n",
        "        print('x F.softmax(x, dim=softmax_dim)', x)\n",
        "        print('prob', prob)\n",
        "        return prob\n",
        "    \n",
        "    def v(self, x): # value NN\n",
        "        x = F.relu(self.fc1(x))\n",
        "        v = self.fc_v(x) # value는 확률이 아니므로 softmax 불필요 \n",
        "        return v\n",
        "    \n",
        "    def put_data(self, transition):\n",
        "        self.data.append(transition)\n",
        "        \n",
        "    # 모은 데이터로 batch를 생성\n",
        "    def make_batch(self):\n",
        "        s_lst, a_lst, r_lst, s_prime_lst, done_lst = [], [], [], [], []\n",
        "        for transition in self.data: \n",
        "            s,a,r,s_prime,done = transition\n",
        "            s_lst.append(s)\n",
        "            a_lst.append([a])\n",
        "            r_lst.append([r/100.0])\n",
        "            s_prime_lst.append(s_prime)\n",
        "            done_mask = 0.0 if done else 1.0\n",
        "            done_lst.append([done_mask])\n",
        "\n",
        "        # 같은 속성끼리 모아서 tensor로 전환\n",
        "        s_batch, a_batch, r_batch, s_prime_batch, done_batch = torch.tensor(s_lst, dtype=torch.float), torch.tensor(a_lst), \\\n",
        "                                                               torch.tensor(r_lst, dtype=torch.float), torch.tensor(s_prime_lst, dtype=torch.float), \\\n",
        "                                                               torch.tensor(done_lst, dtype=torch.float)\n",
        "        self.data = []\n",
        "        return s_batch, a_batch, r_batch, s_prime_batch, done_batch\n",
        "    # 학습 함수\n",
        "    def train_net(self):\n",
        "        s, a, r, s_prime, done = self.make_batch() # make_batch로 들어왔던 데이터 이용해서 tensor 생성됨 \n",
        "        td_target = r + gamma * self.v(s_prime) * done # td_target: 정답\n",
        "        delta = td_target - self.v(s) # target - v(s)\n",
        "        \n",
        "        pi = self.pi(s, softmax_dim=1) # pi action 확률들\n",
        "        pi_a = pi.gather(1,a) # 거기서 고른 action\n",
        "        loss = -torch.log(pi_a) * delta.detach() + F.smooth_l1_loss(self.v(s), td_target.detach())\n",
        "              #policy_loss                         # value_loss\n",
        "        \n",
        "        # delta는 상수값이므로 detach() gradient가 생성되지 않게함\n",
        "        self.optimizer.zero_grad()\n",
        "        loss.mean().backward()\n",
        "        self.optimizer.step()         \n"
      ],
      "metadata": {
        "id": "pNd14XWP9WzN"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "epsilon = 0.99999\n",
        "\n",
        "def update_epsilon(epsilon):\n",
        "    epsilon -= 0.0001\n",
        "    return max(epsilon, 0.2)"
      ],
      "metadata": {
        "id": "MrHpAzKS9WvW"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "gedTpokdMYVL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1003c7d8-9e2c-4e66-94fd-4b1781ce11e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43m스트리밍 출력 내용이 길어서 마지막 5000줄이 삭제되었습니다.\u001b[0m\n",
            "\n",
            "▶▶▶3787번째 에피소드 시작, env 초기화 완료.\n",
            "가져와야 할 아이템 : ['B', 'J', 'L', 'O']\n",
            "\n",
            "현재 state         :  [9 4 4 0]\n",
            "step 데이터 : [9 3 4 0] -100 -100 True False\n",
            "put_data    : [9 4 4 0] 2 -100 [9 3 4 0] True\n",
            "input x tensor([[9., 4., 4., 0.]])\n",
            "x F.relu output tensor([[0.0000e+00, 2.8158e+00, 3.3994e+00, 3.9404e+00, 4.9183e-03, 0.0000e+00,\n",
            "         0.0000e+00, 1.1218e+00, 0.0000e+00, 0.0000e+00, 4.1242e+00, 2.6861e+00,\n",
            "         2.8408e+00, 0.0000e+00, 4.1846e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "         0.0000e+00, 4.3519e+00, 0.0000e+00, 0.0000e+00, 4.0313e+00, 5.9795e+00,\n",
            "         3.8088e+00, 5.5522e+00, 2.5552e+00, 5.0170e+00, 0.0000e+00, 4.8246e+00,\n",
            "         0.0000e+00, 2.8049e+00, 1.5276e+00, 2.2469e+00, 3.9928e+00, 2.9664e+00,\n",
            "         3.2905e+00, 3.7991e+00, 5.1989e+00, 0.0000e+00, 7.3611e-01, 4.1185e+00,\n",
            "         0.0000e+00, 0.0000e+00, 4.8304e+00, 1.6301e+00, 0.0000e+00, 4.4751e+00,\n",
            "         0.0000e+00, 0.0000e+00, 1.3112e+00, 0.0000e+00, 5.7895e+00, 3.8287e+00,\n",
            "         0.0000e+00, 0.0000e+00, 3.9148e+00, 1.5462e-01, 4.5134e+00, 0.0000e+00,\n",
            "         5.6733e+00, 8.4964e-01, 3.8700e+00, 2.7596e+00, 2.2437e+00, 8.2798e-01,\n",
            "         0.0000e+00, 3.4878e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.6760e+00,\n",
            "         0.0000e+00, 2.7813e-01, 1.6144e+00, 0.0000e+00, 1.8743e+00, 0.0000e+00,\n",
            "         4.0840e+00, 6.1193e-02, 5.2757e+00, 2.0937e+00, 0.0000e+00, 5.5149e+00,\n",
            "         0.0000e+00, 4.8359e+00, 4.3236e-01, 6.7207e+00, 0.0000e+00, 0.0000e+00,\n",
            "         0.0000e+00, 2.8916e+00, 0.0000e+00, 5.3932e+00, 0.0000e+00, 4.6211e+00,\n",
            "         0.0000e+00, 9.2130e-01, 3.5947e+00, 0.0000e+00, 0.0000e+00, 5.2365e+00,\n",
            "         1.4320e-01, 5.8759e+00, 3.5040e+00, 0.0000e+00, 7.6148e-01, 0.0000e+00,\n",
            "         1.9912e+00, 5.1320e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.5382e+00,\n",
            "         4.1424e+00, 5.3377e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.8864e+00,\n",
            "         0.0000e+00, 3.0409e+00, 0.0000e+00, 5.0753e+00, 3.1376e+00, 0.0000e+00,\n",
            "         0.0000e+00, 0.0000e+00, 5.2504e+00, 4.9253e+00, 0.0000e+00, 2.3459e+00,\n",
            "         2.9531e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.4193e+00, 2.1336e+00,\n",
            "         3.7385e+00, 1.3208e+00, 0.0000e+00, 0.0000e+00, 3.6119e+00, 0.0000e+00,\n",
            "         1.2932e+00, 2.8089e+00, 0.0000e+00, 7.1634e+00, 3.6279e+00, 1.6125e+00,\n",
            "         0.0000e+00, 7.4903e+00, 0.0000e+00, 5.3382e+00, 0.0000e+00, 0.0000e+00,\n",
            "         0.0000e+00, 4.9048e+00, 1.9445e+00, 5.4007e+00, 0.0000e+00, 2.6632e+00,\n",
            "         0.0000e+00, 4.1823e+00, 2.9491e+00, 0.0000e+00, 3.4363e+00, 0.0000e+00,\n",
            "         5.0397e+00, 0.0000e+00, 4.2063e-01, 0.0000e+00, 4.7783e+00, 0.0000e+00,\n",
            "         0.0000e+00, 3.9382e+00, 6.9941e+00, 0.0000e+00, 6.4716e+00, 0.0000e+00,\n",
            "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "         2.1258e+00, 0.0000e+00, 2.8415e+00, 0.0000e+00, 0.0000e+00, 1.4495e+00,\n",
            "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "         0.0000e+00, 2.8480e+00, 3.6907e+00, 3.4617e+00, 0.0000e+00, 3.2165e+00,\n",
            "         5.6941e+00, 3.5271e+00, 0.0000e+00, 4.2007e+00, 0.0000e+00, 2.2317e+00,\n",
            "         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.1793e+00, 0.0000e+00, 2.7846e+00,\n",
            "         0.0000e+00, 3.2746e+00, 0.0000e+00, 6.9234e-01, 1.2188e+00, 0.0000e+00,\n",
            "         1.9693e+00, 0.0000e+00, 0.0000e+00, 5.4882e+00, 6.9597e+00, 3.3037e+00,\n",
            "         5.2361e+00, 2.5221e+00, 4.6032e+00, 4.8082e+00, 5.6594e+00, 0.0000e+00,\n",
            "         7.1696e-01, 9.5460e-01, 0.0000e+00, 5.7134e+00, 0.0000e+00, 8.7340e+00,\n",
            "         2.2872e+00, 0.0000e+00, 1.8287e+00, 2.1721e+00, 0.0000e+00, 5.3003e+00,\n",
            "         0.0000e+00, 3.9238e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "         0.0000e+00, 7.2136e+00, 0.0000e+00, 6.9818e+00]],\n",
            "       grad_fn=<ReluBackward0>)\n",
            "x fc_pi output tensor([[ 53.0963, -33.8895,   3.5629, -34.6970]], grad_fn=<AddmmBackward0>)\n",
            "x F.softmax(x, dim=softmax_dim) tensor([[ 53.0963, -33.8895,   3.5629, -34.6970]], grad_fn=<AddmmBackward0>)\n",
            "prob tensor([[1.0000e+00, 1.6694e-38, 3.0755e-22, 7.4446e-39]],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "\n",
            "\n",
            "▶▶▶ 3787  : max cum reward :  1887  epsilon = 0.6212900000000418\n",
            "\n",
            "\n",
            "▶▶▶3788번째 에피소드 시작, env 초기화 완료.\n",
            "가져와야 할 아이템 : ['D', 'F', 'G', 'I']\n",
            "\n",
            "현재 state         :  [9 4 2 0]\n",
            "tensor([9, 4, 2, 0])\n",
            "tensor([9., 4., 2., 0.])\n",
            "end input\n",
            "input x tensor([9., 4., 2., 0.])\n",
            "x F.relu output tensor([0.0000, 3.4548, 4.0068, 4.1925, 0.0000, 0.3305, 0.0000, 1.6554, 0.0000,\n",
            "        0.0000, 4.0388, 3.3466, 2.7455, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 4.0140, 0.0000, 0.0000, 3.6153, 5.8090, 2.9238, 4.8003, 3.3069,\n",
            "        5.2311, 0.0000, 3.7032, 0.0000, 3.2828, 1.3538, 3.1306, 4.1948, 2.5990,\n",
            "        4.1150, 2.6849, 4.9764, 0.0000, 0.0841, 3.6843, 0.0000, 0.0000, 4.3696,\n",
            "        1.5862, 0.0000, 3.7686, 0.0000, 0.0000, 2.0820, 0.0000, 4.8159, 4.5194,\n",
            "        0.0000, 0.0000, 3.2939, 0.2871, 3.8220, 0.0000, 5.5880, 0.0000, 2.9345,\n",
            "        2.5072, 2.5372, 0.0373, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 3.1179,\n",
            "        0.0000, 0.7936, 1.6325, 0.0000, 2.0649, 0.0000, 4.5617, 0.0000, 4.4635,\n",
            "        1.1578, 0.0000, 5.2761, 0.0000, 3.9583, 0.0000, 6.4996, 0.0000, 0.0000,\n",
            "        0.0000, 3.2841, 0.0000, 5.6684, 0.0000, 3.7693, 0.0000, 1.1802, 3.2663,\n",
            "        0.0668, 0.0000, 5.7363, 0.4568, 5.6364, 3.6715, 0.0000, 1.3351, 0.0000,\n",
            "        0.9714, 4.7520, 0.0000, 0.5013, 0.0000, 3.0773, 3.2688, 4.5099, 0.0000,\n",
            "        0.0000, 0.0000, 2.9707, 0.0000, 2.2208, 0.0000, 4.0379, 2.1545, 0.0000,\n",
            "        0.0000, 0.0000, 5.2894, 5.4663, 0.0000, 2.1365, 3.0135, 0.0000, 0.0000,\n",
            "        0.0000, 3.5261, 2.1770, 3.9279, 0.9172, 0.0000, 0.0000, 3.0456, 0.0000,\n",
            "        1.4833, 2.9592, 0.0000, 6.8886, 3.0372, 1.8162, 0.0000, 6.3493, 0.3832,\n",
            "        5.3498, 0.0000, 0.0000, 0.0000, 4.6857, 1.7133, 6.1555, 0.0000, 2.9275,\n",
            "        0.0000, 3.6015, 2.4056, 0.0000, 2.7090, 0.0000, 5.6545, 0.0000, 1.1412,\n",
            "        0.0000, 4.3797, 0.0000, 0.0000, 4.0521, 6.7139, 0.0000, 5.9831, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.5271, 0.0000, 3.1997,\n",
            "        0.0000, 0.0000, 2.1137, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 3.4045, 2.9251, 3.8749, 0.0000, 3.2162, 5.8584, 2.4799, 0.0000,\n",
            "        3.1559, 0.0000, 1.2105, 0.0000, 0.0000, 0.5696, 0.9322, 0.0000, 2.2342,\n",
            "        0.0000, 2.9140, 0.0000, 1.2999, 2.0863, 0.0000, 1.1249, 0.0000, 0.0000,\n",
            "        4.9889, 5.8410, 3.4452, 5.0117, 2.6798, 5.2874, 4.0756, 5.5388, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 5.1672, 0.0000, 7.6237, 2.2123, 0.0000, 2.3318,\n",
            "        1.8054, 0.0000, 4.1574, 0.0000, 3.1410, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 5.9802, 0.0000, 6.7562], grad_fn=<ReluBackward0>)\n",
            "x fc_pi output tensor([ 51.5916, -32.4753,   2.0721, -31.4363], grad_fn=<AddBackward0>)\n",
            "x F.softmax(x, dim=softmax_dim) tensor([ 51.5916, -32.4753,   2.0721, -31.4363], grad_fn=<AddBackward0>)\n",
            "prob tensor([1.0000e+00, 3.0919e-37, 3.1186e-22, 8.7388e-37],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "step 데이터 : [8 4 2 0] -1 -1 False False\n",
            "put_data    : [9 4 2 0] 0 -1 [8 4 2 0] False\n",
            "step 데이터 : [7 4 2 0] -1 -2 False False\n",
            "put_data    : [8 4 2 0] 0 -1 [7 4 2 0] False\n",
            "tensor([7, 4, 2, 0])\n",
            "tensor([7., 4., 2., 0.])\n",
            "end input\n",
            "input x tensor([7., 4., 2., 0.])\n",
            "x F.relu output tensor([0.0000, 2.7371, 3.3265, 2.9378, 0.0000, 0.0000, 0.0000, 1.4014, 0.0000,\n",
            "        0.0000, 2.9258, 2.6524, 2.5392, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 3.5410, 0.0000, 0.0000, 3.0926, 4.5485, 2.5220, 4.1687, 2.2086,\n",
            "        4.1514, 0.0000, 3.0138, 0.0000, 2.7450, 1.1876, 2.5655, 3.8520, 2.4297,\n",
            "        2.9432, 2.1211, 4.0739, 0.0000, 0.4150, 2.8973, 0.0000, 0.0000, 3.8369,\n",
            "        1.4597, 0.0000, 3.0891, 0.0000, 0.0000, 1.8381, 0.0000, 4.1504, 3.6117,\n",
            "        0.0000, 0.0000, 2.7526, 0.1885, 3.4790, 0.0000, 4.8355, 0.3999, 2.2474,\n",
            "        2.2704, 1.7837, 0.0852, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 2.3863,\n",
            "        0.0000, 0.0813, 1.4399, 0.0000, 2.0579, 0.0000, 3.5930, 0.0000, 4.0812,\n",
            "        1.3042, 0.0000, 4.2164, 0.0000, 3.1770, 0.2320, 5.5233, 0.0000, 0.0000,\n",
            "        0.0000, 2.4139, 0.0000, 4.8047, 0.0000, 2.8901, 0.0000, 0.7428, 2.5147,\n",
            "        0.0000, 0.0000, 4.6741, 0.4226, 4.7708, 3.2867, 0.0000, 1.1098, 0.0000,\n",
            "        1.1901, 4.2955, 0.0000, 0.0491, 0.0000, 2.6503, 3.2636, 4.1776, 0.0000,\n",
            "        0.0000, 0.0000, 2.8489, 0.0000, 2.2989, 0.0000, 3.7757, 2.0591, 0.0000,\n",
            "        0.0000, 0.0000, 4.5789, 4.6264, 0.0000, 1.9172, 2.5712, 0.0000, 0.0000,\n",
            "        0.0000, 2.7617, 1.5145, 3.3497, 0.5042, 0.0000, 0.0000, 2.8652, 0.1240,\n",
            "        1.4828, 2.2277, 0.0000, 5.8951, 2.7154, 1.2221, 0.0000, 5.6975, 0.6745,\n",
            "        4.2283, 0.0000, 0.0000, 0.0000, 4.0037, 1.7273, 5.0022, 0.0000, 2.0972,\n",
            "        0.0000, 2.8934, 2.6273, 0.0000, 2.5550, 0.0000, 4.8578, 0.0000, 0.8786,\n",
            "        0.0000, 3.9470, 0.0000, 0.0000, 3.4462, 5.7933, 0.0000, 4.9412, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.2802, 0.0000, 2.7525,\n",
            "        0.0000, 0.0000, 1.2107, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 2.6098, 2.2411, 3.3042, 0.0000, 2.7762, 4.9705, 2.4594, 0.0000,\n",
            "        2.6630, 0.0000, 1.2354, 0.0000, 0.0000, 0.5911, 1.1395, 0.0000, 2.0515,\n",
            "        0.0000, 2.7772, 0.0000, 1.3323, 1.8365, 0.0000, 1.1354, 0.0000, 0.0000,\n",
            "        3.8782, 4.9763, 2.8550, 3.8842, 1.9228, 4.4067, 3.2777, 4.7598, 0.0000,\n",
            "        0.0000, 0.2920, 0.0000, 4.6141, 0.0000, 6.5556, 1.8823, 0.0000, 1.6873,\n",
            "        1.3835, 0.0000, 3.8781, 0.0000, 2.3040, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 5.5507, 0.0000, 5.7883], grad_fn=<ReluBackward0>)\n",
            "x fc_pi output tensor([ 43.3049, -27.4063,   2.3231, -26.9353], grad_fn=<AddBackward0>)\n",
            "x F.softmax(x, dim=softmax_dim) tensor([ 43.3049, -27.4063,   2.3231, -26.9353], grad_fn=<AddBackward0>)\n",
            "prob tensor([1.0000e+00, 1.9523e-31, 1.5917e-18, 3.1268e-31],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "step 데이터 : [6 4 2 0] -100 -102 True False\n",
            "put_data    : [7 4 2 0] 0 -100 [6 4 2 0] True\n",
            "input x tensor([[9., 4., 2., 0.],\n",
            "        [8., 4., 2., 0.],\n",
            "        [7., 4., 2., 0.]])\n",
            "x F.relu output tensor([[0.0000, 3.4548, 4.0068, 4.1925, 0.0000, 0.3305, 0.0000, 1.6554, 0.0000,\n",
            "         0.0000, 4.0388, 3.3466, 2.7455, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 4.0140, 0.0000, 0.0000, 3.6153, 5.8090, 2.9238, 4.8003, 3.3069,\n",
            "         5.2311, 0.0000, 3.7032, 0.0000, 3.2828, 1.3538, 3.1306, 4.1948, 2.5990,\n",
            "         4.1150, 2.6849, 4.9764, 0.0000, 0.0841, 3.6843, 0.0000, 0.0000, 4.3696,\n",
            "         1.5862, 0.0000, 3.7686, 0.0000, 0.0000, 2.0820, 0.0000, 4.8159, 4.5194,\n",
            "         0.0000, 0.0000, 3.2939, 0.2871, 3.8220, 0.0000, 5.5880, 0.0000, 2.9345,\n",
            "         2.5072, 2.5372, 0.0373, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 3.1179,\n",
            "         0.0000, 0.7936, 1.6325, 0.0000, 2.0649, 0.0000, 4.5617, 0.0000, 4.4635,\n",
            "         1.1578, 0.0000, 5.2761, 0.0000, 3.9583, 0.0000, 6.4996, 0.0000, 0.0000,\n",
            "         0.0000, 3.2841, 0.0000, 5.6684, 0.0000, 3.7693, 0.0000, 1.1802, 3.2663,\n",
            "         0.0668, 0.0000, 5.7363, 0.4568, 5.6364, 3.6715, 0.0000, 1.3351, 0.0000,\n",
            "         0.9714, 4.7520, 0.0000, 0.5013, 0.0000, 3.0773, 3.2688, 4.5099, 0.0000,\n",
            "         0.0000, 0.0000, 2.9707, 0.0000, 2.2208, 0.0000, 4.0379, 2.1545, 0.0000,\n",
            "         0.0000, 0.0000, 5.2894, 5.4663, 0.0000, 2.1365, 3.0135, 0.0000, 0.0000,\n",
            "         0.0000, 3.5261, 2.1770, 3.9279, 0.9172, 0.0000, 0.0000, 3.0456, 0.0000,\n",
            "         1.4833, 2.9592, 0.0000, 6.8886, 3.0372, 1.8162, 0.0000, 6.3493, 0.3832,\n",
            "         5.3498, 0.0000, 0.0000, 0.0000, 4.6857, 1.7133, 6.1555, 0.0000, 2.9275,\n",
            "         0.0000, 3.6015, 2.4056, 0.0000, 2.7090, 0.0000, 5.6545, 0.0000, 1.1412,\n",
            "         0.0000, 4.3797, 0.0000, 0.0000, 4.0521, 6.7139, 0.0000, 5.9831, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.5271, 0.0000, 3.1997,\n",
            "         0.0000, 0.0000, 2.1137, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 3.4045, 2.9251, 3.8749, 0.0000, 3.2162, 5.8584, 2.4799, 0.0000,\n",
            "         3.1559, 0.0000, 1.2105, 0.0000, 0.0000, 0.5696, 0.9322, 0.0000, 2.2342,\n",
            "         0.0000, 2.9140, 0.0000, 1.2999, 2.0863, 0.0000, 1.1249, 0.0000, 0.0000,\n",
            "         4.9889, 5.8410, 3.4452, 5.0117, 2.6798, 5.2874, 4.0756, 5.5388, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 5.1672, 0.0000, 7.6237, 2.2123, 0.0000, 2.3318,\n",
            "         1.8054, 0.0000, 4.1574, 0.0000, 3.1410, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 5.9802, 0.0000, 6.7562],\n",
            "        [0.0000, 3.0960, 3.6666, 3.5652, 0.0000, 0.1159, 0.0000, 1.5284, 0.0000,\n",
            "         0.0000, 3.4823, 2.9995, 2.6423, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 3.7775, 0.0000, 0.0000, 3.3539, 5.1787, 2.7229, 4.4845, 2.7577,\n",
            "         4.6913, 0.0000, 3.3585, 0.0000, 3.0139, 1.2707, 2.8480, 4.0234, 2.5144,\n",
            "         3.5291, 2.4030, 4.5252, 0.0000, 0.2496, 3.2908, 0.0000, 0.0000, 4.1032,\n",
            "         1.5230, 0.0000, 3.4289, 0.0000, 0.0000, 1.9600, 0.0000, 4.4831, 4.0655,\n",
            "         0.0000, 0.0000, 3.0232, 0.2378, 3.6505, 0.0000, 5.2117, 0.0978, 2.5910,\n",
            "         2.3888, 2.1605, 0.0612, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 2.7521,\n",
            "         0.0000, 0.4375, 1.5362, 0.0000, 2.0614, 0.0000, 4.0774, 0.0000, 4.2724,\n",
            "         1.2310, 0.0000, 4.7463, 0.0000, 3.5677, 0.0619, 6.0114, 0.0000, 0.0000,\n",
            "         0.0000, 2.8490, 0.0000, 5.2365, 0.0000, 3.3297, 0.0000, 0.9615, 2.8905,\n",
            "         0.0000, 0.0000, 5.2052, 0.4397, 5.2036, 3.4791, 0.0000, 1.2225, 0.0000,\n",
            "         1.0808, 4.5237, 0.0000, 0.2752, 0.0000, 2.8638, 3.2662, 4.3438, 0.0000,\n",
            "         0.0000, 0.0000, 2.9098, 0.0000, 2.2599, 0.0000, 3.9068, 2.1068, 0.0000,\n",
            "         0.0000, 0.0000, 4.9341, 5.0463, 0.0000, 2.0268, 2.7924, 0.0000, 0.0000,\n",
            "         0.0000, 3.1439, 1.8458, 3.6388, 0.7107, 0.0000, 0.0000, 2.9554, 0.0000,\n",
            "         1.4830, 2.5935, 0.0000, 6.3918, 2.8763, 1.5192, 0.0000, 6.0234, 0.5288,\n",
            "         4.7890, 0.0000, 0.0000, 0.0000, 4.3447, 1.7203, 5.5789, 0.0000, 2.5123,\n",
            "         0.0000, 3.2474, 2.5165, 0.0000, 2.6320, 0.0000, 5.2562, 0.0000, 1.0099,\n",
            "         0.0000, 4.1634, 0.0000, 0.0000, 3.7492, 6.2536, 0.0000, 5.4622, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.4037, 0.0000, 2.9761,\n",
            "         0.0000, 0.0000, 1.6622, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 3.0071, 2.5831, 3.5896, 0.0000, 2.9962, 5.4144, 2.4696, 0.0000,\n",
            "         2.9094, 0.0000, 1.2229, 0.0000, 0.0000, 0.5804, 1.0359, 0.0000, 2.1428,\n",
            "         0.0000, 2.8456, 0.0000, 1.3161, 1.9614, 0.0000, 1.1301, 0.0000, 0.0000,\n",
            "         4.4335, 5.4087, 3.1501, 4.4479, 2.3013, 4.8470, 3.6766, 5.1493, 0.0000,\n",
            "         0.0000, 0.1311, 0.0000, 4.8907, 0.0000, 7.0897, 2.0473, 0.0000, 2.0096,\n",
            "         1.5944, 0.0000, 4.0177, 0.0000, 2.7225, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 5.7655, 0.0000, 6.2722],\n",
            "        [0.0000, 2.7371, 3.3265, 2.9378, 0.0000, 0.0000, 0.0000, 1.4014, 0.0000,\n",
            "         0.0000, 2.9258, 2.6524, 2.5392, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 3.5410, 0.0000, 0.0000, 3.0926, 4.5485, 2.5220, 4.1687, 2.2086,\n",
            "         4.1514, 0.0000, 3.0138, 0.0000, 2.7450, 1.1876, 2.5655, 3.8520, 2.4297,\n",
            "         2.9432, 2.1211, 4.0739, 0.0000, 0.4150, 2.8973, 0.0000, 0.0000, 3.8369,\n",
            "         1.4597, 0.0000, 3.0891, 0.0000, 0.0000, 1.8381, 0.0000, 4.1504, 3.6117,\n",
            "         0.0000, 0.0000, 2.7526, 0.1885, 3.4790, 0.0000, 4.8355, 0.3999, 2.2474,\n",
            "         2.2704, 1.7837, 0.0852, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 2.3863,\n",
            "         0.0000, 0.0813, 1.4399, 0.0000, 2.0579, 0.0000, 3.5930, 0.0000, 4.0812,\n",
            "         1.3042, 0.0000, 4.2164, 0.0000, 3.1770, 0.2320, 5.5233, 0.0000, 0.0000,\n",
            "         0.0000, 2.4139, 0.0000, 4.8047, 0.0000, 2.8901, 0.0000, 0.7428, 2.5147,\n",
            "         0.0000, 0.0000, 4.6741, 0.4226, 4.7708, 3.2867, 0.0000, 1.1098, 0.0000,\n",
            "         1.1901, 4.2955, 0.0000, 0.0491, 0.0000, 2.6503, 3.2636, 4.1776, 0.0000,\n",
            "         0.0000, 0.0000, 2.8489, 0.0000, 2.2989, 0.0000, 3.7757, 2.0591, 0.0000,\n",
            "         0.0000, 0.0000, 4.5789, 4.6264, 0.0000, 1.9172, 2.5712, 0.0000, 0.0000,\n",
            "         0.0000, 2.7617, 1.5145, 3.3497, 0.5042, 0.0000, 0.0000, 2.8652, 0.1240,\n",
            "         1.4828, 2.2277, 0.0000, 5.8951, 2.7154, 1.2221, 0.0000, 5.6975, 0.6745,\n",
            "         4.2283, 0.0000, 0.0000, 0.0000, 4.0037, 1.7273, 5.0022, 0.0000, 2.0972,\n",
            "         0.0000, 2.8934, 2.6273, 0.0000, 2.5550, 0.0000, 4.8578, 0.0000, 0.8786,\n",
            "         0.0000, 3.9470, 0.0000, 0.0000, 3.4462, 5.7933, 0.0000, 4.9412, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.2802, 0.0000, 2.7525,\n",
            "         0.0000, 0.0000, 1.2107, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 2.6098, 2.2411, 3.3042, 0.0000, 2.7762, 4.9705, 2.4594, 0.0000,\n",
            "         2.6630, 0.0000, 1.2354, 0.0000, 0.0000, 0.5911, 1.1395, 0.0000, 2.0515,\n",
            "         0.0000, 2.7772, 0.0000, 1.3323, 1.8365, 0.0000, 1.1354, 0.0000, 0.0000,\n",
            "         3.8782, 4.9763, 2.8550, 3.8842, 1.9228, 4.4067, 3.2777, 4.7598, 0.0000,\n",
            "         0.0000, 0.2920, 0.0000, 4.6141, 0.0000, 6.5556, 1.8823, 0.0000, 1.6873,\n",
            "         1.3835, 0.0000, 3.8781, 0.0000, 2.3040, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 5.5507, 0.0000, 5.7883]], grad_fn=<ReluBackward0>)\n",
            "x fc_pi output tensor([[ 51.5916, -32.4753,   2.0721, -31.4363],\n",
            "        [ 47.4493, -29.9351,   2.1909, -29.1695],\n",
            "        [ 43.3049, -27.4063,   2.3231, -26.9353]], grad_fn=<AddmmBackward0>)\n",
            "x F.softmax(x, dim=softmax_dim) tensor([[ 51.5916, -32.4753,   2.0721, -31.4363],\n",
            "        [ 47.4493, -29.9351,   2.1909, -29.1695],\n",
            "        [ 43.3049, -27.4063,   2.3231, -26.9353]], grad_fn=<AddmmBackward0>)\n",
            "prob tensor([[1.0000e+00, 3.0919e-37, 3.1186e-22, 8.7388e-37],\n",
            "        [1.0000e+00, 2.4681e-34, 2.2106e-20, 5.3074e-34],\n",
            "        [1.0000e+00, 1.9523e-31, 1.5917e-18, 3.1267e-31]],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "\n",
            "\n",
            "▶▶▶ 3788  : max cum reward :  1887  epsilon = 0.6211900000000418\n",
            "\n",
            "\n",
            "▶▶▶3789번째 에피소드 시작, env 초기화 완료.\n",
            "가져와야 할 아이템 : ['A', 'B', 'D', 'G', 'K', 'M']\n",
            "\n",
            "현재 state         :  [9 4 5 0]\n",
            "step 데이터 : [9 5 5 0] -100 -100 True False\n",
            "put_data    : [9 4 5 0] 3 -100 [9 5 5 0] True\n",
            "input x tensor([[9., 4., 5., 0.]])\n",
            "x F.relu output tensor([[0.0000, 2.4986, 3.0972, 3.8161, 0.3742, 0.0000, 0.0000, 0.8559, 0.0000,\n",
            "         0.0000, 4.1683, 2.3565, 2.8902, 0.0000, 0.9105, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 4.5220, 0.0000, 0.0000, 4.2423, 6.0665, 4.2524, 5.9300, 2.1808,\n",
            "         4.9119, 0.0000, 5.3887, 0.0000, 2.5674, 1.6151, 1.8051, 3.8926, 3.1520,\n",
            "         2.8794, 4.3584, 5.3124, 0.0000, 1.0644, 4.3385, 0.0000, 0.0000, 5.0621,\n",
            "         1.6543, 0.0000, 4.8292, 0.0000, 0.0000, 0.9259, 0.0000, 6.2777, 3.4850,\n",
            "         0.0000, 0.0000, 4.2264, 0.0899, 4.8613, 0.0000, 5.7183, 1.3790, 4.3395,\n",
            "         2.8872, 2.0977, 1.2242, 0.0000, 0.7881, 0.0000, 0.0000, 0.0000, 2.4564,\n",
            "         0.0000, 0.0196, 1.6060, 0.0000, 1.7815, 0.0000, 3.8466, 0.2399, 5.6832,\n",
            "         2.5657, 0.0000, 5.6352, 0.0000, 5.2773, 0.7040, 6.8322, 0.0000, 0.0000,\n",
            "         0.0000, 2.6983, 0.0000, 5.2568, 0.0000, 5.0491, 0.0000, 0.7925, 3.7604,\n",
            "         0.0000, 0.0000, 4.9882, 0.0000, 5.9985, 3.4217, 0.0000, 0.4751, 0.0000,\n",
            "         2.5030, 5.3246, 0.0000, 0.0000, 0.0000, 2.2692, 4.5810, 5.7526, 0.0000,\n",
            "         0.0000, 0.0000, 2.8456, 0.0000, 3.4528, 0.0000, 5.5968, 3.6306, 0.0000,\n",
            "         0.0000, 0.0000, 5.2326, 4.6577, 0.0000, 2.4517, 2.9249, 0.0000, 0.0000,\n",
            "         0.0000, 3.3676, 2.1131, 3.6464, 1.5232, 0.0000, 0.0000, 3.8977, 0.0000,\n",
            "         1.1993, 2.7350, 0.0000, 7.3026, 3.9249, 1.5118, 0.0000, 8.0634, 0.0000,\n",
            "         5.3338, 0.0000, 0.0000, 0.0000, 5.0166, 2.0615, 5.0248, 0.0000, 2.5327,\n",
            "         0.0000, 4.4750, 3.2227, 0.0329, 3.8019, 0.0000, 4.7344, 0.0000, 0.0624,\n",
            "         0.0000, 4.9787, 0.0000, 0.0000, 3.8825, 7.1351, 0.0000, 6.7170, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 2.4292, 0.0000, 2.6651,\n",
            "         0.0000, 0.0000, 1.1187, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 2.5701, 4.0750, 3.2566, 0.0000, 3.2200, 5.6132, 4.0547, 0.0000,\n",
            "         4.7258, 0.0000, 2.7445, 0.0000, 0.0000, 0.0000, 1.3051, 0.0000, 3.0626,\n",
            "         0.0000, 3.4564, 0.0000, 0.3903, 0.7857, 0.0000, 2.3942, 0.0000, 0.0000,\n",
            "         5.7392, 7.5212, 3.2348, 5.3506, 2.4452, 4.2633, 5.1766, 5.7231, 0.0000,\n",
            "         1.1636, 1.4477, 0.0000, 5.9875, 0.0000, 9.2921, 2.3266, 0.0000, 1.5780,\n",
            "         2.3582, 0.0000, 5.8748, 0.0000, 4.3171, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 7.8330, 0.0000, 7.0966]], grad_fn=<ReluBackward0>)\n",
            "x fc_pi output tensor([[ 53.8928, -34.6823,   4.3866, -36.4496]], grad_fn=<AddmmBackward0>)\n",
            "x F.softmax(x, dim=softmax_dim) tensor([[ 53.8928, -34.6823,   4.3866, -36.4496]], grad_fn=<AddmmBackward0>)\n",
            "prob tensor([[1.0000e+00, 3.4068e-39, 3.1604e-22, 5.8183e-40]],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "\n",
            "\n",
            "▶▶▶ 3789  : max cum reward :  1887  epsilon = 0.6210900000000418\n",
            "\n",
            "\n",
            "▶▶▶3790번째 에피소드 시작, env 초기화 완료.\n",
            "가져와야 할 아이템 : ['A', 'I', 'J', 'M', 'O']\n",
            "\n",
            "현재 state         :  [9 4 5 0]\n",
            "tensor([9, 4, 5, 0])\n",
            "tensor([9., 4., 5., 0.])\n",
            "end input\n",
            "input x tensor([9., 4., 5., 0.])\n",
            "x F.relu output tensor([0.0000, 2.4992, 3.0975, 3.8165, 0.3745, 0.0000, 0.0000, 0.8560, 0.0000,\n",
            "        0.0000, 4.1685, 2.3566, 2.8907, 0.0000, 0.9109, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 4.5222, 0.0000, 0.0000, 4.2431, 6.0669, 4.2526, 5.9305, 2.1811,\n",
            "        4.9124, 0.0000, 5.3897, 0.0000, 2.5679, 1.6152, 1.8050, 3.8928, 3.1525,\n",
            "        2.8796, 4.3589, 5.3130, 0.0000, 1.0652, 4.3393, 0.0000, 0.0000, 5.0624,\n",
            "        1.6549, 0.0000, 4.8294, 0.0000, 0.0000, 0.9258, 0.0000, 6.2779, 3.4854,\n",
            "        0.0000, 0.0000, 4.2267, 0.0902, 4.8619, 0.0000, 5.7190, 1.3797, 4.3398,\n",
            "        2.8875, 2.0979, 1.2242, 0.0000, 0.7881, 0.0000, 0.0000, 0.0000, 2.4566,\n",
            "        0.0000, 0.0193, 1.6061, 0.0000, 1.7822, 0.0000, 3.8471, 0.2403, 5.6836,\n",
            "        2.5669, 0.0000, 5.6354, 0.0000, 5.2781, 0.7043, 6.8324, 0.0000, 0.0000,\n",
            "        0.0000, 2.6991, 0.0000, 5.2570, 0.0000, 5.0496, 0.0000, 0.7926, 3.7606,\n",
            "        0.0000, 0.0000, 4.9886, 0.0000, 5.9994, 3.4220, 0.0000, 0.4751, 0.0000,\n",
            "        2.5034, 5.3253, 0.0000, 0.0000, 0.0000, 2.2693, 4.5814, 5.7527, 0.0000,\n",
            "        0.0000, 0.0000, 2.8459, 0.0000, 3.4532, 0.0000, 5.5975, 3.6309, 0.0000,\n",
            "        0.0000, 0.0000, 5.2331, 4.6586, 0.0000, 2.4519, 2.9254, 0.0000, 0.0000,\n",
            "        0.0000, 3.3680, 2.1134, 3.6472, 1.5232, 0.0000, 0.0000, 3.8984, 0.0000,\n",
            "        1.1995, 2.7353, 0.0000, 7.3031, 3.9253, 1.5120, 0.0000, 8.0641, 0.0000,\n",
            "        5.3342, 0.0000, 0.0000, 0.0000, 5.0172, 2.0618, 5.0252, 0.0000, 2.5331,\n",
            "        0.0000, 4.4756, 3.2232, 0.0329, 3.8024, 0.0000, 4.7349, 0.0000, 0.0629,\n",
            "        0.0000, 4.9790, 0.0000, 0.0000, 3.8829, 7.1353, 0.0000, 6.7173, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 2.4304, 0.0000, 2.6660,\n",
            "        0.0000, 0.0000, 1.1190, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 2.5701, 4.0754, 3.2570, 0.0000, 3.2211, 5.6135, 4.0560, 0.0000,\n",
            "        4.7265, 0.0000, 2.7451, 0.0000, 0.0000, 0.0000, 1.3057, 0.0000, 3.0634,\n",
            "        0.0000, 3.4568, 0.0000, 0.3908, 0.7857, 0.0000, 2.3949, 0.0000, 0.0000,\n",
            "        5.7395, 7.5217, 3.2352, 5.3514, 2.4457, 4.2640, 5.1772, 5.7241, 0.0000,\n",
            "        1.1636, 1.4478, 0.0000, 5.9877, 0.0000, 9.2929, 2.3271, 0.0000, 1.5782,\n",
            "        2.3591, 0.0000, 5.8757, 0.0000, 4.3176, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 7.8337, 0.0000, 7.0972], grad_fn=<ReluBackward0>)\n",
            "x fc_pi output tensor([ 53.9041, -34.6971,   4.4003, -36.4690], grad_fn=<AddBackward0>)\n",
            "x F.softmax(x, dim=softmax_dim) tensor([ 53.9041, -34.6971,   4.4003, -36.4690], grad_fn=<AddBackward0>)\n",
            "prob tensor([1.0000e+00, 3.3190e-39, 3.1678e-22, 5.6427e-40],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "step 데이터 : [8 4 5 0] -1 -1 False False\n",
            "put_data    : [9 4 5 0] 0 -1 [8 4 5 0] False\n",
            "step 데이터 : [9 4 5 0] -1 -2 False False\n",
            "put_data    : [8 4 5 0] 1 -1 [9 4 5 0] False\n",
            "step 데이터 : [9 5 5 0] -100 -102 True False\n",
            "put_data    : [9 4 5 0] 3 -100 [9 5 5 0] True\n",
            "input x tensor([[9., 4., 5., 0.],\n",
            "        [8., 4., 5., 0.],\n",
            "        [9., 4., 5., 0.]])\n",
            "x F.relu output tensor([[0.0000, 2.4992, 3.0975, 3.8165, 0.3745, 0.0000, 0.0000, 0.8560, 0.0000,\n",
            "         0.0000, 4.1685, 2.3566, 2.8907, 0.0000, 0.9109, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 4.5222, 0.0000, 0.0000, 4.2431, 6.0669, 4.2526, 5.9305, 2.1811,\n",
            "         4.9124, 0.0000, 5.3897, 0.0000, 2.5679, 1.6152, 1.8050, 3.8928, 3.1525,\n",
            "         2.8796, 4.3589, 5.3130, 0.0000, 1.0652, 4.3393, 0.0000, 0.0000, 5.0624,\n",
            "         1.6549, 0.0000, 4.8294, 0.0000, 0.0000, 0.9258, 0.0000, 6.2779, 3.4854,\n",
            "         0.0000, 0.0000, 4.2267, 0.0902, 4.8619, 0.0000, 5.7190, 1.3797, 4.3398,\n",
            "         2.8875, 2.0979, 1.2242, 0.0000, 0.7881, 0.0000, 0.0000, 0.0000, 2.4566,\n",
            "         0.0000, 0.0193, 1.6061, 0.0000, 1.7822, 0.0000, 3.8471, 0.2403, 5.6836,\n",
            "         2.5669, 0.0000, 5.6354, 0.0000, 5.2781, 0.7043, 6.8324, 0.0000, 0.0000,\n",
            "         0.0000, 2.6991, 0.0000, 5.2570, 0.0000, 5.0496, 0.0000, 0.7926, 3.7606,\n",
            "         0.0000, 0.0000, 4.9886, 0.0000, 5.9994, 3.4220, 0.0000, 0.4751, 0.0000,\n",
            "         2.5034, 5.3253, 0.0000, 0.0000, 0.0000, 2.2693, 4.5814, 5.7527, 0.0000,\n",
            "         0.0000, 0.0000, 2.8459, 0.0000, 3.4532, 0.0000, 5.5975, 3.6309, 0.0000,\n",
            "         0.0000, 0.0000, 5.2331, 4.6586, 0.0000, 2.4519, 2.9254, 0.0000, 0.0000,\n",
            "         0.0000, 3.3680, 2.1134, 3.6472, 1.5232, 0.0000, 0.0000, 3.8984, 0.0000,\n",
            "         1.1995, 2.7353, 0.0000, 7.3031, 3.9253, 1.5120, 0.0000, 8.0641, 0.0000,\n",
            "         5.3342, 0.0000, 0.0000, 0.0000, 5.0172, 2.0618, 5.0252, 0.0000, 2.5331,\n",
            "         0.0000, 4.4756, 3.2232, 0.0329, 3.8024, 0.0000, 4.7349, 0.0000, 0.0629,\n",
            "         0.0000, 4.9790, 0.0000, 0.0000, 3.8829, 7.1353, 0.0000, 6.7173, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 2.4304, 0.0000, 2.6660,\n",
            "         0.0000, 0.0000, 1.1190, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 2.5701, 4.0754, 3.2570, 0.0000, 3.2211, 5.6135, 4.0560, 0.0000,\n",
            "         4.7265, 0.0000, 2.7451, 0.0000, 0.0000, 0.0000, 1.3057, 0.0000, 3.0634,\n",
            "         0.0000, 3.4568, 0.0000, 0.3908, 0.7857, 0.0000, 2.3949, 0.0000, 0.0000,\n",
            "         5.7395, 7.5217, 3.2352, 5.3514, 2.4457, 4.2640, 5.1772, 5.7241, 0.0000,\n",
            "         1.1636, 1.4478, 0.0000, 5.9877, 0.0000, 9.2929, 2.3271, 0.0000, 1.5782,\n",
            "         2.3591, 0.0000, 5.8757, 0.0000, 4.3176, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 7.8337, 0.0000, 7.0972],\n",
            "        [0.0000, 2.1403, 2.7574, 3.1891, 0.6889, 0.0000, 0.0000, 0.7290, 0.0000,\n",
            "         0.0000, 3.6120, 2.0095, 2.7875, 0.0000, 1.1521, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 4.2856, 0.0000, 0.0000, 3.9817, 5.4366, 4.0516, 5.6146, 1.6320,\n",
            "         4.3725, 0.0000, 5.0449, 0.0000, 2.2989, 1.5321, 1.5224, 3.7214, 3.0678,\n",
            "         2.2937, 4.0770, 4.8616, 0.0000, 1.2306, 3.9457, 0.0000, 0.0000, 4.7960,\n",
            "         1.5915, 0.0000, 4.4896, 0.0000, 0.0000, 0.8039, 0.0000, 5.9451, 3.0315,\n",
            "         0.0000, 0.0000, 3.9560, 0.0408, 4.6903, 0.0000, 5.3427, 1.6816, 3.9962,\n",
            "         2.7691, 1.7211, 1.2481, 0.0000, 0.9989, 0.0000, 0.0000, 0.0000, 2.0908,\n",
            "         0.0000, 0.0000, 1.5098, 0.0000, 1.7786, 0.0000, 3.3627, 0.2239, 5.4924,\n",
            "         2.6400, 0.0000, 5.1055, 0.0000, 4.8873, 0.8744, 6.3442, 0.0000, 0.0000,\n",
            "         0.0000, 2.2639, 0.0000, 4.8251, 0.0000, 4.6100, 0.0000, 0.5739, 3.3848,\n",
            "         0.0000, 0.0000, 4.4575, 0.0000, 5.5665, 3.2296, 0.0000, 0.3624, 0.0000,\n",
            "         2.6127, 5.0969, 0.0000, 0.0000, 0.0000, 2.0557, 4.5787, 5.5866, 0.0000,\n",
            "         0.0000, 0.0000, 2.7850, 0.0000, 3.4922, 0.0000, 5.4663, 3.5831, 0.0000,\n",
            "         0.0000, 0.1548, 4.8778, 4.2385, 0.0000, 2.3422, 2.7041, 0.0000, 0.0000,\n",
            "         0.0000, 2.9857, 1.7821, 3.3580, 1.3167, 0.0000, 0.0000, 3.8082, 0.0000,\n",
            "         1.1992, 2.3695, 0.0000, 6.8062, 3.7643, 1.2150, 0.0000, 7.7381, 0.0000,\n",
            "         4.7734, 0.0000, 0.0000, 0.0000, 4.6761, 2.0688, 4.4484, 0.0000, 2.1179,\n",
            "         0.0000, 4.1214, 3.3340, 0.2307, 3.7253, 0.0000, 4.3365, 0.0000, 0.0000,\n",
            "         0.0000, 4.7626, 0.0000, 0.0000, 3.5799, 6.6749, 0.0000, 6.1963, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 2.3068, 0.0000, 2.4423,\n",
            "         0.0000, 0.0000, 0.6675, 0.0000, 0.0000, 0.0000, 0.0142, 0.0000, 0.0000,\n",
            "         0.0000, 2.1728, 3.7333, 2.9715, 0.0000, 3.0009, 5.1695, 4.0455, 0.0000,\n",
            "         4.4799, 0.0000, 2.7574, 0.0000, 0.0000, 0.0000, 1.4092, 0.0000, 2.9719,\n",
            "         0.0000, 3.3883, 0.1130, 0.4069, 0.6608, 0.0000, 2.4001, 0.0000, 0.0000,\n",
            "         5.1841, 7.0894, 2.9401, 4.7875, 2.0672, 3.8235, 4.7781, 5.3345, 0.0000,\n",
            "         1.2442, 1.6086, 0.0000, 5.7110, 0.0000, 8.7588, 2.1620, 0.0000, 1.2559,\n",
            "         2.1480, 0.0000, 5.7359, 0.0000, 3.8990, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 7.6189, 0.0000, 6.6132],\n",
            "        [0.0000, 2.4992, 3.0975, 3.8165, 0.3745, 0.0000, 0.0000, 0.8560, 0.0000,\n",
            "         0.0000, 4.1685, 2.3566, 2.8907, 0.0000, 0.9109, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 4.5222, 0.0000, 0.0000, 4.2431, 6.0669, 4.2526, 5.9305, 2.1811,\n",
            "         4.9124, 0.0000, 5.3897, 0.0000, 2.5679, 1.6152, 1.8050, 3.8928, 3.1525,\n",
            "         2.8796, 4.3589, 5.3130, 0.0000, 1.0652, 4.3393, 0.0000, 0.0000, 5.0624,\n",
            "         1.6549, 0.0000, 4.8294, 0.0000, 0.0000, 0.9258, 0.0000, 6.2779, 3.4854,\n",
            "         0.0000, 0.0000, 4.2267, 0.0902, 4.8619, 0.0000, 5.7190, 1.3797, 4.3398,\n",
            "         2.8875, 2.0979, 1.2242, 0.0000, 0.7881, 0.0000, 0.0000, 0.0000, 2.4566,\n",
            "         0.0000, 0.0193, 1.6061, 0.0000, 1.7822, 0.0000, 3.8471, 0.2403, 5.6836,\n",
            "         2.5669, 0.0000, 5.6354, 0.0000, 5.2781, 0.7043, 6.8324, 0.0000, 0.0000,\n",
            "         0.0000, 2.6991, 0.0000, 5.2570, 0.0000, 5.0496, 0.0000, 0.7926, 3.7606,\n",
            "         0.0000, 0.0000, 4.9886, 0.0000, 5.9994, 3.4220, 0.0000, 0.4751, 0.0000,\n",
            "         2.5034, 5.3253, 0.0000, 0.0000, 0.0000, 2.2693, 4.5814, 5.7527, 0.0000,\n",
            "         0.0000, 0.0000, 2.8459, 0.0000, 3.4532, 0.0000, 5.5975, 3.6309, 0.0000,\n",
            "         0.0000, 0.0000, 5.2331, 4.6586, 0.0000, 2.4519, 2.9254, 0.0000, 0.0000,\n",
            "         0.0000, 3.3680, 2.1134, 3.6472, 1.5232, 0.0000, 0.0000, 3.8984, 0.0000,\n",
            "         1.1995, 2.7353, 0.0000, 7.3031, 3.9253, 1.5120, 0.0000, 8.0641, 0.0000,\n",
            "         5.3342, 0.0000, 0.0000, 0.0000, 5.0172, 2.0618, 5.0252, 0.0000, 2.5331,\n",
            "         0.0000, 4.4756, 3.2232, 0.0329, 3.8024, 0.0000, 4.7349, 0.0000, 0.0629,\n",
            "         0.0000, 4.9790, 0.0000, 0.0000, 3.8829, 7.1353, 0.0000, 6.7173, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 2.4304, 0.0000, 2.6660,\n",
            "         0.0000, 0.0000, 1.1190, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 2.5701, 4.0754, 3.2570, 0.0000, 3.2211, 5.6135, 4.0560, 0.0000,\n",
            "         4.7265, 0.0000, 2.7451, 0.0000, 0.0000, 0.0000, 1.3057, 0.0000, 3.0634,\n",
            "         0.0000, 3.4568, 0.0000, 0.3908, 0.7857, 0.0000, 2.3949, 0.0000, 0.0000,\n",
            "         5.7395, 7.5217, 3.2352, 5.3514, 2.4457, 4.2640, 5.1772, 5.7241, 0.0000,\n",
            "         1.1636, 1.4478, 0.0000, 5.9877, 0.0000, 9.2929, 2.3271, 0.0000, 1.5782,\n",
            "         2.3591, 0.0000, 5.8757, 0.0000, 4.3176, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 7.8337, 0.0000, 7.0972]], grad_fn=<ReluBackward0>)\n",
            "x fc_pi output tensor([[ 53.9041, -34.6971,   4.4003, -36.4689],\n",
            "        [ 49.7628, -32.1873,   4.5243, -34.2688],\n",
            "        [ 53.9041, -34.6971,   4.4003, -36.4689]], grad_fn=<AddmmBackward0>)\n",
            "x F.softmax(x, dim=softmax_dim) tensor([[ 53.9041, -34.6971,   4.4003, -36.4689],\n",
            "        [ 49.7628, -32.1873,   4.5243, -34.2688],\n",
            "        [ 53.9041, -34.6971,   4.4003, -36.4689]], grad_fn=<AddmmBackward0>)\n",
            "prob tensor([[1.0000e+00, 3.3190e-39, 3.1678e-22, 5.6427e-40],\n",
            "        [1.0000e+00, 2.5675e-36, 2.2549e-20, 3.2027e-37],\n",
            "        [1.0000e+00, 3.3190e-39, 3.1678e-22, 5.6427e-40]],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "\n",
            "\n",
            "▶▶▶ 3790  : max cum reward :  1887  epsilon = 0.6209900000000418\n",
            "\n",
            "\n",
            "▶▶▶3791번째 에피소드 시작, env 초기화 완료.\n",
            "가져와야 할 아이템 : ['A', 'L', 'N', 'O']\n",
            "\n",
            "현재 state         :  [9 4 5 0]\n",
            "step 데이터 : [9 3 5 0] -100 -100 True False\n",
            "put_data    : [9 4 5 0] 2 -100 [9 3 5 0] True\n",
            "input x tensor([[9., 4., 5., 0.]])\n",
            "x F.relu output tensor([[0.0000, 2.4997, 3.0978, 3.8169, 0.3749, 0.0000, 0.0000, 0.8562, 0.0000,\n",
            "         0.0000, 4.1688, 2.3567, 2.8911, 0.0000, 0.9113, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 4.5223, 0.0000, 0.0000, 4.2439, 6.0672, 4.2527, 5.9309, 2.1813,\n",
            "         4.9128, 0.0000, 5.3907, 0.0000, 2.5683, 1.6152, 1.8048, 3.8929, 3.1529,\n",
            "         2.8798, 4.3594, 5.3135, 0.0000, 1.0660, 4.3401, 0.0000, 0.0000, 5.0627,\n",
            "         1.6553, 0.0000, 4.8295, 0.0000, 0.0000, 0.9257, 0.0000, 6.2782, 3.4858,\n",
            "         0.0000, 0.0000, 4.2269, 0.0904, 4.8624, 0.0000, 5.7197, 1.3802, 4.3401,\n",
            "         2.8877, 2.0979, 1.2242, 0.0000, 0.7880, 0.0000, 0.0000, 0.0000, 2.4568,\n",
            "         0.0000, 0.0190, 1.6061, 0.0000, 1.7827, 0.0000, 3.8474, 0.2405, 5.6838,\n",
            "         2.5681, 0.0000, 5.6355, 0.0000, 5.2787, 0.7045, 6.8324, 0.0000, 0.0000,\n",
            "         0.0000, 2.6999, 0.0000, 5.2572, 0.0000, 5.0501, 0.0000, 0.7926, 3.7608,\n",
            "         0.0000, 0.0000, 4.9890, 0.0000, 6.0002, 3.4223, 0.0000, 0.4751, 0.0000,\n",
            "         2.5037, 5.3258, 0.0000, 0.0000, 0.0000, 2.2693, 4.5818, 5.7528, 0.0000,\n",
            "         0.0000, 0.0000, 2.8462, 0.0000, 3.4536, 0.0000, 5.5981, 3.6311, 0.0000,\n",
            "         0.0000, 0.0000, 5.2335, 4.6593, 0.0000, 2.4520, 2.9258, 0.0000, 0.0000,\n",
            "         0.0000, 3.3683, 2.1136, 3.6478, 1.5231, 0.0000, 0.0000, 3.8990, 0.0000,\n",
            "         1.1996, 2.7355, 0.0000, 7.3034, 3.9256, 1.5122, 0.0000, 8.0647, 0.0000,\n",
            "         5.3345, 0.0000, 0.0000, 0.0000, 5.0177, 2.0620, 5.0255, 0.0000, 2.5334,\n",
            "         0.0000, 4.4761, 3.2236, 0.0328, 3.8028, 0.0000, 4.7353, 0.0000, 0.0633,\n",
            "         0.0000, 4.9792, 0.0000, 0.0000, 3.8832, 7.1354, 0.0000, 6.7174, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 2.4316, 0.0000, 2.6668,\n",
            "         0.0000, 0.0000, 1.1192, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 2.5701, 4.0757, 3.2572, 0.0000, 3.2220, 5.6138, 4.0571, 0.0000,\n",
            "         4.7271, 0.0000, 2.7455, 0.0000, 0.0000, 0.0000, 1.3061, 0.0000, 3.0641,\n",
            "         0.0000, 3.4570, 0.0000, 0.3913, 0.7857, 0.0000, 2.3956, 0.0000, 0.0000,\n",
            "         5.7397, 7.5222, 3.2356, 5.3520, 2.4462, 4.2645, 5.1776, 5.7250, 0.0000,\n",
            "         1.1635, 1.4479, 0.0000, 5.9878, 0.0000, 9.2936, 2.3275, 0.0000, 1.5783,\n",
            "         2.3600, 0.0000, 5.8765, 0.0000, 4.3180, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 7.8344, 0.0000, 7.0976]], grad_fn=<ReluBackward0>)\n",
            "x fc_pi output tensor([[ 53.9135, -34.7091,   4.4126, -36.4863]], grad_fn=<AddmmBackward0>)\n",
            "x F.softmax(x, dim=softmax_dim) tensor([[ 53.9135, -34.7091,   4.4126, -36.4863]], grad_fn=<AddmmBackward0>)\n",
            "prob tensor([[1.0000e+00, 3.2488e-39, 3.1772e-22, 5.4942e-40]],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "\n",
            "\n",
            "▶▶▶ 3791  : max cum reward :  1887  epsilon = 0.6208900000000418\n",
            "\n",
            "\n",
            "▶▶▶3792번째 에피소드 시작, env 초기화 완료.\n",
            "가져와야 할 아이템 : ['C', 'I', 'N', 'P']\n",
            "\n",
            "현재 state         :  [9 4 3 0]\n",
            "step 데이터 : [9 3 3 0] -100 -100 True False\n",
            "put_data    : [9 4 3 0] 2 -100 [9 3 3 0] True\n",
            "input x tensor([[9., 4., 3., 0.]])\n",
            "x F.relu output tensor([[0.0000, 3.1382, 3.7048, 4.0686, 0.0000, 0.1454, 0.0000, 1.3898, 0.0000,\n",
            "         0.0000, 4.0830, 3.0171, 2.7954, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 4.1840, 0.0000, 0.0000, 3.8271, 5.8963, 3.3674, 5.1785, 2.9327,\n",
            "         5.1265, 0.0000, 4.2683, 0.0000, 3.0461, 1.4414, 2.6887, 4.0947, 2.7850,\n",
            "         3.7041, 3.2446, 5.0906, 0.0000, 0.4133, 3.9051, 0.0000, 0.0000, 4.6017,\n",
            "         1.6107, 0.0000, 4.1229, 0.0000, 0.0000, 1.6965, 0.0000, 5.3042, 4.1763,\n",
            "         0.0000, 0.0000, 3.6058, 0.2226, 4.1704, 0.0000, 5.6338, 0.3256, 3.4042,\n",
            "         2.6350, 2.3913, 0.4333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 2.8984,\n",
            "         0.0000, 0.5350, 1.6240, 0.0000, 1.9726, 0.0000, 4.3249, 0.0000, 4.8713,\n",
            "         1.6310, 0.0000, 5.3966, 0.0000, 4.4004, 0.1635, 6.6111, 0.0000, 0.0000,\n",
            "         0.0000, 3.0917, 0.0000, 5.5321, 0.0000, 4.1978, 0.0000, 1.0515, 3.4320,\n",
            "         0.0000, 0.0000, 5.4885, 0.2987, 5.7600, 3.5896, 0.0000, 1.0489, 0.0000,\n",
            "         1.4834, 4.9450, 0.0000, 0.1488, 0.0000, 2.8084, 3.7077, 4.9249, 0.0000,\n",
            "         0.0000, 0.0000, 2.9301, 0.0000, 2.6330, 0.0000, 4.5598, 2.6477, 0.0000,\n",
            "         0.0000, 0.0000, 5.2723, 5.1997, 0.0000, 2.2424, 2.9858, 0.0000, 0.0000,\n",
            "         0.0000, 3.4747, 2.1568, 3.8366, 1.1192, 0.0000, 0.0000, 3.3320, 0.0000,\n",
            "         1.3894, 2.8854, 0.0000, 7.0281, 3.3345, 1.7157, 0.0000, 6.9229, 0.0992,\n",
            "         5.3458, 0.0000, 0.0000, 0.0000, 4.7980, 1.8305, 5.7801, 0.0000, 2.7974,\n",
            "         0.0000, 3.8948, 2.6796, 0.0000, 3.0751, 0.0000, 5.3494, 0.0000, 0.7835,\n",
            "         0.0000, 4.5804, 0.0000, 0.0000, 3.9969, 6.8550, 0.0000, 6.2288, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.8318, 0.0000, 3.0243,\n",
            "         0.0000, 0.0000, 1.7831, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 3.1265, 3.3097, 3.6701, 0.0000, 3.2209, 5.7780, 3.0087, 0.0000,\n",
            "         3.6816, 0.0000, 1.7237, 0.0000, 0.0000, 0.0569, 1.0582, 0.0000, 2.5129,\n",
            "         0.0000, 3.0960, 0.0000, 0.9986, 1.6531, 0.0000, 1.5503, 0.0000, 0.0000,\n",
            "         5.2400, 6.4028, 3.3766, 5.1271, 2.6034, 4.9482, 4.4444, 5.6036, 0.0000,\n",
            "         0.2712, 0.4633, 0.0000, 5.4414, 0.0000, 8.1825, 2.2520, 0.0000, 2.0814,\n",
            "         1.9928, 0.0000, 4.7328, 0.0000, 3.5347, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 6.6003, 0.0000, 6.8715]], grad_fn=<ReluBackward0>)\n",
            "x fc_pi output tensor([[ 52.4054, -33.2218,   2.8543, -33.1295]], grad_fn=<AddmmBackward0>)\n",
            "x F.softmax(x, dim=softmax_dim) tensor([[ 52.4054, -33.2218,   2.8543, -33.1295]], grad_fn=<AddmmBackward0>)\n",
            "prob tensor([[1.0000e+00, 6.4947e-38, 3.0216e-22, 7.1230e-38]],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "\n",
            "\n",
            "▶▶▶ 3792  : max cum reward :  1887  epsilon = 0.6207900000000418\n",
            "\n",
            "\n",
            "▶▶▶3793번째 에피소드 시작, env 초기화 완료.\n",
            "가져와야 할 아이템 : ['D', 'F', 'N', 'O']\n",
            "\n",
            "현재 state         :  [9 4 2 0]\n",
            "step 데이터 : [9 5 2 0] -100 -100 True False\n",
            "put_data    : [9 4 2 0] 3 -100 [9 5 2 0] True\n",
            "input x tensor([[9., 4., 2., 0.]])\n",
            "x F.relu output tensor([[0.0000, 3.4580, 4.0086, 4.1948, 0.0000, 0.3303, 0.0000, 1.6573, 0.0000,\n",
            "         0.0000, 4.0406, 3.3478, 2.7480, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 4.0152, 0.0000, 0.0000, 3.6190, 5.8113, 2.9251, 4.8027, 3.3087,\n",
            "         5.2338, 0.0000, 3.7074, 0.0000, 3.2853, 1.3548, 3.1311, 4.1960, 2.6014,\n",
            "         4.1166, 2.6874, 4.9795, 0.0000, 0.0867, 3.6880, 0.0000, 0.0000, 4.3716,\n",
            "         1.5885, 0.0000, 3.7699, 0.0000, 0.0000, 2.0823, 0.0000, 4.8175, 4.5220,\n",
            "         0.0000, 0.0000, 3.2956, 0.2892, 3.8248, 0.0000, 5.5912, 0.0000, 2.9366,\n",
            "         2.5089, 2.5384, 0.0381, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 3.1195,\n",
            "         0.0000, 0.7937, 1.6333, 0.0000, 2.0678, 0.0000, 4.5640, 0.0000, 4.4654,\n",
            "         1.1624, 0.0000, 5.2775, 0.0000, 3.9616, 0.0000, 6.5007, 0.0000, 0.0000,\n",
            "         0.0000, 3.2879, 0.0000, 5.6699, 0.0000, 3.7720, 0.0000, 1.1814, 3.2680,\n",
            "         0.0688, 0.0000, 5.7386, 0.4560, 5.6404, 3.6736, 0.0000, 1.3364, 0.0000,\n",
            "         0.9734, 4.7547, 0.0000, 0.5018, 0.0000, 3.0783, 3.2710, 4.5112, 0.0000,\n",
            "         0.0000, 0.0000, 2.9725, 0.0000, 2.2231, 0.0000, 4.0408, 2.1564, 0.0000,\n",
            "         0.0000, 0.0000, 5.2921, 5.4703, 0.0000, 2.1379, 3.0162, 0.0000, 0.0000,\n",
            "         0.0000, 3.5283, 2.1787, 3.9313, 0.9172, 0.0000, 0.0000, 3.0487, 0.0000,\n",
            "         1.4846, 2.9608, 0.0000, 6.8906, 3.0394, 1.8179, 0.0000, 6.3524, 0.3855,\n",
            "         5.3518, 0.0000, 0.0000, 0.0000, 4.6886, 1.7150, 6.1578, 0.0000, 2.9299,\n",
            "         0.0000, 3.6045, 2.4079, 0.0000, 2.7115, 0.0000, 5.6568, 0.0000, 1.1441,\n",
            "         0.0000, 4.3813, 0.0000, 0.0000, 4.0542, 6.7151, 0.0000, 5.9848, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.5320, 0.0000, 3.2033,\n",
            "         0.0000, 0.0000, 2.1154, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 3.4052, 2.9272, 3.8769, 0.0000, 3.2205, 5.8605, 2.4846, 0.0000,\n",
            "         3.1591, 0.0000, 1.2131, 0.0000, 0.0000, 0.5696, 0.9344, 0.0000, 2.2376,\n",
            "         0.0000, 2.9157, 0.0000, 1.3028, 2.0872, 0.0000, 1.1276, 0.0000, 0.0000,\n",
            "         4.9905, 5.8434, 3.4475, 5.0150, 2.6825, 5.2905, 4.0781, 5.5432, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 5.1685, 0.0000, 7.6273, 2.2146, 0.0000, 2.3333,\n",
            "         1.8096, 0.0000, 4.1613, 0.0000, 3.1434, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 5.9836, 0.0000, 6.7589]], grad_fn=<ReluBackward0>)\n",
            "x fc_pi output tensor([[ 51.6659, -32.5404,   2.1065, -31.5248]], grad_fn=<AddmmBackward0>)\n",
            "x F.softmax(x, dim=softmax_dim) tensor([[ 51.6659, -32.5404,   2.1065, -31.5248]], grad_fn=<AddmmBackward0>)\n",
            "prob tensor([[1.0000e+00, 2.6894e-37, 2.9964e-22, 7.4255e-37]],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "\n",
            "\n",
            "▶▶▶ 3793  : max cum reward :  1887  epsilon = 0.6206900000000418\n",
            "\n",
            "\n",
            "▶▶▶3794번째 에피소드 시작, env 초기화 완료.\n",
            "가져와야 할 아이템 : ['D', 'H', 'I', 'J', 'K']\n",
            "\n",
            "현재 state         :  [9 4 2 0]\n",
            "step 데이터 : [10  4  2  0] -100 -100 True False\n",
            "put_data    : [9 4 2 0] 1 -100 [10  4  2  0] True\n",
            "input x tensor([[9., 4., 2., 0.]])\n",
            "x F.relu output tensor([[0.0000, 3.4592, 4.0095, 4.1958, 0.0000, 0.3310, 0.0000, 1.6583, 0.0000,\n",
            "         0.0000, 4.0414, 3.3487, 2.7490, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 4.0161, 0.0000, 0.0000, 3.6202, 5.8123, 2.9260, 4.8036, 3.3097,\n",
            "         5.2350, 0.0000, 3.7084, 0.0000, 3.2861, 1.3554, 3.1319, 4.1968, 2.6024,\n",
            "         4.1175, 2.6885, 4.9807, 0.0000, 0.0866, 3.6892, 0.0000, 0.0000, 4.3725,\n",
            "         1.5894, 0.0000, 3.7707, 0.0000, 0.0000, 2.0829, 0.0000, 4.8184, 4.5230,\n",
            "         0.0000, 0.0000, 3.2965, 0.2904, 3.8258, 0.0000, 5.5921, 0.0000, 2.9377,\n",
            "         2.5099, 2.5392, 0.0389, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 3.1204,\n",
            "         0.0000, 0.7945, 1.6341, 0.0000, 2.0687, 0.0000, 4.5648, 0.0000, 4.4664,\n",
            "         1.1633, 0.0000, 5.2783, 0.0000, 3.9627, 0.0000, 6.5017, 0.0000, 0.0000,\n",
            "         0.0000, 3.2891, 0.0000, 5.6708, 0.0000, 3.7728, 0.0000, 1.1823, 3.2690,\n",
            "         0.0684, 0.0000, 5.7396, 0.4563, 5.6415, 3.6745, 0.0000, 1.3374, 0.0000,\n",
            "         0.9744, 4.7554, 0.0000, 0.5029, 0.0000, 3.0791, 3.2720, 4.5120, 0.0000,\n",
            "         0.0000, 0.0000, 2.9734, 0.0000, 2.2240, 0.0000, 4.0418, 2.1573, 0.0000,\n",
            "         0.0000, 0.0000, 5.2930, 5.4714, 0.0000, 2.1388, 3.0173, 0.0000, 0.0000,\n",
            "         0.0000, 3.5292, 2.1797, 3.9324, 0.9176, 0.0000, 0.0000, 3.0498, 0.0000,\n",
            "         1.4855, 2.9617, 0.0000, 6.8915, 3.0404, 1.8190, 0.0000, 6.3535, 0.3853,\n",
            "         5.3527, 0.0000, 0.0000, 0.0000, 4.6896, 1.7159, 6.1588, 0.0000, 2.9310,\n",
            "         0.0000, 3.6056, 2.4087, 0.0000, 2.7124, 0.0000, 5.6578, 0.0000, 1.1455,\n",
            "         0.0000, 4.3821, 0.0000, 0.0000, 4.0550, 6.7159, 0.0000, 5.9858, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.5330, 0.0000, 3.2042,\n",
            "         0.0000, 0.0000, 2.1163, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 3.4060, 2.9282, 3.8779, 0.0000, 3.2216, 5.8614, 2.4855, 0.0000,\n",
            "         3.1602, 0.0000, 1.2141, 0.0000, 0.0000, 0.5693, 0.9353, 0.0000, 2.2388,\n",
            "         0.0000, 2.9166, 0.0000, 1.3040, 2.0881, 0.0000, 1.1282, 0.0000, 0.0000,\n",
            "         4.9914, 5.8442, 3.4485, 5.0158, 2.6836, 5.2915, 4.0791, 5.5443, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 5.1694, 0.0000, 7.6285, 2.2156, 0.0000, 2.3343,\n",
            "         1.8107, 0.0000, 4.1625, 0.0000, 3.1443, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 5.9847, 0.0000, 6.7599]], grad_fn=<ReluBackward0>)\n",
            "x fc_pi output tensor([[ 51.7036, -32.5549,   2.0991, -31.5597]], grad_fn=<AddmmBackward0>)\n",
            "x F.softmax(x, dim=softmax_dim) tensor([[ 51.7036, -32.5549,   2.0991, -31.5597]], grad_fn=<AddmmBackward0>)\n",
            "prob tensor([[1.0000e+00, 2.5529e-37, 2.8646e-22, 6.9064e-37]],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "\n",
            "\n",
            "▶▶▶ 3794  : max cum reward :  1887  epsilon = 0.6205900000000418\n",
            "\n",
            "\n",
            "▶▶▶3795번째 에피소드 시작, env 초기화 완료.\n",
            "가져와야 할 아이템 : ['B', 'C', 'F', 'J', 'M', 'Q']\n",
            "\n",
            "현재 state         :  [9 4 4 0]\n",
            "step 데이터 : [9 5 4 0] -100 -100 True False\n",
            "put_data    : [9 4 4 0] 3 -100 [9 5 4 0] True\n",
            "input x tensor([[9., 4., 4., 0.]])\n",
            "x F.relu output tensor([[0.0000e+00, 2.8232e+00, 3.4042e+00, 3.9459e+00, 6.5569e-03, 0.0000e+00,\n",
            "         0.0000e+00, 1.1265e+00, 0.0000e+00, 0.0000e+00, 4.1288e+00, 2.6898e+00,\n",
            "         2.8466e+00, 0.0000e+00, 4.2055e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "         0.0000e+00, 4.3559e+00, 0.0000e+00, 0.0000e+00, 4.0393e+00, 5.9849e+00,\n",
            "         3.8128e+00, 5.5578e+00, 2.5602e+00, 5.0234e+00, 0.0000e+00, 4.8328e+00,\n",
            "         0.0000e+00, 2.8100e+00, 1.5305e+00, 2.2493e+00, 3.9964e+00, 2.9721e+00,\n",
            "         3.2948e+00, 3.8052e+00, 5.2057e+00, 0.0000e+00, 7.3963e-01, 4.1266e+00,\n",
            "         0.0000e+00, 0.0000e+00, 4.8351e+00, 1.6356e+00, 0.0000e+00, 4.4787e+00,\n",
            "         0.0000e+00, 0.0000e+00, 1.3132e+00, 0.0000e+00, 5.7940e+00, 3.8343e+00,\n",
            "         0.0000e+00, 0.0000e+00, 3.9192e+00, 1.6036e-01, 4.5197e+00, 0.0000e+00,\n",
            "         5.6800e+00, 8.5362e-01, 3.8754e+00, 2.7643e+00, 2.2472e+00, 8.3128e-01,\n",
            "         0.0000e+00, 3.4905e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.6805e+00,\n",
            "         0.0000e+00, 2.7971e-01, 1.6174e+00, 0.0000e+00, 1.8807e+00, 0.0000e+00,\n",
            "         4.0891e+00, 6.4065e-02, 5.2805e+00, 2.1023e+00, 0.0000e+00, 5.5187e+00,\n",
            "         0.0000e+00, 4.8429e+00, 4.3466e-01, 6.7245e+00, 0.0000e+00, 0.0000e+00,\n",
            "         0.0000e+00, 2.8996e+00, 0.0000e+00, 5.3975e+00, 0.0000e+00, 4.6270e+00,\n",
            "         0.0000e+00, 9.2487e-01, 3.5995e+00, 0.0000e+00, 0.0000e+00, 5.2419e+00,\n",
            "         1.4285e-01, 5.8841e+00, 3.5090e+00, 0.0000e+00, 7.6542e-01, 0.0000e+00,\n",
            "         1.9964e+00, 5.1377e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.5414e+00,\n",
            "         4.1479e+00, 5.3415e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.8910e+00,\n",
            "         0.0000e+00, 3.0464e+00, 0.0000e+00, 5.0820e+00, 3.1425e+00, 0.0000e+00,\n",
            "         0.0000e+00, 0.0000e+00, 5.2562e+00, 4.9335e+00, 0.0000e+00, 2.3499e+00,\n",
            "         2.9592e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.4246e+00, 2.1381e+00,\n",
            "         3.7458e+00, 1.3223e+00, 0.0000e+00, 0.0000e+00, 3.6190e+00, 0.0000e+00,\n",
            "         1.2973e+00, 2.8133e+00, 0.0000e+00, 7.1686e+00, 3.6333e+00, 1.6171e+00,\n",
            "         0.0000e+00, 7.4973e+00, 0.0000e+00, 5.3432e+00, 0.0000e+00, 0.0000e+00,\n",
            "         0.0000e+00, 4.9113e+00, 1.9491e+00, 5.4059e+00, 0.0000e+00, 2.6689e+00,\n",
            "         0.0000e+00, 4.1891e+00, 2.9545e+00, 0.0000e+00, 3.4420e+00, 0.0000e+00,\n",
            "         5.0455e+00, 0.0000e+00, 4.2814e-01, 0.0000e+00, 4.7825e+00, 0.0000e+00,\n",
            "         0.0000e+00, 3.9430e+00, 6.9977e+00, 0.0000e+00, 6.4761e+00, 0.0000e+00,\n",
            "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "         2.1351e+00, 0.0000e+00, 2.8486e+00, 0.0000e+00, 0.0000e+00, 1.4541e+00,\n",
            "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "         0.0000e+00, 2.8509e+00, 3.6958e+00, 3.4667e+00, 0.0000e+00, 3.2252e+00,\n",
            "         5.6989e+00, 3.5360e+00, 0.0000e+00, 4.2078e+00, 0.0000e+00, 2.2378e+00,\n",
            "         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.1848e+00, 0.0000e+00, 2.7921e+00,\n",
            "         0.0000e+00, 3.2794e+00, 0.0000e+00, 6.9897e-01, 1.2221e+00, 0.0000e+00,\n",
            "         1.9747e+00, 0.0000e+00, 0.0000e+00, 5.4926e+00, 6.9654e+00, 3.3093e+00,\n",
            "         5.2428e+00, 2.5284e+00, 4.6098e+00, 4.8142e+00, 5.6683e+00, 0.0000e+00,\n",
            "         7.1840e-01, 9.5649e-01, 0.0000e+00, 5.7173e+00, 0.0000e+00, 8.7418e+00,\n",
            "         2.2929e+00, 0.0000e+00, 1.8329e+00, 2.1801e+00, 0.0000e+00, 5.3085e+00,\n",
            "         0.0000e+00, 3.9294e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "         0.0000e+00, 7.2209e+00, 0.0000e+00, 6.9880e+00]],\n",
            "       grad_fn=<ReluBackward0>)\n",
            "x fc_pi output tensor([[ 53.2797, -34.0209,   3.6025, -34.8972]], grad_fn=<AddmmBackward0>)\n",
            "x F.softmax(x, dim=softmax_dim) tensor([[ 53.2797, -34.0209,   3.6025, -34.8972]], grad_fn=<AddmmBackward0>)\n",
            "prob tensor([[1.0000e+00, 1.2185e-38, 2.6635e-22, 5.0728e-39]],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "\n",
            "\n",
            "▶▶▶ 3795  : max cum reward :  1887  epsilon = 0.6204900000000418\n",
            "\n",
            "\n",
            "▶▶▶3796번째 에피소드 시작, env 초기화 완료.\n",
            "가져와야 할 아이템 : ['A', 'B', 'E', 'F', 'H', 'J']\n",
            "\n",
            "현재 state         :  [9 4 5 0]\n",
            "step 데이터 : [10  4  5  0] -100 -100 True False\n",
            "put_data    : [9 4 5 0] 1 -100 [10  4  5  0] True\n",
            "input x tensor([[9., 4., 5., 0.]])\n",
            "x F.relu output tensor([[0.0000, 2.5058, 3.1020, 3.8214, 0.3753, 0.0000, 0.0000, 0.8611, 0.0000,\n",
            "         0.0000, 4.1729, 2.3608, 2.8958, 0.0000, 0.9120, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 4.5263, 0.0000, 0.0000, 4.2493, 6.0718, 4.2565, 5.9353, 2.1860,\n",
            "         4.9182, 0.0000, 5.3954, 0.0000, 2.5723, 1.6185, 1.8084, 3.8965, 3.1575,\n",
            "         2.8839, 4.3640, 5.3187, 0.0000, 1.0660, 4.3459, 0.0000, 0.0000, 5.0668,\n",
            "         1.6591, 0.0000, 4.8331, 0.0000, 0.0000, 0.9288, 0.0000, 6.2822, 3.4904,\n",
            "         0.0000, 0.0000, 4.2309, 0.0959, 4.8672, 0.0000, 5.7244, 1.3812, 4.3446,\n",
            "         2.8919, 2.1016, 1.2278, 0.0000, 0.7881, 0.0000, 0.0000, 0.0000, 2.4610,\n",
            "         0.0000, 0.0228, 1.6095, 0.0000, 1.7873, 0.0000, 3.8518, 0.2411, 5.6880,\n",
            "         2.5722, 0.0000, 5.6393, 0.0000, 5.2834, 0.7054, 6.8363, 0.0000, 0.0000,\n",
            "         0.0000, 2.7055, 0.0000, 5.2613, 0.0000, 5.0545, 0.0000, 0.7966, 3.7652,\n",
            "         0.0000, 0.0000, 4.9936, 0.0000, 6.0059, 3.4267, 0.0000, 0.4799, 0.0000,\n",
            "         2.5078, 5.3291, 0.0000, 0.0000, 0.0000, 2.2729, 4.5863, 5.7566, 0.0000,\n",
            "         0.0000, 0.0000, 2.8503, 0.0000, 3.4581, 0.0000, 5.6024, 3.6355, 0.0000,\n",
            "         0.0000, 0.0000, 5.2383, 4.6651, 0.0000, 2.4559, 2.9306, 0.0000, 0.0000,\n",
            "         0.0000, 3.3727, 2.1178, 3.6531, 1.5249, 0.0000, 0.0000, 3.9041, 0.0000,\n",
            "         1.2036, 2.7395, 0.0000, 7.3075, 3.9302, 1.5166, 0.0000, 8.0697, 0.0000,\n",
            "         5.3389, 0.0000, 0.0000, 0.0000, 5.0227, 2.0661, 5.0299, 0.0000, 2.5383,\n",
            "         0.0000, 4.4814, 3.2278, 0.0332, 3.8073, 0.0000, 4.7398, 0.0000, 0.0702,\n",
            "         0.0000, 4.9832, 0.0000, 0.0000, 3.8874, 7.1389, 0.0000, 6.7217, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 2.4366, 0.0000, 2.6714,\n",
            "         0.0000, 0.0000, 1.1235, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 2.5737, 4.0800, 3.2616, 0.0000, 3.2275, 5.6181, 4.0616, 0.0000,\n",
            "         4.7321, 0.0000, 2.7501, 0.0000, 0.0000, 0.0000, 1.3099, 0.0000, 3.0693,\n",
            "         0.0000, 3.4612, 0.0000, 0.3971, 0.7896, 0.0000, 2.3981, 0.0000, 0.0000,\n",
            "         5.7436, 7.5264, 3.2402, 5.3568, 2.4513, 4.2693, 5.1822, 5.7308, 0.0000,\n",
            "         1.1647, 1.4490, 0.0000, 5.9916, 0.0000, 9.2990, 2.3321, 0.0000, 1.5826,\n",
            "         2.3654, 0.0000, 5.8821, 0.0000, 4.3225, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 7.8396, 0.0000, 7.1025]], grad_fn=<ReluBackward0>)\n",
            "x fc_pi output tensor([[ 54.0790, -34.8043,   4.3892, -36.6206]], grad_fn=<AddmmBackward0>)\n",
            "x F.softmax(x, dim=softmax_dim) tensor([[ 54.0790, -34.8043,   4.3892, -36.6206]], grad_fn=<AddmmBackward0>)\n",
            "prob tensor([[1.0000e+00, 2.5030e-39, 2.6302e-22, 4.0705e-40]],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "\n",
            "\n",
            "▶▶▶ 3796  : max cum reward :  1887  epsilon = 0.6203900000000419\n",
            "\n",
            "\n",
            "▶▶▶3797번째 에피소드 시작, env 초기화 완료.\n",
            "가져와야 할 아이템 : ['G', 'N', 'O']\n",
            "\n",
            "현재 state         :  [9 4 0 2]\n",
            "tensor([9, 4, 0, 2])\n",
            "tensor([9., 4., 0., 2.])\n",
            "end input\n",
            "input x tensor([9., 4., 0., 2.])\n",
            "x F.relu output tensor([0.0000, 3.7242, 4.5981, 5.1064, 0.0000, 0.0000, 0.0000, 2.6413, 0.0000,\n",
            "        0.0000, 4.4231, 4.3303, 2.2767, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.5531, 4.1556, 0.0000, 0.0000, 2.5513, 5.9872, 2.9933, 3.3732, 4.3981,\n",
            "        5.8551, 0.0000, 3.2650, 0.0000, 2.8519, 2.0424, 5.0088, 3.6206, 2.6240,\n",
            "        4.7936, 1.5211, 5.3330, 0.0000, 0.0000, 2.6155, 0.0000, 0.0000, 3.0723,\n",
            "        2.2015, 0.0000, 2.2975, 0.0000, 0.0000, 3.5353, 0.0000, 3.4538, 4.2806,\n",
            "        0.0000, 0.0000, 3.5109, 0.0000, 2.4981, 0.0000, 6.4032, 0.0000, 1.7697,\n",
            "        1.9348, 2.8290, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 4.0938,\n",
            "        0.0000, 0.9618, 1.9347, 0.0000, 1.4972, 0.0000, 5.2912, 0.0000, 3.4770,\n",
            "        0.5423, 0.0000, 4.3455, 0.0000, 2.8272, 0.0000, 6.4928, 0.0000, 0.0000,\n",
            "        0.0000, 4.3285, 0.0000, 6.9521, 0.8284, 2.9546, 1.0906, 0.7294, 3.4344,\n",
            "        0.0000, 1.1383, 5.6150, 0.1358, 5.8989, 3.8766, 0.0000, 2.1773, 0.0000,\n",
            "        0.4437, 5.1002, 0.0000, 1.8722, 0.0000, 3.4634, 2.7040, 4.4220, 0.0000,\n",
            "        0.0000, 0.0000, 3.4680, 0.0000, 1.3510, 0.0000, 2.4349, 1.0761, 0.0000,\n",
            "        0.0000, 0.0000, 5.9705, 5.8321, 0.0937, 1.2594, 2.6391, 0.0000, 0.0000,\n",
            "        0.0000, 3.1828, 1.7954, 3.4018, 1.3835, 0.0000, 0.0000, 3.4257, 0.0000,\n",
            "        1.3469, 2.4547, 0.0000, 6.0878, 2.7829, 1.2512, 0.0000, 5.0568, 0.3701,\n",
            "        5.6394, 0.0000, 0.0000, 0.0000, 3.7479, 1.6887, 7.8094, 0.0000, 2.8770,\n",
            "        0.0000, 4.0566, 1.5353, 0.0000, 2.9578, 0.0000, 5.7576, 0.0000, 1.9532,\n",
            "        0.0000, 4.2546, 0.1613, 0.0000, 4.7757, 6.1933, 0.0000, 5.6595, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.3768, 0.0000, 3.0616,\n",
            "        0.0000, 0.0000, 2.3029, 0.0000, 0.0000, 1.0756, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 4.2014, 2.9061, 3.5479, 0.0000, 2.7579, 6.8744, 0.5967, 1.4898,\n",
            "        2.6295, 0.0000, 0.5117, 0.0000, 0.0000, 2.1403, 0.2222, 0.0000, 2.0368,\n",
            "        0.0000, 2.0871, 0.0000, 1.8320, 3.5184, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        4.7727, 4.7526, 4.3339, 4.1648, 2.1670, 6.1633, 2.7144, 4.7213, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 3.8013, 0.0000, 5.9250, 1.2477, 0.0000, 3.2181,\n",
            "        1.4639, 0.8866, 3.7842, 0.0000, 2.0222, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 5.1134, 0.0000, 7.3580], grad_fn=<ReluBackward0>)\n",
            "x fc_pi output tensor([ 50.1907, -31.0507,   0.5280, -28.0062], grad_fn=<AddBackward0>)\n",
            "x F.softmax(x, dim=softmax_dim) tensor([ 50.1907, -31.0507,   0.5280, -28.0062], grad_fn=<AddBackward0>)\n",
            "prob tensor([1.0000e+00, 5.2156e-36, 2.7024e-22, 1.0953e-34],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "step 데이터 : [8 4 0 2] -1 -1 False False\n",
            "put_data    : [9 4 0 2] 0 -1 [8 4 0 2] False\n",
            "step 데이터 : [8 3 0 2] -1 -2 False False\n",
            "put_data    : [8 4 0 2] 2 -1 [8 3 0 2] False\n",
            "tensor([8, 3, 0, 2])\n",
            "tensor([8., 3., 0., 2.])\n",
            "end input\n",
            "input x tensor([8., 3., 0., 2.])\n",
            "x F.relu output tensor([0.0000, 3.0579, 3.7912, 4.8117, 0.0000, 0.0093, 0.0000, 2.3187, 0.0000,\n",
            "        0.0000, 4.1305, 3.6809, 1.6561, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.6950, 3.4658, 0.0000, 0.0000, 2.1758, 5.3583, 2.6438, 2.8979, 4.2072,\n",
            "        5.1683, 0.0000, 3.1471, 0.0000, 2.1592, 1.8875, 4.4718, 2.8816, 2.3069,\n",
            "        4.2524, 1.4147, 4.6784, 0.0000, 0.0000, 2.3336, 0.0000, 0.0000, 2.3170,\n",
            "        1.9846, 0.0000, 1.8640, 0.0000, 0.0000, 3.0628, 0.0000, 2.8499, 3.4915,\n",
            "        0.0000, 0.0000, 3.1664, 0.0000, 1.8807, 0.0000, 5.5487, 0.0000, 1.6562,\n",
            "        1.5714, 2.5940, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 3.5820,\n",
            "        0.0000, 1.1131, 1.6920, 0.0000, 0.9036, 0.0000, 4.6006, 0.0000, 2.8848,\n",
            "        0.3973, 0.0393, 3.7394, 0.0000, 2.4906, 0.0000, 5.5223, 0.0000, 0.0000,\n",
            "        0.0000, 3.8742, 0.0000, 6.0406, 1.0255, 2.6826, 0.8172, 0.7770, 3.2323,\n",
            "        0.0000, 0.8977, 4.6957, 0.0000, 5.1907, 3.1488, 0.0000, 1.8065, 0.0000,\n",
            "        0.2432, 4.3950, 0.0000, 1.7713, 0.0000, 2.9096, 2.2035, 3.7955, 0.0000,\n",
            "        0.0000, 0.0000, 2.9298, 0.0221, 1.0925, 0.0000, 1.9835, 0.9851, 0.0000,\n",
            "        0.0000, 0.0000, 5.2154, 4.8515, 0.0000, 0.8554, 2.2347, 0.0000, 0.0000,\n",
            "        0.0000, 2.8413, 1.6013, 2.6631, 1.6274, 0.0000, 0.0000, 2.9451, 0.0000,\n",
            "        1.0555, 2.2238, 0.0000, 5.1240, 2.3243, 1.0778, 0.0000, 4.2720, 0.0000,\n",
            "        5.0876, 0.0000, 0.0000, 0.0000, 2.9810, 1.3041, 6.7623, 0.0000, 2.6231,\n",
            "        0.0000, 3.7227, 1.0781, 0.0000, 2.4795, 0.0000, 4.8006, 0.0000, 1.6563,\n",
            "        0.0000, 3.5107, 0.1409, 0.0000, 4.0255, 5.2986, 0.0000, 4.9564, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.2161, 0.0000, 2.5303,\n",
            "        0.0000, 0.0000, 2.2365, 0.0166, 0.0000, 0.9918, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 3.7979, 2.7083, 2.7894, 0.0000, 2.1631, 5.9549, 0.2542, 1.3488,\n",
            "        2.5537, 0.0000, 0.5476, 0.0000, 0.0000, 1.7154, 0.0194, 0.0000, 1.7082,\n",
            "        0.0000, 1.6331, 0.0000, 1.3541, 3.0705, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        4.3648, 4.0181, 3.7746, 3.7348, 1.9554, 5.2049, 2.3596, 3.8216, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 3.1375, 0.0000, 5.0740, 0.9459, 0.0000, 2.9939,\n",
            "        1.3831, 0.9900, 3.1964, 0.0000, 1.8826, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 4.3419, 0.0000, 6.3521], grad_fn=<ReluBackward0>)\n",
            "x fc_pi output tensor([ 43.1457, -26.6304,   0.2604, -23.9614], grad_fn=<AddBackward0>)\n",
            "x F.softmax(x, dim=softmax_dim) tensor([ 43.1457, -26.6304,   0.2604, -23.9614], grad_fn=<AddBackward0>)\n",
            "prob tensor([1.0000e+00, 4.9733e-31, 2.3723e-19, 7.1742e-30],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "step 데이터 : [7 3 0 2] -1 -3 False False\n",
            "put_data    : [8 3 0 2] 0 -1 [7 3 0 2] False\n",
            "step 데이터 : [7 4 0 2] -1 -4 False False\n",
            "put_data    : [7 3 0 2] 3 -1 [7 4 0 2] False\n",
            "step 데이터 : [6 4 0 2] -100 -104 True False\n",
            "put_data    : [7 4 0 2] 0 -100 [6 4 0 2] True\n",
            "input x tensor([[9., 4., 0., 2.],\n",
            "        [8., 4., 0., 2.],\n",
            "        [8., 3., 0., 2.],\n",
            "        [7., 3., 0., 2.],\n",
            "        [7., 4., 0., 2.]])\n",
            "x F.relu output tensor([[0.0000, 3.7242, 4.5981,  ..., 5.1134, 0.0000, 7.3580],\n",
            "        [0.0000, 3.3649, 4.2576,  ..., 4.8981, 0.0000, 6.8736],\n",
            "        [0.0000, 3.0579, 3.7912,  ..., 4.3419, 0.0000, 6.3521],\n",
            "        [0.0000, 2.6986, 3.4508,  ..., 4.1267, 0.0000, 5.8677],\n",
            "        [0.0000, 3.0056, 3.9172,  ..., 4.6829, 0.0000, 6.3893]],\n",
            "       grad_fn=<ReluBackward0>)\n",
            "x fc_pi output tensor([[ 50.1907, -31.0507,   0.5280, -28.0062],\n",
            "        [ 46.0206, -28.4878,   0.6252, -25.6685],\n",
            "        [ 43.1457, -26.6304,   0.2604, -23.9614],\n",
            "        [ 38.9843, -24.0702,   0.3608, -21.6266],\n",
            "        [ 41.8525, -25.9299,   0.7203, -23.3267]], grad_fn=<AddmmBackward0>)\n",
            "x F.softmax(x, dim=softmax_dim) tensor([[ 50.1907, -31.0507,   0.5280, -28.0062],\n",
            "        [ 46.0206, -28.4878,   0.6252, -25.6685],\n",
            "        [ 43.1457, -26.6304,   0.2604, -23.9614],\n",
            "        [ 38.9843, -24.0702,   0.3608, -21.6266],\n",
            "        [ 41.8525, -25.9299,   0.7203, -23.3267]], grad_fn=<AddmmBackward0>)\n",
            "prob tensor([[1.0000e+00, 5.2156e-36, 2.7024e-22, 1.0953e-34],\n",
            "        [1.0000e+00, 4.3794e-33, 1.9276e-20, 7.3422e-32],\n",
            "        [1.0000e+00, 4.9734e-31, 2.3724e-19, 7.1743e-30],\n",
            "        [1.0000e+00, 4.1286e-28, 1.6828e-17, 4.7535e-27],\n",
            "        [1.0000e+00, 3.6515e-30, 1.3692e-18, 4.9320e-29]],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "\n",
            "\n",
            "▶▶▶ 3797  : max cum reward :  1887  epsilon = 0.6202900000000419\n",
            "\n",
            "\n",
            "▶▶▶3798번째 에피소드 시작, env 초기화 완료.\n",
            "가져와야 할 아이템 : ['F', 'I', 'N', 'O', 'Q']\n",
            "\n",
            "현재 state         :  [9 4 0 1]\n",
            "tensor([9, 4, 0, 1])\n",
            "tensor([9., 4., 0., 1.])\n",
            "end input\n",
            "input x tensor([9., 4., 0., 1.])\n",
            "x F.relu output tensor([0.0000e+00, 3.9126e+00, 4.6085e+00, 4.7783e+00, 0.0000e+00, 2.5102e-01,\n",
            "        0.0000e+00, 2.4180e+00, 0.0000e+00, 0.0000e+00, 4.1906e+00, 4.1708e+00,\n",
            "        2.4664e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        1.3374e-01, 3.9179e+00, 0.0000e+00, 0.0000e+00, 2.8789e+00, 5.8156e+00,\n",
            "        2.5182e+00, 3.7135e+00, 4.2309e+00, 5.6534e+00, 0.0000e+00, 2.9268e+00,\n",
            "        0.0000e+00, 3.3089e+00, 1.6128e+00, 4.5133e+00, 4.0107e+00, 2.4305e+00,\n",
            "        4.8689e+00, 1.5488e+00, 5.0469e+00, 0.0000e+00, 0.0000e+00, 2.9366e+00,\n",
            "        0.0000e+00, 0.0000e+00, 3.4932e+00, 1.8743e+00, 0.0000e+00, 2.6819e+00,\n",
            "        0.0000e+00, 0.0000e+00, 3.1954e+00, 0.0000e+00, 3.6503e+00, 4.7484e+00,\n",
            "        0.0000e+00, 0.0000e+00, 3.0944e+00, 1.3346e-02, 2.8174e+00, 0.0000e+00,\n",
            "        5.9559e+00, 0.0000e+00, 1.8872e+00, 2.0973e+00, 2.8319e+00, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.8292e+00,\n",
            "        0.0000e+00, 1.1370e+00, 1.7943e+00, 0.0000e+00, 1.8791e+00, 0.0000e+00,\n",
            "        5.1678e+00, 0.0000e+00, 3.5668e+00, 3.8530e-01, 0.0000e+00, 4.6935e+00,\n",
            "        0.0000e+00, 2.9572e+00, 0.0000e+00, 6.3878e+00, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 4.0062e+00, 0.0000e+00, 6.4502e+00, 4.7247e-01, 2.9387e+00,\n",
            "        7.1713e-01, 1.0866e+00, 3.1887e+00, 1.4248e-01, 8.1615e-01, 5.9284e+00,\n",
            "        4.5430e-01, 5.6518e+00, 3.8604e+00, 0.0000e+00, 2.0456e+00, 0.0000e+00,\n",
            "        2.0017e-01, 4.7384e+00, 0.0000e+00, 1.5418e+00, 0.0000e+00, 3.5419e+00,\n",
            "        2.5523e+00, 4.0541e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.2639e+00,\n",
            "        0.0000e+00, 1.3786e+00, 0.0000e+00, 2.7205e+00, 1.1263e+00, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 5.6524e+00, 5.9235e+00, 1.2655e-03, 1.5954e+00,\n",
            "        2.8596e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.4105e+00, 2.0104e+00,\n",
            "        3.7629e+00, 9.4916e-01, 0.0000e+00, 0.0000e+00, 2.9556e+00, 0.0000e+00,\n",
            "        1.5124e+00, 2.7844e+00, 0.0000e+00, 6.3532e+00, 2.6175e+00, 1.6383e+00,\n",
            "        0.0000e+00, 5.1358e+00, 6.6452e-01, 5.5030e+00, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 4.1103e+00, 1.5878e+00, 7.3626e+00, 0.0000e+00, 3.0375e+00,\n",
            "        0.0000e+00, 3.5420e+00, 1.7012e+00, 0.0000e+00, 2.4725e+00, 0.0000e+00,\n",
            "        6.0162e+00, 0.0000e+00, 1.9111e+00, 0.0000e+00, 4.1201e+00, 0.0000e+00,\n",
            "        0.0000e+00, 4.4734e+00, 6.3155e+00, 0.0000e+00, 5.5796e+00, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        1.1564e+00, 0.0000e+00, 3.3127e+00, 0.0000e+00, 0.0000e+00, 2.5427e+00,\n",
            "        0.0000e+00, 0.0000e+00, 9.7800e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 4.0831e+00, 2.5355e+00, 3.9206e+00, 0.0000e+00, 2.9906e+00,\n",
            "        6.4511e+00, 1.0183e+00, 1.0761e+00, 2.3734e+00, 0.0000e+00, 3.5330e-01,\n",
            "        0.0000e+00, 0.0000e+00, 1.8666e+00, 4.5616e-01, 0.0000e+00, 1.8637e+00,\n",
            "        0.0000e+00, 2.3226e+00, 0.0000e+00, 1.8732e+00, 3.2381e+00, 0.0000e+00,\n",
            "        1.0921e-01, 0.0000e+00, 0.0000e+00, 4.6333e+00, 4.7399e+00, 3.9630e+00,\n",
            "        4.4790e+00, 2.5055e+00, 6.0707e+00, 3.0315e+00, 5.0736e+00, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 4.2134e+00, 0.0000e+00, 6.2227e+00,\n",
            "        1.6953e+00, 0.0000e+00, 3.0291e+00, 1.4552e+00, 5.3750e-01, 3.4031e+00,\n",
            "        0.0000e+00, 2.1929e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 4.9334e+00, 0.0000e+00, 6.9473e+00],\n",
            "       grad_fn=<ReluBackward0>)\n",
            "x fc_pi output tensor([ 50.2997, -31.2233,   0.6395, -28.3599], grad_fn=<AddBackward0>)\n",
            "x F.softmax(x, dim=softmax_dim) tensor([ 50.2997, -31.2233,   0.6395, -28.3599], grad_fn=<AddBackward0>)\n",
            "prob tensor([1.0000e+00, 3.9354e-36, 2.7092e-22, 6.8952e-35],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "step 데이터 : [8 4 0 1] -1 -1 False False\n",
            "put_data    : [9 4 0 1] 0 -1 [8 4 0 1] False\n",
            "step 데이터 : [7 4 0 1] -1 -2 False False\n",
            "put_data    : [8 4 0 1] 0 -1 [7 4 0 1] False\n",
            "step 데이터 : [6 4 0 1] -100 -102 True False\n",
            "put_data    : [7 4 0 1] 0 -100 [6 4 0 1] True\n",
            "input x tensor([[9., 4., 0., 1.],\n",
            "        [8., 4., 0., 1.],\n",
            "        [7., 4., 0., 1.]])\n",
            "x F.relu output tensor([[0.0000e+00, 3.9126e+00, 4.6085e+00, 4.7783e+00, 0.0000e+00, 2.5102e-01,\n",
            "         0.0000e+00, 2.4180e+00, 0.0000e+00, 0.0000e+00, 4.1906e+00, 4.1708e+00,\n",
            "         2.4664e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "         1.3374e-01, 3.9179e+00, 0.0000e+00, 0.0000e+00, 2.8789e+00, 5.8156e+00,\n",
            "         2.5182e+00, 3.7135e+00, 4.2309e+00, 5.6534e+00, 0.0000e+00, 2.9268e+00,\n",
            "         0.0000e+00, 3.3089e+00, 1.6128e+00, 4.5133e+00, 4.0107e+00, 2.4305e+00,\n",
            "         4.8689e+00, 1.5488e+00, 5.0469e+00, 0.0000e+00, 0.0000e+00, 2.9366e+00,\n",
            "         0.0000e+00, 0.0000e+00, 3.4932e+00, 1.8743e+00, 0.0000e+00, 2.6819e+00,\n",
            "         0.0000e+00, 0.0000e+00, 3.1954e+00, 0.0000e+00, 3.6503e+00, 4.7484e+00,\n",
            "         0.0000e+00, 0.0000e+00, 3.0944e+00, 1.3346e-02, 2.8174e+00, 0.0000e+00,\n",
            "         5.9559e+00, 0.0000e+00, 1.8872e+00, 2.0973e+00, 2.8319e+00, 0.0000e+00,\n",
            "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.8292e+00,\n",
            "         0.0000e+00, 1.1370e+00, 1.7943e+00, 0.0000e+00, 1.8791e+00, 0.0000e+00,\n",
            "         5.1678e+00, 0.0000e+00, 3.5668e+00, 3.8530e-01, 0.0000e+00, 4.6935e+00,\n",
            "         0.0000e+00, 2.9572e+00, 0.0000e+00, 6.3878e+00, 0.0000e+00, 0.0000e+00,\n",
            "         0.0000e+00, 4.0062e+00, 0.0000e+00, 6.4502e+00, 4.7247e-01, 2.9387e+00,\n",
            "         7.1713e-01, 1.0866e+00, 3.1887e+00, 1.4248e-01, 8.1615e-01, 5.9284e+00,\n",
            "         4.5430e-01, 5.6518e+00, 3.8604e+00, 0.0000e+00, 2.0456e+00, 0.0000e+00,\n",
            "         2.0017e-01, 4.7384e+00, 0.0000e+00, 1.5418e+00, 0.0000e+00, 3.5419e+00,\n",
            "         2.5523e+00, 4.0541e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.2639e+00,\n",
            "         0.0000e+00, 1.3786e+00, 0.0000e+00, 2.7205e+00, 1.1263e+00, 0.0000e+00,\n",
            "         0.0000e+00, 0.0000e+00, 5.6524e+00, 5.9235e+00, 1.2655e-03, 1.5954e+00,\n",
            "         2.8596e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.4105e+00, 2.0104e+00,\n",
            "         3.7629e+00, 9.4916e-01, 0.0000e+00, 0.0000e+00, 2.9556e+00, 0.0000e+00,\n",
            "         1.5124e+00, 2.7844e+00, 0.0000e+00, 6.3532e+00, 2.6175e+00, 1.6383e+00,\n",
            "         0.0000e+00, 5.1358e+00, 6.6452e-01, 5.5030e+00, 0.0000e+00, 0.0000e+00,\n",
            "         0.0000e+00, 4.1103e+00, 1.5878e+00, 7.3626e+00, 0.0000e+00, 3.0375e+00,\n",
            "         0.0000e+00, 3.5420e+00, 1.7012e+00, 0.0000e+00, 2.4725e+00, 0.0000e+00,\n",
            "         6.0162e+00, 0.0000e+00, 1.9111e+00, 0.0000e+00, 4.1201e+00, 0.0000e+00,\n",
            "         0.0000e+00, 4.4734e+00, 6.3155e+00, 0.0000e+00, 5.5796e+00, 0.0000e+00,\n",
            "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "         1.1564e+00, 0.0000e+00, 3.3127e+00, 0.0000e+00, 0.0000e+00, 2.5427e+00,\n",
            "         0.0000e+00, 0.0000e+00, 9.7800e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "         0.0000e+00, 4.0831e+00, 2.5355e+00, 3.9206e+00, 0.0000e+00, 2.9906e+00,\n",
            "         6.4511e+00, 1.0183e+00, 1.0761e+00, 2.3734e+00, 0.0000e+00, 3.5330e-01,\n",
            "         0.0000e+00, 0.0000e+00, 1.8666e+00, 4.5616e-01, 0.0000e+00, 1.8637e+00,\n",
            "         0.0000e+00, 2.3226e+00, 0.0000e+00, 1.8732e+00, 3.2381e+00, 0.0000e+00,\n",
            "         1.0921e-01, 0.0000e+00, 0.0000e+00, 4.6333e+00, 4.7399e+00, 3.9630e+00,\n",
            "         4.4790e+00, 2.5055e+00, 6.0707e+00, 3.0315e+00, 5.0736e+00, 0.0000e+00,\n",
            "         0.0000e+00, 0.0000e+00, 0.0000e+00, 4.2134e+00, 0.0000e+00, 6.2227e+00,\n",
            "         1.6953e+00, 0.0000e+00, 3.0291e+00, 1.4552e+00, 5.3750e-01, 3.4031e+00,\n",
            "         0.0000e+00, 2.1929e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "         0.0000e+00, 4.9334e+00, 0.0000e+00, 6.9473e+00],\n",
            "        [0.0000e+00, 3.5533e+00, 4.2680e+00, 4.1505e+00, 0.0000e+00, 3.6089e-02,\n",
            "         0.0000e+00, 2.2905e+00, 0.0000e+00, 0.0000e+00, 3.6338e+00, 3.8234e+00,\n",
            "         2.3629e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "         1.3412e-01, 3.6811e+00, 0.0000e+00, 0.0000e+00, 2.6170e+00, 5.1849e+00,\n",
            "         2.3170e+00, 3.3973e+00, 3.6814e+00, 5.1131e+00, 0.0000e+00, 2.5816e+00,\n",
            "         0.0000e+00, 3.0396e+00, 1.5295e+00, 4.2305e+00, 3.8391e+00, 2.3455e+00,\n",
            "         4.2827e+00, 1.2664e+00, 4.5952e+00, 0.0000e+00, 0.0000e+00, 2.5425e+00,\n",
            "         0.0000e+00, 0.0000e+00, 3.2265e+00, 1.8107e+00, 0.0000e+00, 2.3418e+00,\n",
            "         0.0000e+00, 0.0000e+00, 3.0732e+00, 0.0000e+00, 3.3172e+00, 4.2941e+00,\n",
            "         0.0000e+00, 0.0000e+00, 2.8234e+00, 0.0000e+00, 2.6454e+00, 0.0000e+00,\n",
            "         5.5792e+00, 0.0000e+00, 1.5432e+00, 1.9785e+00, 2.4549e+00, 0.0000e+00,\n",
            "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.4630e+00,\n",
            "         0.0000e+00, 7.8063e-01, 1.6978e+00, 0.0000e+00, 1.8752e+00, 0.0000e+00,\n",
            "         4.6831e+00, 0.0000e+00, 3.3753e+00, 4.5798e-01, 0.0000e+00, 4.1633e+00,\n",
            "         0.0000e+00, 2.5660e+00, 0.0000e+00, 5.8994e+00, 0.0000e+00, 0.0000e+00,\n",
            "         0.0000e+00, 3.5705e+00, 0.0000e+00, 6.0180e+00, 2.7312e-01, 2.4987e+00,\n",
            "         7.9839e-01, 8.6753e-01, 2.8126e+00, 4.5159e-02, 9.4529e-01, 5.3969e+00,\n",
            "         4.3707e-01, 5.2184e+00, 3.6676e+00, 0.0000e+00, 1.9326e+00, 0.0000e+00,\n",
            "         3.0914e-01, 4.5098e+00, 0.0000e+00, 1.3154e+00, 0.0000e+00, 3.3281e+00,\n",
            "         2.5493e+00, 3.8877e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.2026e+00,\n",
            "         0.0000e+00, 1.4172e+00, 0.0000e+00, 2.5890e+00, 1.0782e+00, 0.0000e+00,\n",
            "         0.0000e+00, 0.0000e+00, 5.2967e+00, 5.5030e+00, 1.0387e-01, 1.4854e+00,\n",
            "         2.6380e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.0279e+00, 1.6788e+00,\n",
            "         3.4733e+00, 7.4257e-01, 0.0000e+00, 0.0000e+00, 2.8650e+00, 1.3621e-01,\n",
            "         1.5118e+00, 2.4183e+00, 0.0000e+00, 5.8560e+00, 2.4562e+00, 1.3408e+00,\n",
            "         0.0000e+00, 4.8094e+00, 8.0995e-01, 4.9418e+00, 0.0000e+00, 0.0000e+00,\n",
            "         0.0000e+00, 3.7689e+00, 1.5944e+00, 6.7855e+00, 0.0000e+00, 2.6219e+00,\n",
            "         0.0000e+00, 3.1874e+00, 1.8117e+00, 0.0000e+00, 2.3950e+00, 0.0000e+00,\n",
            "         5.6174e+00, 0.0000e+00, 1.7792e+00, 0.0000e+00, 3.9034e+00, 0.0000e+00,\n",
            "         0.0000e+00, 4.1701e+00, 5.8549e+00, 0.0000e+00, 5.0583e+00, 0.0000e+00,\n",
            "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "         1.0323e+00, 0.0000e+00, 3.0886e+00, 0.0000e+00, 0.0000e+00, 2.0909e+00,\n",
            "         0.0000e+00, 0.0000e+00, 8.1107e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "         0.0000e+00, 3.6855e+00, 2.1931e+00, 3.6349e+00, 0.0000e+00, 2.7700e+00,\n",
            "         6.0068e+00, 1.0074e+00, 1.0035e+00, 2.1265e+00, 0.0000e+00, 3.6531e-01,\n",
            "         0.0000e+00, 0.0000e+00, 1.8775e+00, 5.5939e-01, 0.0000e+00, 1.7718e+00,\n",
            "         0.0000e+00, 2.2538e+00, 0.0000e+00, 1.8888e+00, 3.1129e+00, 0.0000e+00,\n",
            "         1.1414e-01, 0.0000e+00, 0.0000e+00, 4.0776e+00, 4.3072e+00, 3.6675e+00,\n",
            "         3.9148e+00, 2.1265e+00, 5.6298e+00, 2.6321e+00, 4.6835e+00, 0.0000e+00,\n",
            "         0.0000e+00, 0.0000e+00, 0.0000e+00, 3.9365e+00, 0.0000e+00, 5.6881e+00,\n",
            "         1.5299e+00, 0.0000e+00, 2.7065e+00, 1.2436e+00, 3.6521e-01, 3.2629e+00,\n",
            "         0.0000e+00, 1.7739e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "         0.0000e+00, 4.7181e+00, 0.0000e+00, 6.4629e+00],\n",
            "        [0.0000e+00, 3.1939e+00, 3.9276e+00, 3.5227e+00, 0.0000e+00, 0.0000e+00,\n",
            "         0.0000e+00, 2.1631e+00, 0.0000e+00, 0.0000e+00, 3.0769e+00, 3.4760e+00,\n",
            "         2.2593e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "         1.3450e-01, 3.4443e+00, 0.0000e+00, 0.0000e+00, 2.3551e+00, 4.5543e+00,\n",
            "         2.1158e+00, 3.0811e+00, 3.1319e+00, 4.5728e+00, 0.0000e+00, 2.2363e+00,\n",
            "         0.0000e+00, 2.7703e+00, 1.4461e+00, 3.9477e+00, 3.6674e+00, 2.2604e+00,\n",
            "         3.6964e+00, 9.8411e-01, 4.1434e+00, 0.0000e+00, 0.0000e+00, 2.1484e+00,\n",
            "         0.0000e+00, 0.0000e+00, 2.9597e+00, 1.7471e+00, 0.0000e+00, 2.0017e+00,\n",
            "         0.0000e+00, 0.0000e+00, 2.9511e+00, 0.0000e+00, 2.9841e+00, 3.8398e+00,\n",
            "         0.0000e+00, 0.0000e+00, 2.5524e+00, 0.0000e+00, 2.4734e+00, 0.0000e+00,\n",
            "         5.2025e+00, 0.0000e+00, 1.1992e+00, 1.8598e+00, 2.0779e+00, 0.0000e+00,\n",
            "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.0969e+00,\n",
            "         0.0000e+00, 4.2426e-01, 1.6013e+00, 0.0000e+00, 1.8712e+00, 0.0000e+00,\n",
            "         4.1984e+00, 0.0000e+00, 3.1838e+00, 5.3066e-01, 0.0000e+00, 3.6332e+00,\n",
            "         0.0000e+00, 2.1748e+00, 0.0000e+00, 5.4109e+00, 0.0000e+00, 0.0000e+00,\n",
            "         0.0000e+00, 3.1348e+00, 0.0000e+00, 5.5858e+00, 7.3770e-02, 2.0587e+00,\n",
            "         8.7964e-01, 6.4850e-01, 2.4364e+00, 0.0000e+00, 1.0744e+00, 4.8653e+00,\n",
            "         4.1983e-01, 4.7850e+00, 3.4748e+00, 0.0000e+00, 1.8195e+00, 0.0000e+00,\n",
            "         4.1811e-01, 4.2811e+00, 0.0000e+00, 1.0890e+00, 0.0000e+00, 3.1143e+00,\n",
            "         2.5462e+00, 3.7213e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.1414e+00,\n",
            "         0.0000e+00, 1.4558e+00, 0.0000e+00, 2.4574e+00, 1.0301e+00, 0.0000e+00,\n",
            "         0.0000e+00, 0.0000e+00, 4.9410e+00, 5.0824e+00, 2.0648e-01, 1.3755e+00,\n",
            "         2.4163e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.6453e+00, 1.3472e+00,\n",
            "         3.1837e+00, 5.3598e-01, 0.0000e+00, 0.0000e+00, 2.7743e+00, 3.5695e-01,\n",
            "         1.5112e+00, 2.0522e+00, 0.0000e+00, 5.3589e+00, 2.2949e+00, 1.0434e+00,\n",
            "         0.0000e+00, 4.4830e+00, 9.5537e-01, 4.3807e+00, 0.0000e+00, 0.0000e+00,\n",
            "         0.0000e+00, 3.4275e+00, 1.6010e+00, 6.2084e+00, 0.0000e+00, 2.2063e+00,\n",
            "         0.0000e+00, 2.8329e+00, 1.9222e+00, 0.0000e+00, 2.3176e+00, 6.0388e-02,\n",
            "         5.2187e+00, 0.0000e+00, 1.6474e+00, 0.0000e+00, 3.6867e+00, 0.0000e+00,\n",
            "         0.0000e+00, 3.8667e+00, 5.3943e+00, 0.0000e+00, 4.5370e+00, 0.0000e+00,\n",
            "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "         9.0825e-01, 0.0000e+00, 2.8645e+00, 0.0000e+00, 0.0000e+00, 1.6390e+00,\n",
            "         0.0000e+00, 0.0000e+00, 6.4415e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "         0.0000e+00, 3.2879e+00, 1.8507e+00, 3.3491e+00, 0.0000e+00, 2.5494e+00,\n",
            "         5.5625e+00, 9.9657e-01, 9.3089e-01, 1.8795e+00, 0.0000e+00, 3.7733e-01,\n",
            "         0.0000e+00, 0.0000e+00, 1.8884e+00, 6.6262e-01, 0.0000e+00, 1.6799e+00,\n",
            "         0.0000e+00, 2.1850e+00, 0.0000e+00, 1.9045e+00, 2.9877e+00, 0.0000e+00,\n",
            "         1.1907e-01, 0.0000e+00, 0.0000e+00, 3.5220e+00, 3.8745e+00, 3.3720e+00,\n",
            "         3.3506e+00, 1.7475e+00, 5.1890e+00, 2.2327e+00, 4.2933e+00, 0.0000e+00,\n",
            "         0.0000e+00, 0.0000e+00, 0.0000e+00, 3.6596e+00, 0.0000e+00, 5.1535e+00,\n",
            "         1.3644e+00, 0.0000e+00, 2.3839e+00, 1.0320e+00, 1.9292e-01, 3.1226e+00,\n",
            "         0.0000e+00, 1.3550e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "         0.0000e+00, 4.5029e+00, 0.0000e+00, 5.9785e+00]],\n",
            "       grad_fn=<ReluBackward0>)\n",
            "x fc_pi output tensor([[ 50.2997, -31.2233,   0.6395, -28.3599],\n",
            "        [ 46.1173, -28.6453,   0.7365, -26.0297],\n",
            "        [ 41.9396, -26.0769,   0.8349, -23.6929]], grad_fn=<AddmmBackward0>)\n",
            "x F.softmax(x, dim=softmax_dim) tensor([[ 50.2997, -31.2233,   0.6395, -28.3599],\n",
            "        [ 46.1173, -28.6453,   0.7365, -26.0297],\n",
            "        [ 41.9396, -26.0769,   0.8349, -23.6929]], grad_fn=<AddmmBackward0>)\n",
            "prob tensor([[1.0000e+00, 3.9354e-36, 2.7092e-22, 6.8951e-35],\n",
            "        [1.0000e+00, 3.3962e-33, 1.9560e-20, 4.6445e-32],\n",
            "        [1.0000e+00, 2.8895e-30, 1.4076e-18, 3.1346e-29]],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "\n",
            "\n",
            "▶▶▶ 3798  : max cum reward :  1887  epsilon = 0.6201900000000419\n",
            "\n",
            "\n",
            "▶▶▶3799번째 에피소드 시작, env 초기화 완료.\n",
            "가져와야 할 아이템 : ['C', 'D', 'E', 'J', 'L', 'P']\n",
            "\n",
            "현재 state         :  [9 4 3 0]\n",
            "tensor([9, 4, 3, 0])\n",
            "tensor([9., 4., 3., 0.])\n",
            "end input\n",
            "input x tensor([9., 4., 3., 0.])\n",
            "x F.relu output tensor([0.0000, 3.1448, 3.7094, 4.0737, 0.0000, 0.1510, 0.0000, 1.3953, 0.0000,\n",
            "        0.0000, 4.0876, 3.0215, 2.8009, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 4.1882, 0.0000, 0.0000, 3.8334, 5.9014, 3.3718, 5.1833, 2.9376,\n",
            "        5.1325, 0.0000, 4.2740, 0.0000, 3.0504, 1.4445, 2.6925, 4.0987, 2.7900,\n",
            "        3.7086, 3.2498, 5.0966, 0.0000, 0.4131, 3.9116, 0.0000, 0.0000, 4.6066,\n",
            "        1.6149, 0.0000, 4.1268, 0.0000, 0.0000, 1.6995, 0.0000, 5.3086, 4.1817,\n",
            "        0.0000, 0.0000, 3.6104, 0.2287, 4.1757, 0.0000, 5.6387, 0.3255, 3.4096,\n",
            "        2.6397, 2.3954, 0.4374, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 2.9030,\n",
            "        0.0000, 0.5389, 1.6274, 0.0000, 1.9772, 0.0000, 4.3293, 0.0000, 4.8763,\n",
            "        1.6358, 0.0000, 5.4004, 0.0000, 4.4062, 0.1652, 6.6155, 0.0000, 0.0000,\n",
            "        0.0000, 3.0979, 0.0000, 5.5367, 0.0000, 4.2022, 0.0000, 1.0560, 3.4371,\n",
            "        0.0000, 0.0000, 5.4936, 0.3018, 5.7664, 3.5944, 0.0000, 1.0542, 0.0000,\n",
            "        1.4881, 4.9488, 0.0000, 0.1551, 0.0000, 2.8124, 3.7128, 4.9289, 0.0000,\n",
            "        0.0000, 0.0000, 2.9346, 0.0000, 2.6379, 0.0000, 4.5649, 2.6526, 0.0000,\n",
            "        0.0000, 0.0000, 5.2775, 5.2061, 0.0000, 2.2465, 2.9912, 0.0000, 0.0000,\n",
            "        0.0000, 3.4795, 2.1614, 3.8423, 1.1205, 0.0000, 0.0000, 3.3374, 0.0000,\n",
            "        1.3939, 2.8898, 0.0000, 7.0325, 3.3397, 1.7210, 0.0000, 6.9288, 0.0995,\n",
            "        5.3504, 0.0000, 0.0000, 0.0000, 4.8035, 1.8350, 5.7850, 0.0000, 2.8031,\n",
            "        0.0000, 3.9007, 2.6840, 0.0000, 3.0798, 0.0000, 5.3545, 0.0000, 0.7905,\n",
            "        0.0000, 4.5844, 0.0000, 0.0000, 4.0013, 6.8588, 0.0000, 6.2334, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.8375, 0.0000, 3.0288,\n",
            "        0.0000, 0.0000, 1.7876, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 3.1305, 3.3149, 3.6750, 0.0000, 3.2267, 5.7826, 3.0141, 0.0000,\n",
            "        3.6870, 0.0000, 1.7287, 0.0000, 0.0000, 0.0551, 1.0626, 0.0000, 2.5190,\n",
            "        0.0000, 3.1004, 0.0000, 1.0050, 1.6574, 0.0000, 1.5532, 0.0000, 0.0000,\n",
            "        5.2443, 6.4072, 3.3817, 5.1319, 2.6092, 4.9539, 4.4495, 5.6098, 0.0000,\n",
            "        0.2718, 0.4628, 0.0000, 5.4457, 0.0000, 8.1887, 2.2571, 0.0000, 2.0864,\n",
            "        1.9989, 0.0000, 4.7391, 0.0000, 3.5395, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 6.6059, 0.0000, 6.8769], grad_fn=<ReluBackward0>)\n",
            "x fc_pi output tensor([ 52.5976, -33.3017,   2.8204, -33.3043], grad_fn=<AddBackward0>)\n",
            "x F.softmax(x, dim=softmax_dim) tensor([ 52.5976, -33.3017,   2.8204, -33.3043], grad_fn=<AddBackward0>)\n",
            "prob tensor([1.0000e+00, 4.9480e-38, 2.4103e-22, 4.9348e-38],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "step 데이터 : [8 4 3 0] -1 -1 False False\n",
            "put_data    : [9 4 3 0] 0 -1 [8 4 3 0] False\n",
            "step 데이터 : [9 4 3 0] -1 -2 False False\n",
            "put_data    : [8 4 3 0] 1 -1 [9 4 3 0] False\n",
            "step 데이터 : [9 3 3 0] -100 -102 True False\n",
            "put_data    : [9 4 3 0] 2 -100 [9 3 3 0] True\n",
            "input x tensor([[9., 4., 3., 0.],\n",
            "        [8., 4., 3., 0.],\n",
            "        [9., 4., 3., 0.]])\n",
            "x F.relu output tensor([[0.0000, 3.1448, 3.7094, 4.0737, 0.0000, 0.1510, 0.0000, 1.3953, 0.0000,\n",
            "         0.0000, 4.0876, 3.0215, 2.8009, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 4.1882, 0.0000, 0.0000, 3.8334, 5.9014, 3.3718, 5.1833, 2.9376,\n",
            "         5.1325, 0.0000, 4.2740, 0.0000, 3.0504, 1.4445, 2.6925, 4.0987, 2.7900,\n",
            "         3.7086, 3.2498, 5.0966, 0.0000, 0.4131, 3.9116, 0.0000, 0.0000, 4.6066,\n",
            "         1.6149, 0.0000, 4.1268, 0.0000, 0.0000, 1.6995, 0.0000, 5.3086, 4.1817,\n",
            "         0.0000, 0.0000, 3.6104, 0.2287, 4.1757, 0.0000, 5.6387, 0.3255, 3.4096,\n",
            "         2.6397, 2.3954, 0.4374, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 2.9030,\n",
            "         0.0000, 0.5389, 1.6274, 0.0000, 1.9772, 0.0000, 4.3293, 0.0000, 4.8763,\n",
            "         1.6358, 0.0000, 5.4004, 0.0000, 4.4062, 0.1652, 6.6155, 0.0000, 0.0000,\n",
            "         0.0000, 3.0979, 0.0000, 5.5367, 0.0000, 4.2022, 0.0000, 1.0560, 3.4371,\n",
            "         0.0000, 0.0000, 5.4936, 0.3018, 5.7664, 3.5944, 0.0000, 1.0542, 0.0000,\n",
            "         1.4881, 4.9488, 0.0000, 0.1551, 0.0000, 2.8124, 3.7128, 4.9289, 0.0000,\n",
            "         0.0000, 0.0000, 2.9346, 0.0000, 2.6379, 0.0000, 4.5649, 2.6526, 0.0000,\n",
            "         0.0000, 0.0000, 5.2775, 5.2061, 0.0000, 2.2465, 2.9912, 0.0000, 0.0000,\n",
            "         0.0000, 3.4795, 2.1614, 3.8423, 1.1205, 0.0000, 0.0000, 3.3374, 0.0000,\n",
            "         1.3939, 2.8898, 0.0000, 7.0325, 3.3397, 1.7210, 0.0000, 6.9288, 0.0995,\n",
            "         5.3504, 0.0000, 0.0000, 0.0000, 4.8035, 1.8350, 5.7850, 0.0000, 2.8031,\n",
            "         0.0000, 3.9007, 2.6840, 0.0000, 3.0798, 0.0000, 5.3545, 0.0000, 0.7905,\n",
            "         0.0000, 4.5844, 0.0000, 0.0000, 4.0013, 6.8588, 0.0000, 6.2334, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.8375, 0.0000, 3.0288,\n",
            "         0.0000, 0.0000, 1.7876, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 3.1305, 3.3149, 3.6750, 0.0000, 3.2267, 5.7826, 3.0141, 0.0000,\n",
            "         3.6870, 0.0000, 1.7287, 0.0000, 0.0000, 0.0551, 1.0626, 0.0000, 2.5190,\n",
            "         0.0000, 3.1004, 0.0000, 1.0050, 1.6574, 0.0000, 1.5532, 0.0000, 0.0000,\n",
            "         5.2443, 6.4072, 3.3817, 5.1319, 2.6092, 4.9539, 4.4495, 5.6098, 0.0000,\n",
            "         0.2718, 0.4628, 0.0000, 5.4457, 0.0000, 8.1887, 2.2571, 0.0000, 2.0864,\n",
            "         1.9989, 0.0000, 4.7391, 0.0000, 3.5395, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 6.6059, 0.0000, 6.8769],\n",
            "        [0.0000, 2.7854, 3.3689, 3.4459, 0.0000, 0.0000, 0.0000, 1.2678, 0.0000,\n",
            "         0.0000, 3.5308, 2.6740, 2.6972, 0.0000, 0.1711, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 3.9513, 0.0000, 0.0000, 3.5715, 5.2707, 3.1706, 4.8670, 2.3881,\n",
            "         4.5921, 0.0000, 3.9287, 0.0000, 2.7810, 1.3611, 2.4097, 3.9270, 2.7049,\n",
            "         3.1224, 2.9675, 4.6448, 0.0000, 0.5784, 3.5175, 0.0000, 0.0000, 4.3399,\n",
            "         1.5512, 0.0000, 3.7867, 0.0000, 0.0000, 1.5774, 0.0000, 4.9755, 3.7273,\n",
            "         0.0000, 0.0000, 3.3393, 0.1789, 4.0037, 0.0000, 5.2619, 0.6274, 3.0656,\n",
            "         2.5209, 2.0183, 0.4610, 0.0000, 0.1194, 0.0000, 0.0000, 0.0000, 2.5368,\n",
            "         0.0000, 0.1826, 1.5309, 0.0000, 1.9732, 0.0000, 3.8446, 0.0000, 4.6847,\n",
            "         1.7084, 0.0000, 4.8703, 0.0000, 4.0149, 0.3351, 6.1271, 0.0000, 0.0000,\n",
            "         0.0000, 2.6622, 0.0000, 5.1044, 0.0000, 3.7622, 0.0000, 0.8370, 3.0609,\n",
            "         0.0000, 0.0000, 4.9620, 0.2846, 5.3330, 3.4015, 0.0000, 0.9411, 0.0000,\n",
            "         1.5970, 4.7201, 0.0000, 0.0000, 0.0000, 2.5986, 3.7097, 4.7624, 0.0000,\n",
            "         0.0000, 0.0000, 2.8734, 0.0000, 2.6765, 0.0000, 4.4333, 2.6044, 0.0000,\n",
            "         0.0000, 0.0000, 4.9217, 4.7855, 0.0000, 2.1365, 2.7696, 0.0000, 0.0000,\n",
            "         0.0000, 3.0969, 1.8298, 3.5527, 0.9139, 0.0000, 0.0000, 3.2468, 0.0000,\n",
            "         1.3933, 2.5237, 0.0000, 6.5353, 3.1783, 1.4235, 0.0000, 6.6023, 0.2449,\n",
            "         4.7893, 0.0000, 0.0000, 0.0000, 4.4620, 1.8416, 5.2079, 0.0000, 2.3875,\n",
            "         0.0000, 3.5461, 2.7945, 0.0000, 3.0023, 0.0000, 4.9558, 0.0000, 0.6586,\n",
            "         0.0000, 4.3677, 0.0000, 0.0000, 3.6980, 6.3982, 0.0000, 5.7121, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.7134, 0.0000, 2.8047,\n",
            "         0.0000, 0.0000, 1.3357, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 2.7329, 2.9724, 3.3892, 0.0000, 3.0061, 5.3382, 3.0032, 0.0000,\n",
            "         3.4399, 0.0000, 1.7407, 0.0000, 0.0000, 0.0660, 1.1658, 0.0000, 2.4270,\n",
            "         0.0000, 3.0316, 0.0000, 1.0206, 1.5322, 0.0000, 1.5581, 0.0000, 0.0000,\n",
            "         4.6885, 5.9745, 3.0861, 4.5677, 2.2302, 4.5130, 4.0500, 5.2196, 0.0000,\n",
            "         0.3524, 0.6237, 0.0000, 5.1688, 0.0000, 7.6540, 2.0917, 0.0000, 1.7638,\n",
            "         1.7873, 0.0000, 4.5988, 0.0000, 3.1205, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 6.3906, 0.0000, 6.3925],\n",
            "        [0.0000, 3.1448, 3.7094, 4.0737, 0.0000, 0.1510, 0.0000, 1.3953, 0.0000,\n",
            "         0.0000, 4.0876, 3.0215, 2.8009, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 4.1882, 0.0000, 0.0000, 3.8334, 5.9014, 3.3718, 5.1833, 2.9376,\n",
            "         5.1325, 0.0000, 4.2740, 0.0000, 3.0504, 1.4445, 2.6925, 4.0987, 2.7900,\n",
            "         3.7086, 3.2498, 5.0966, 0.0000, 0.4131, 3.9116, 0.0000, 0.0000, 4.6066,\n",
            "         1.6149, 0.0000, 4.1268, 0.0000, 0.0000, 1.6995, 0.0000, 5.3086, 4.1817,\n",
            "         0.0000, 0.0000, 3.6104, 0.2287, 4.1757, 0.0000, 5.6387, 0.3255, 3.4096,\n",
            "         2.6397, 2.3954, 0.4374, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 2.9030,\n",
            "         0.0000, 0.5389, 1.6274, 0.0000, 1.9772, 0.0000, 4.3293, 0.0000, 4.8763,\n",
            "         1.6358, 0.0000, 5.4004, 0.0000, 4.4062, 0.1652, 6.6155, 0.0000, 0.0000,\n",
            "         0.0000, 3.0979, 0.0000, 5.5367, 0.0000, 4.2022, 0.0000, 1.0560, 3.4371,\n",
            "         0.0000, 0.0000, 5.4936, 0.3018, 5.7664, 3.5944, 0.0000, 1.0542, 0.0000,\n",
            "         1.4881, 4.9488, 0.0000, 0.1551, 0.0000, 2.8124, 3.7128, 4.9289, 0.0000,\n",
            "         0.0000, 0.0000, 2.9346, 0.0000, 2.6379, 0.0000, 4.5649, 2.6526, 0.0000,\n",
            "         0.0000, 0.0000, 5.2775, 5.2061, 0.0000, 2.2465, 2.9912, 0.0000, 0.0000,\n",
            "         0.0000, 3.4795, 2.1614, 3.8423, 1.1205, 0.0000, 0.0000, 3.3374, 0.0000,\n",
            "         1.3939, 2.8898, 0.0000, 7.0325, 3.3397, 1.7210, 0.0000, 6.9288, 0.0995,\n",
            "         5.3504, 0.0000, 0.0000, 0.0000, 4.8035, 1.8350, 5.7850, 0.0000, 2.8031,\n",
            "         0.0000, 3.9007, 2.6840, 0.0000, 3.0798, 0.0000, 5.3545, 0.0000, 0.7905,\n",
            "         0.0000, 4.5844, 0.0000, 0.0000, 4.0013, 6.8588, 0.0000, 6.2334, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.8375, 0.0000, 3.0288,\n",
            "         0.0000, 0.0000, 1.7876, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 3.1305, 3.3149, 3.6750, 0.0000, 3.2267, 5.7826, 3.0141, 0.0000,\n",
            "         3.6870, 0.0000, 1.7287, 0.0000, 0.0000, 0.0551, 1.0626, 0.0000, 2.5190,\n",
            "         0.0000, 3.1004, 0.0000, 1.0050, 1.6574, 0.0000, 1.5532, 0.0000, 0.0000,\n",
            "         5.2443, 6.4072, 3.3817, 5.1319, 2.6092, 4.9539, 4.4495, 5.6098, 0.0000,\n",
            "         0.2718, 0.4628, 0.0000, 5.4457, 0.0000, 8.1887, 2.2571, 0.0000, 2.0864,\n",
            "         1.9989, 0.0000, 4.7391, 0.0000, 3.5395, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 6.6059, 0.0000, 6.8769]], grad_fn=<ReluBackward0>)\n",
            "x fc_pi output tensor([[ 52.5976, -33.3017,   2.8204, -33.3043],\n",
            "        [ 48.4312, -30.7715,   2.9629, -31.0711],\n",
            "        [ 52.5976, -33.3017,   2.8204, -33.3043]], grad_fn=<AddmmBackward0>)\n",
            "x F.softmax(x, dim=softmax_dim) tensor([[ 52.5976, -33.3017,   2.8204, -33.3043],\n",
            "        [ 48.4312, -30.7715,   2.9629, -31.0711],\n",
            "        [ 52.5976, -33.3017,   2.8204, -33.3043]], grad_fn=<AddmmBackward0>)\n",
            "prob tensor([[1.0000e+00, 4.9479e-38, 2.4103e-22, 4.9347e-38],\n",
            "        [1.0000e+00, 4.0059e-35, 1.7920e-20, 2.9688e-35],\n",
            "        [1.0000e+00, 4.9479e-38, 2.4103e-22, 4.9347e-38]],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "\n",
            "\n",
            "▶▶▶ 3799  : max cum reward :  1887  epsilon = 0.6200900000000419\n",
            "\n",
            "\n",
            "▶▶▶3800번째 에피소드 시작, env 초기화 완료.\n",
            "가져와야 할 아이템 : ['A', 'K', 'N', 'O', 'P', 'Q']\n",
            "\n",
            "현재 state         :  [9 4 5 0]\n",
            "step 데이터 : [9 5 5 0] -100 -100 True False\n",
            "put_data    : [9 4 5 0] 3 -100 [9 5 5 0] True\n",
            "input x tensor([[9., 4., 5., 0.]])\n",
            "x F.relu output tensor([[0.0000, 2.5079, 3.1033, 3.8232, 0.3766, 0.0000, 0.0000, 0.8629, 0.0000,\n",
            "         0.0000, 4.1743, 2.3618, 2.8979, 0.0000, 0.9128, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 4.5270, 0.0000, 0.0000, 4.2522, 6.0735, 4.2579, 5.9368, 2.1872,\n",
            "         4.9202, 0.0000, 5.3984, 0.0000, 2.5739, 1.6187, 1.8092, 3.8974, 3.1590,\n",
            "         2.8852, 4.3660, 5.3211, 0.0000, 1.0666, 4.3484, 0.0000, 0.0000, 5.0688,\n",
            "         1.6604, 0.0000, 4.8341, 0.0000, 0.0000, 0.9289, 0.0000, 6.2834, 3.4926,\n",
            "         0.0000, 0.0000, 4.2324, 0.0976, 4.8690, 0.0000, 5.7259, 1.3804, 4.3467,\n",
            "         2.8934, 2.1027, 1.2288, 0.0000, 0.7863, 0.0000, 0.0000, 0.0000, 2.4622,\n",
            "         0.0000, 0.0234, 1.6098, 0.0000, 1.7884, 0.0000, 3.8529, 0.2421, 5.6899,\n",
            "         2.5751, 0.0000, 5.6400, 0.0000, 5.2863, 0.7068, 6.8377, 0.0000, 0.0000,\n",
            "         0.0000, 2.7080, 0.0000, 5.2626, 0.0000, 5.0557, 0.0000, 0.7979, 3.7669,\n",
            "         0.0000, 0.0000, 4.9953, 0.0000, 6.0085, 3.4282, 0.0000, 0.4814, 0.0000,\n",
            "         2.5094, 5.3307, 0.0000, 0.0000, 0.0000, 2.2739, 4.5880, 5.7575, 0.0000,\n",
            "         0.0000, 0.0000, 2.8515, 0.0000, 3.4595, 0.0000, 5.6047, 3.6370, 0.0000,\n",
            "         0.0000, 0.0000, 5.2400, 4.6677, 0.0000, 2.4569, 2.9326, 0.0000, 0.0000,\n",
            "         0.0000, 3.3742, 2.1192, 3.6552, 1.5241, 0.0000, 0.0000, 3.9060, 0.0000,\n",
            "         1.2050, 2.7406, 0.0000, 7.3088, 3.9318, 1.5185, 0.0000, 8.0722, 0.0000,\n",
            "         5.3401, 0.0000, 0.0000, 0.0000, 5.0245, 2.0674, 5.0315, 0.0000, 2.5405,\n",
            "         0.0000, 4.4836, 3.2290, 0.0332, 3.8087, 0.0000, 4.7415, 0.0000, 0.0720,\n",
            "         0.0000, 4.9839, 0.0000, 0.0000, 3.8885, 7.1398, 0.0000, 6.7230, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 2.4395, 0.0000, 2.6728,\n",
            "         0.0000, 0.0000, 1.1246, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 2.5745, 4.0820, 3.2632, 0.0000, 3.2297, 5.6194, 4.0647, 0.0000,\n",
            "         4.7339, 0.0000, 2.7517, 0.0000, 0.0000, 0.0000, 1.3115, 0.0000, 3.0719,\n",
            "         0.0000, 3.4622, 0.0000, 0.3995, 0.7907, 0.0000, 2.3994, 0.0000, 0.0000,\n",
            "         5.7448, 7.5276, 3.2418, 5.3583, 2.4534, 4.2719, 5.1839, 5.7333, 0.0000,\n",
            "         1.1640, 1.4471, 0.0000, 5.9928, 0.0000, 9.3015, 2.3337, 0.0000, 1.5843,\n",
            "         2.3681, 0.0000, 5.8847, 0.0000, 4.3238, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 7.8415, 0.0000, 7.1043]], grad_fn=<ReluBackward0>)\n",
            "x fc_pi output tensor([[ 54.1400, -34.8060,   4.3859, -36.7048]], grad_fn=<AddmmBackward0>)\n",
            "x F.softmax(x, dim=softmax_dim) tensor([[ 54.1400, -34.8060,   4.3859, -36.7048]], grad_fn=<AddmmBackward0>)\n",
            "prob tensor([[1.0000e+00, 2.3510e-39, 2.4663e-22, 3.5206e-40]],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "\n",
            "\n",
            "▶▶▶ 3800  : max cum reward :  1887  epsilon = 0.6199900000000419\n",
            "\n",
            "\n",
            "▶▶▶3801번째 에피소드 시작, env 초기화 완료.\n",
            "가져와야 할 아이템 : ['B', 'G', 'H', 'O']\n",
            "\n",
            "현재 state         :  [9 4 4 0]\n",
            "tensor([9, 4, 4, 0])\n",
            "tensor([9., 4., 4., 0.])\n",
            "end input\n",
            "input x tensor([9., 4., 4., 0.])\n",
            "x F.relu output tensor([0.0000e+00, 2.8269e+00, 3.4065e+00, 3.9487e+00, 8.2641e-03, 0.0000e+00,\n",
            "        0.0000e+00, 1.1295e+00, 0.0000e+00, 0.0000e+00, 4.1312e+00, 2.6917e+00,\n",
            "        2.8498e+00, 0.0000e+00, 4.2174e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 4.3574e+00, 0.0000e+00, 0.0000e+00, 4.0435e+00, 5.9878e+00,\n",
            "        3.8150e+00, 5.5603e+00, 2.5625e+00, 5.0267e+00, 0.0000e+00, 4.8371e+00,\n",
            "        0.0000e+00, 2.8127e+00, 1.5316e+00, 2.2508e+00, 3.9980e+00, 2.9748e+00,\n",
            "        3.2970e+00, 3.8082e+00, 5.2094e+00, 0.0000e+00, 7.4014e-01, 4.1306e+00,\n",
            "        0.0000e+00, 0.0000e+00, 4.8382e+00, 1.6377e+00, 0.0000e+00, 4.4806e+00,\n",
            "        0.0000e+00, 0.0000e+00, 1.3141e+00, 0.0000e+00, 5.7961e+00, 3.8378e+00,\n",
            "        0.0000e+00, 0.0000e+00, 3.9216e+00, 1.6323e-01, 4.5227e+00, 0.0000e+00,\n",
            "        5.6828e+00, 8.5228e-01, 3.8784e+00, 2.7667e+00, 2.2491e+00, 8.3297e-01,\n",
            "        0.0000e+00, 3.4674e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.6825e+00,\n",
            "        0.0000e+00, 2.8106e-01, 1.6185e+00, 0.0000e+00, 1.8830e+00, 0.0000e+00,\n",
            "        4.0914e+00, 6.4500e-02, 5.2834e+00, 2.1065e+00, 0.0000e+00, 5.5203e+00,\n",
            "        0.0000e+00, 4.8468e+00, 4.3579e-01, 6.7266e+00, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 2.9037e+00, 0.0000e+00, 5.3997e+00, 0.0000e+00, 4.6293e+00,\n",
            "        0.0000e+00, 9.2717e-01, 3.6021e+00, 0.0000e+00, 0.0000e+00, 5.2448e+00,\n",
            "        1.4544e-01, 5.8882e+00, 3.5116e+00, 0.0000e+00, 7.6801e-01, 0.0000e+00,\n",
            "        1.9988e+00, 5.1401e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.5432e+00,\n",
            "        4.1506e+00, 5.3433e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.8933e+00,\n",
            "        0.0000e+00, 3.0489e+00, 0.0000e+00, 5.0852e+00, 3.1449e+00, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 5.2593e+00, 4.9377e+00, 0.0000e+00, 2.3518e+00,\n",
            "        2.9624e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.4272e+00, 2.1405e+00,\n",
            "        3.7493e+00, 1.3218e+00, 0.0000e+00, 0.0000e+00, 3.6221e+00, 0.0000e+00,\n",
            "        1.2994e+00, 2.8152e+00, 0.0000e+00, 7.1707e+00, 3.6360e+00, 1.6200e+00,\n",
            "        0.0000e+00, 7.5010e+00, 0.0000e+00, 5.3455e+00, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 4.9144e+00, 1.9513e+00, 5.4087e+00, 0.0000e+00, 2.6722e+00,\n",
            "        0.0000e+00, 4.1926e+00, 2.9567e+00, 0.0000e+00, 3.4445e+00, 0.0000e+00,\n",
            "        5.0482e+00, 0.0000e+00, 4.3148e-01, 0.0000e+00, 4.7842e+00, 0.0000e+00,\n",
            "        0.0000e+00, 3.9453e+00, 6.9993e+00, 0.0000e+00, 6.4784e+00, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        2.1394e+00, 0.0000e+00, 2.8514e+00, 0.0000e+00, 0.0000e+00, 1.4562e+00,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 2.8524e+00, 3.6987e+00, 3.4693e+00, 0.0000e+00, 3.2289e+00,\n",
            "        5.7014e+00, 3.5403e+00, 0.0000e+00, 4.2109e+00, 0.0000e+00, 2.2405e+00,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 1.1871e+00, 0.0000e+00, 2.7960e+00,\n",
            "        0.0000e+00, 3.2812e+00, 0.0000e+00, 7.0289e-01, 1.2240e+00, 0.0000e+00,\n",
            "        1.9764e+00, 0.0000e+00, 0.0000e+00, 5.4946e+00, 6.9675e+00, 3.3120e+00,\n",
            "        5.2457e+00, 2.5318e+00, 4.6136e+00, 4.8169e+00, 5.6724e+00, 0.0000e+00,\n",
            "        7.1725e-01, 9.5421e-01, 0.0000e+00, 5.7193e+00, 0.0000e+00, 8.7457e+00,\n",
            "        2.2956e+00, 0.0000e+00, 1.8356e+00, 2.1845e+00, 0.0000e+00, 5.3126e+00,\n",
            "        0.0000e+00, 3.9320e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 7.2242e+00, 0.0000e+00, 6.9910e+00],\n",
            "       grad_fn=<ReluBackward0>)\n",
            "x fc_pi output tensor([ 53.3826, -34.0535,   3.5954, -35.0110], grad_fn=<AddBackward0>)\n",
            "x F.softmax(x, dim=softmax_dim) tensor([ 53.3826, -34.0535,   3.5954, -35.0110], grad_fn=<AddBackward0>)\n",
            "prob tensor([1.0000e+00, 1.0642e-38, 2.3863e-22, 4.0848e-39],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "step 데이터 : [8 4 4 0] -1 -1 False False\n",
            "put_data    : [9 4 4 0] 0 -1 [8 4 4 0] False\n",
            "tensor([8, 4, 4, 0])\n",
            "tensor([8., 4., 4., 0.])\n",
            "end input\n",
            "input x tensor([8., 4., 4., 0.])\n",
            "x F.relu output tensor([0.0000, 2.4674, 3.0660, 3.3209, 0.3224, 0.0000, 0.0000, 1.0020, 0.0000,\n",
            "        0.0000, 3.5743, 2.3443, 2.7461, 0.0000, 0.6628, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 4.1205, 0.0000, 0.0000, 3.7815, 5.3571, 3.6137, 5.2441, 2.0130,\n",
            "        4.4863, 0.0000, 4.4917, 0.0000, 2.5434, 1.4482, 1.9680, 3.8263, 2.8897,\n",
            "        2.7107, 3.5258, 4.7576, 0.0000, 0.9054, 3.7364, 0.0000, 0.0000, 4.5714,\n",
            "        1.5740, 0.0000, 4.1404, 0.0000, 0.0000, 1.1920, 0.0000, 5.4630, 3.3834,\n",
            "        0.0000, 0.0000, 3.6506, 0.1134, 4.3506, 0.0000, 5.3061, 1.1542, 3.5344,\n",
            "        2.6479, 1.8721, 0.8566, 0.0000, 0.5577, 0.0000, 0.0000, 0.0000, 2.3164,\n",
            "        0.0000, 0.0000, 1.5220, 0.0000, 1.8790, 0.0000, 3.6066, 0.0481, 5.0918,\n",
            "        2.1790, 0.0000, 4.9901, 0.0000, 4.4555, 0.6058, 6.2382, 0.0000, 0.0000,\n",
            "        0.0000, 2.4679, 0.0000, 4.9675, 0.0000, 4.1892, 0.0000, 0.7081, 3.2259,\n",
            "        0.0000, 0.0000, 4.7132, 0.1282, 5.4547, 3.3187, 0.0000, 0.6549, 0.0000,\n",
            "        2.1077, 4.9113, 0.0000, 0.0000, 0.0000, 2.3294, 4.1475, 5.1768, 0.0000,\n",
            "        0.0000, 0.0000, 2.8320, 0.0000, 3.0875, 0.0000, 4.9535, 3.0968, 0.0000,\n",
            "        0.0000, 0.0000, 4.9035, 4.5170, 0.0000, 2.2418, 2.7407, 0.0000, 0.0000,\n",
            "        0.0000, 3.0446, 1.8088, 3.4596, 1.1153, 0.0000, 0.0000, 3.5314, 0.0000,\n",
            "        1.2988, 2.4491, 0.0000, 6.6735, 3.4746, 1.3225, 0.0000, 7.1744, 0.0000,\n",
            "        4.7843, 0.0000, 0.0000, 0.0000, 4.5729, 1.9579, 4.8316, 0.0000, 2.2566,\n",
            "        0.0000, 3.8379, 3.0671, 0.0000, 3.3670, 0.0000, 4.6494, 0.0000, 0.2995,\n",
            "        0.0000, 4.5675, 0.0000, 0.0000, 3.6419, 6.5387, 0.0000, 5.9570, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 2.0151, 0.0000, 2.6272,\n",
            "        0.0000, 0.0000, 1.0043, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 2.4548, 3.3563, 3.1835, 0.0000, 3.0082, 5.2570, 3.5293, 0.0000,\n",
            "        3.9638, 0.0000, 2.2524, 0.0000, 0.0000, 0.0000, 1.2903, 0.0000, 2.7040,\n",
            "        0.0000, 3.2124, 0.0000, 0.7184, 1.0988, 0.0000, 1.9813, 0.0000, 0.0000,\n",
            "        4.9389, 6.5348, 3.0164, 4.6814, 2.1527, 4.1726, 4.4174, 5.2821, 0.0000,\n",
            "        0.7979, 1.1151, 0.0000, 5.4423, 0.0000, 8.2110, 2.1301, 0.0000, 1.5129,\n",
            "        1.9728, 0.0000, 5.1722, 0.0000, 3.5130, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 7.0088, 0.0000, 6.5065], grad_fn=<ReluBackward0>)\n",
            "x fc_pi output tensor([ 49.2083, -31.5249,   3.7365, -32.7824], grad_fn=<AddBackward0>)\n",
            "x F.softmax(x, dim=softmax_dim) tensor([ 49.2083, -31.5249,   3.7365, -32.7824], grad_fn=<AddBackward0>)\n",
            "prob tensor([1.0000e+00, 8.6702e-36, 1.7859e-20, 2.4654e-36],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "step 데이터 : [7 4 4 0] -1 -2 False False\n",
            "put_data    : [8 4 4 0] 0 -1 [7 4 4 0] False\n",
            "tensor([7, 4, 4, 0])\n",
            "tensor([7., 4., 4., 0.])\n",
            "end input\n",
            "input x tensor([7., 4., 4., 0.])\n",
            "x F.relu output tensor([0.0000, 2.1080, 2.7254, 2.6930, 0.6366, 0.0000, 0.0000, 0.8745, 0.0000,\n",
            "        0.0000, 3.0174, 1.9968, 2.6425, 0.0000, 0.9038, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 3.8837, 0.0000, 0.0000, 3.5194, 4.7263, 3.4125, 4.9278, 1.4634,\n",
            "        3.9459, 0.0000, 4.1463, 0.0000, 2.2740, 1.3648, 1.6852, 3.6546, 2.8045,\n",
            "        2.1245, 3.2434, 4.3057, 0.0000, 1.0707, 3.3422, 0.0000, 0.0000, 4.3045,\n",
            "        1.5104, 0.0000, 3.8003, 0.0000, 0.0000, 1.0699, 0.0000, 5.1298, 2.9290,\n",
            "        0.0000, 0.0000, 3.3795, 0.0636, 4.1786, 0.0000, 4.9293, 1.4562, 3.1903,\n",
            "        2.5291, 1.4950, 0.8802, 0.0000, 0.7687, 0.0000, 0.0000, 0.0000, 1.9502,\n",
            "        0.0000, 0.0000, 1.4254, 0.0000, 1.8750, 0.0000, 3.1219, 0.0317, 4.9002,\n",
            "        2.2515, 0.0000, 4.4600, 0.0000, 4.0642, 0.7757, 5.7497, 0.0000, 0.0000,\n",
            "        0.0000, 2.0321, 0.0000, 4.5353, 0.0000, 3.7492, 0.0000, 0.4890, 2.8497,\n",
            "        0.0000, 0.0000, 4.1816, 0.1109, 5.0212, 3.1259, 0.0000, 0.5418, 0.0000,\n",
            "        2.2167, 4.6826, 0.0000, 0.0000, 0.0000, 2.1156, 4.1444, 5.0103, 0.0000,\n",
            "        0.0000, 0.0000, 2.7707, 0.0000, 3.1261, 0.0000, 4.8218, 3.0486, 0.0000,\n",
            "        0.0000, 0.1943, 4.5477, 4.0963, 0.0000, 2.1318, 2.5190, 0.0000, 0.0000,\n",
            "        0.0000, 2.6619, 1.4772, 3.1698, 0.9087, 0.0000, 0.0000, 3.4406, 0.0000,\n",
            "        1.2982, 2.0830, 0.0000, 6.1763, 3.3132, 1.0250, 0.0000, 6.8479, 0.1051,\n",
            "        4.2231, 0.0000, 0.0000, 0.0000, 4.2313, 1.9645, 4.2544, 0.0000, 1.8409,\n",
            "        0.0000, 3.4833, 3.1775, 0.0000, 3.2895, 0.0000, 4.2506, 0.0000, 0.1676,\n",
            "        0.0000, 4.3508, 0.0000, 0.0000, 3.3385, 6.0781, 0.0000, 5.4357, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.8909, 0.0000, 2.4030,\n",
            "        0.0000, 0.0000, 0.5524, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 2.0572, 3.0138, 2.8977, 0.0000, 2.7874, 4.8126, 3.5183, 0.0000,\n",
            "        3.7167, 0.0000, 2.2644, 0.0000, 0.0000, 0.0000, 1.3935, 0.0000, 2.6119,\n",
            "        0.0000, 3.1436, 0.0000, 0.7340, 0.9736, 0.0000, 1.9862, 0.0000, 0.0000,\n",
            "        4.3831, 6.1020, 2.7208, 4.1171, 1.7737, 3.7317, 4.0180, 4.8919, 0.0000,\n",
            "        0.8786, 1.2760, 0.0000, 5.1654, 0.0000, 7.6762, 1.9646, 0.0000, 1.1903,\n",
            "        1.7610, 0.0000, 5.0318, 0.0000, 3.0940, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 6.7934, 0.0000, 6.0221], grad_fn=<ReluBackward0>)\n",
            "x fc_pi output tensor([ 45.0578, -29.0196,   3.8724, -30.5467], grad_fn=<AddBackward0>)\n",
            "x F.softmax(x, dim=softmax_dim) tensor([ 45.0578, -29.0196,   3.8724, -30.5467], grad_fn=<AddBackward0>)\n",
            "prob tensor([1.0000e+00, 6.7392e-33, 1.2984e-18, 1.4635e-33],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "step 데이터 : [6 4 4 0] -100 -102 True False\n",
            "put_data    : [7 4 4 0] 0 -100 [6 4 4 0] True\n",
            "input x tensor([[9., 4., 4., 0.],\n",
            "        [8., 4., 4., 0.],\n",
            "        [7., 4., 4., 0.]])\n",
            "x F.relu output tensor([[0.0000e+00, 2.8269e+00, 3.4065e+00, 3.9487e+00, 8.2641e-03, 0.0000e+00,\n",
            "         0.0000e+00, 1.1295e+00, 0.0000e+00, 0.0000e+00, 4.1312e+00, 2.6917e+00,\n",
            "         2.8498e+00, 0.0000e+00, 4.2174e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "         0.0000e+00, 4.3574e+00, 0.0000e+00, 0.0000e+00, 4.0435e+00, 5.9878e+00,\n",
            "         3.8150e+00, 5.5603e+00, 2.5625e+00, 5.0267e+00, 0.0000e+00, 4.8371e+00,\n",
            "         0.0000e+00, 2.8127e+00, 1.5316e+00, 2.2508e+00, 3.9980e+00, 2.9748e+00,\n",
            "         3.2970e+00, 3.8082e+00, 5.2094e+00, 0.0000e+00, 7.4014e-01, 4.1306e+00,\n",
            "         0.0000e+00, 0.0000e+00, 4.8382e+00, 1.6377e+00, 0.0000e+00, 4.4806e+00,\n",
            "         0.0000e+00, 0.0000e+00, 1.3141e+00, 0.0000e+00, 5.7961e+00, 3.8378e+00,\n",
            "         0.0000e+00, 0.0000e+00, 3.9216e+00, 1.6323e-01, 4.5227e+00, 0.0000e+00,\n",
            "         5.6828e+00, 8.5228e-01, 3.8784e+00, 2.7667e+00, 2.2491e+00, 8.3297e-01,\n",
            "         0.0000e+00, 3.4674e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.6825e+00,\n",
            "         0.0000e+00, 2.8106e-01, 1.6185e+00, 0.0000e+00, 1.8830e+00, 0.0000e+00,\n",
            "         4.0914e+00, 6.4500e-02, 5.2834e+00, 2.1065e+00, 0.0000e+00, 5.5203e+00,\n",
            "         0.0000e+00, 4.8468e+00, 4.3579e-01, 6.7266e+00, 0.0000e+00, 0.0000e+00,\n",
            "         0.0000e+00, 2.9037e+00, 0.0000e+00, 5.3997e+00, 0.0000e+00, 4.6293e+00,\n",
            "         0.0000e+00, 9.2717e-01, 3.6021e+00, 0.0000e+00, 0.0000e+00, 5.2448e+00,\n",
            "         1.4544e-01, 5.8882e+00, 3.5116e+00, 0.0000e+00, 7.6801e-01, 0.0000e+00,\n",
            "         1.9988e+00, 5.1401e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.5432e+00,\n",
            "         4.1506e+00, 5.3433e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.8933e+00,\n",
            "         0.0000e+00, 3.0489e+00, 0.0000e+00, 5.0852e+00, 3.1449e+00, 0.0000e+00,\n",
            "         0.0000e+00, 0.0000e+00, 5.2593e+00, 4.9377e+00, 0.0000e+00, 2.3518e+00,\n",
            "         2.9624e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.4272e+00, 2.1405e+00,\n",
            "         3.7493e+00, 1.3218e+00, 0.0000e+00, 0.0000e+00, 3.6221e+00, 0.0000e+00,\n",
            "         1.2994e+00, 2.8152e+00, 0.0000e+00, 7.1707e+00, 3.6360e+00, 1.6200e+00,\n",
            "         0.0000e+00, 7.5010e+00, 0.0000e+00, 5.3455e+00, 0.0000e+00, 0.0000e+00,\n",
            "         0.0000e+00, 4.9144e+00, 1.9513e+00, 5.4087e+00, 0.0000e+00, 2.6722e+00,\n",
            "         0.0000e+00, 4.1926e+00, 2.9567e+00, 0.0000e+00, 3.4445e+00, 0.0000e+00,\n",
            "         5.0482e+00, 0.0000e+00, 4.3148e-01, 0.0000e+00, 4.7842e+00, 0.0000e+00,\n",
            "         0.0000e+00, 3.9453e+00, 6.9993e+00, 0.0000e+00, 6.4784e+00, 0.0000e+00,\n",
            "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "         2.1394e+00, 0.0000e+00, 2.8514e+00, 0.0000e+00, 0.0000e+00, 1.4562e+00,\n",
            "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "         0.0000e+00, 2.8524e+00, 3.6987e+00, 3.4693e+00, 0.0000e+00, 3.2289e+00,\n",
            "         5.7014e+00, 3.5403e+00, 0.0000e+00, 4.2109e+00, 0.0000e+00, 2.2405e+00,\n",
            "         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.1871e+00, 0.0000e+00, 2.7960e+00,\n",
            "         0.0000e+00, 3.2812e+00, 0.0000e+00, 7.0289e-01, 1.2240e+00, 0.0000e+00,\n",
            "         1.9764e+00, 0.0000e+00, 0.0000e+00, 5.4946e+00, 6.9675e+00, 3.3120e+00,\n",
            "         5.2457e+00, 2.5318e+00, 4.6136e+00, 4.8169e+00, 5.6724e+00, 0.0000e+00,\n",
            "         7.1725e-01, 9.5421e-01, 0.0000e+00, 5.7193e+00, 0.0000e+00, 8.7457e+00,\n",
            "         2.2956e+00, 0.0000e+00, 1.8356e+00, 2.1845e+00, 0.0000e+00, 5.3126e+00,\n",
            "         0.0000e+00, 3.9320e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "         0.0000e+00, 7.2242e+00, 0.0000e+00, 6.9910e+00],\n",
            "        [0.0000e+00, 2.4674e+00, 3.0660e+00, 3.3209e+00, 3.2244e-01, 0.0000e+00,\n",
            "         0.0000e+00, 1.0020e+00, 0.0000e+00, 0.0000e+00, 3.5743e+00, 2.3443e+00,\n",
            "         2.7461e+00, 0.0000e+00, 6.6276e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "         0.0000e+00, 4.1205e+00, 0.0000e+00, 0.0000e+00, 3.7815e+00, 5.3571e+00,\n",
            "         3.6137e+00, 5.2441e+00, 2.0130e+00, 4.4863e+00, 0.0000e+00, 4.4917e+00,\n",
            "         0.0000e+00, 2.5434e+00, 1.4482e+00, 1.9680e+00, 3.8263e+00, 2.8897e+00,\n",
            "         2.7107e+00, 3.5258e+00, 4.7576e+00, 0.0000e+00, 9.0541e-01, 3.7364e+00,\n",
            "         0.0000e+00, 0.0000e+00, 4.5714e+00, 1.5740e+00, 0.0000e+00, 4.1404e+00,\n",
            "         0.0000e+00, 0.0000e+00, 1.1920e+00, 0.0000e+00, 5.4630e+00, 3.3834e+00,\n",
            "         0.0000e+00, 0.0000e+00, 3.6506e+00, 1.1340e-01, 4.3506e+00, 0.0000e+00,\n",
            "         5.3061e+00, 1.1542e+00, 3.5344e+00, 2.6479e+00, 1.8721e+00, 8.5657e-01,\n",
            "         0.0000e+00, 5.5772e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.3164e+00,\n",
            "         0.0000e+00, 0.0000e+00, 1.5220e+00, 0.0000e+00, 1.8790e+00, 0.0000e+00,\n",
            "         3.6066e+00, 4.8092e-02, 5.0918e+00, 2.1790e+00, 0.0000e+00, 4.9901e+00,\n",
            "         0.0000e+00, 4.4555e+00, 6.0577e-01, 6.2382e+00, 0.0000e+00, 0.0000e+00,\n",
            "         0.0000e+00, 2.4679e+00, 0.0000e+00, 4.9675e+00, 0.0000e+00, 4.1892e+00,\n",
            "         0.0000e+00, 7.0809e-01, 3.2259e+00, 0.0000e+00, 0.0000e+00, 4.7132e+00,\n",
            "         1.2815e-01, 5.4547e+00, 3.3187e+00, 0.0000e+00, 6.5491e-01, 0.0000e+00,\n",
            "         2.1077e+00, 4.9113e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.3294e+00,\n",
            "         4.1475e+00, 5.1768e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.8320e+00,\n",
            "         0.0000e+00, 3.0875e+00, 0.0000e+00, 4.9535e+00, 3.0968e+00, 0.0000e+00,\n",
            "         0.0000e+00, 0.0000e+00, 4.9035e+00, 4.5170e+00, 0.0000e+00, 2.2418e+00,\n",
            "         2.7407e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.0446e+00, 1.8088e+00,\n",
            "         3.4596e+00, 1.1153e+00, 0.0000e+00, 0.0000e+00, 3.5314e+00, 0.0000e+00,\n",
            "         1.2988e+00, 2.4491e+00, 0.0000e+00, 6.6735e+00, 3.4746e+00, 1.3225e+00,\n",
            "         0.0000e+00, 7.1744e+00, 0.0000e+00, 4.7843e+00, 0.0000e+00, 0.0000e+00,\n",
            "         0.0000e+00, 4.5729e+00, 1.9579e+00, 4.8316e+00, 0.0000e+00, 2.2566e+00,\n",
            "         0.0000e+00, 3.8379e+00, 3.0671e+00, 0.0000e+00, 3.3670e+00, 0.0000e+00,\n",
            "         4.6494e+00, 0.0000e+00, 2.9953e-01, 0.0000e+00, 4.5675e+00, 0.0000e+00,\n",
            "         0.0000e+00, 3.6419e+00, 6.5387e+00, 0.0000e+00, 5.9570e+00, 0.0000e+00,\n",
            "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "         2.0151e+00, 0.0000e+00, 2.6272e+00, 0.0000e+00, 0.0000e+00, 1.0043e+00,\n",
            "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "         0.0000e+00, 2.4548e+00, 3.3563e+00, 3.1835e+00, 0.0000e+00, 3.0082e+00,\n",
            "         5.2570e+00, 3.5293e+00, 0.0000e+00, 3.9638e+00, 0.0000e+00, 2.2524e+00,\n",
            "         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.2903e+00, 0.0000e+00, 2.7040e+00,\n",
            "         0.0000e+00, 3.2124e+00, 0.0000e+00, 7.1845e-01, 1.0988e+00, 0.0000e+00,\n",
            "         1.9813e+00, 0.0000e+00, 0.0000e+00, 4.9389e+00, 6.5348e+00, 3.0164e+00,\n",
            "         4.6814e+00, 2.1527e+00, 4.1726e+00, 4.4174e+00, 5.2821e+00, 0.0000e+00,\n",
            "         7.9790e-01, 1.1151e+00, 0.0000e+00, 5.4423e+00, 0.0000e+00, 8.2110e+00,\n",
            "         2.1301e+00, 0.0000e+00, 1.5129e+00, 1.9728e+00, 0.0000e+00, 5.1722e+00,\n",
            "         0.0000e+00, 3.5130e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "         0.0000e+00, 7.0088e+00, 0.0000e+00, 6.5065e+00],\n",
            "        [0.0000e+00, 2.1080e+00, 2.7254e+00, 2.6930e+00, 6.3662e-01, 0.0000e+00,\n",
            "         0.0000e+00, 8.7449e-01, 0.0000e+00, 0.0000e+00, 3.0174e+00, 1.9968e+00,\n",
            "         2.6425e+00, 0.0000e+00, 9.0378e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "         0.0000e+00, 3.8837e+00, 0.0000e+00, 0.0000e+00, 3.5194e+00, 4.7263e+00,\n",
            "         3.4125e+00, 4.9278e+00, 1.4634e+00, 3.9459e+00, 0.0000e+00, 4.1463e+00,\n",
            "         0.0000e+00, 2.2740e+00, 1.3648e+00, 1.6852e+00, 3.6546e+00, 2.8045e+00,\n",
            "         2.1245e+00, 3.2434e+00, 4.3057e+00, 0.0000e+00, 1.0707e+00, 3.3422e+00,\n",
            "         0.0000e+00, 0.0000e+00, 4.3045e+00, 1.5104e+00, 0.0000e+00, 3.8003e+00,\n",
            "         0.0000e+00, 0.0000e+00, 1.0699e+00, 0.0000e+00, 5.1298e+00, 2.9290e+00,\n",
            "         0.0000e+00, 0.0000e+00, 3.3795e+00, 6.3561e-02, 4.1786e+00, 0.0000e+00,\n",
            "         4.9293e+00, 1.4562e+00, 3.1903e+00, 2.5291e+00, 1.4950e+00, 8.8017e-01,\n",
            "         0.0000e+00, 7.6870e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.9502e+00,\n",
            "         0.0000e+00, 0.0000e+00, 1.4254e+00, 0.0000e+00, 1.8750e+00, 0.0000e+00,\n",
            "         3.1219e+00, 3.1683e-02, 4.9002e+00, 2.2515e+00, 0.0000e+00, 4.4600e+00,\n",
            "         0.0000e+00, 4.0642e+00, 7.7575e-01, 5.7497e+00, 0.0000e+00, 0.0000e+00,\n",
            "         0.0000e+00, 2.0321e+00, 0.0000e+00, 4.5353e+00, 0.0000e+00, 3.7492e+00,\n",
            "         0.0000e+00, 4.8901e-01, 2.8497e+00, 0.0000e+00, 0.0000e+00, 4.1816e+00,\n",
            "         1.1087e-01, 5.0212e+00, 3.1259e+00, 0.0000e+00, 5.4181e-01, 0.0000e+00,\n",
            "         2.2167e+00, 4.6826e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.1156e+00,\n",
            "         4.1444e+00, 5.0103e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.7707e+00,\n",
            "         0.0000e+00, 3.1261e+00, 0.0000e+00, 4.8218e+00, 3.0486e+00, 0.0000e+00,\n",
            "         0.0000e+00, 1.9433e-01, 4.5477e+00, 4.0963e+00, 0.0000e+00, 2.1318e+00,\n",
            "         2.5190e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.6619e+00, 1.4772e+00,\n",
            "         3.1698e+00, 9.0872e-01, 0.0000e+00, 0.0000e+00, 3.4406e+00, 0.0000e+00,\n",
            "         1.2982e+00, 2.0830e+00, 0.0000e+00, 6.1763e+00, 3.3132e+00, 1.0250e+00,\n",
            "         0.0000e+00, 6.8479e+00, 1.0510e-01, 4.2231e+00, 0.0000e+00, 0.0000e+00,\n",
            "         0.0000e+00, 4.2313e+00, 1.9645e+00, 4.2544e+00, 0.0000e+00, 1.8409e+00,\n",
            "         0.0000e+00, 3.4833e+00, 3.1775e+00, 0.0000e+00, 3.2895e+00, 0.0000e+00,\n",
            "         4.2506e+00, 0.0000e+00, 1.6758e-01, 0.0000e+00, 4.3508e+00, 0.0000e+00,\n",
            "         0.0000e+00, 3.3385e+00, 6.0781e+00, 0.0000e+00, 5.4357e+00, 0.0000e+00,\n",
            "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "         1.8909e+00, 0.0000e+00, 2.4030e+00, 0.0000e+00, 0.0000e+00, 5.5241e-01,\n",
            "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "         0.0000e+00, 2.0572e+00, 3.0138e+00, 2.8977e+00, 0.0000e+00, 2.7874e+00,\n",
            "         4.8126e+00, 3.5183e+00, 0.0000e+00, 3.7167e+00, 0.0000e+00, 2.2644e+00,\n",
            "         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.3935e+00, 0.0000e+00, 2.6119e+00,\n",
            "         0.0000e+00, 3.1436e+00, 0.0000e+00, 7.3400e-01, 9.7361e-01, 0.0000e+00,\n",
            "         1.9862e+00, 0.0000e+00, 0.0000e+00, 4.3831e+00, 6.1020e+00, 2.7208e+00,\n",
            "         4.1171e+00, 1.7737e+00, 3.7317e+00, 4.0180e+00, 4.8919e+00, 0.0000e+00,\n",
            "         8.7855e-01, 1.2760e+00, 0.0000e+00, 5.1654e+00, 0.0000e+00, 7.6762e+00,\n",
            "         1.9646e+00, 0.0000e+00, 1.1903e+00, 1.7610e+00, 0.0000e+00, 5.0318e+00,\n",
            "         0.0000e+00, 3.0940e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "         0.0000e+00, 6.7934e+00, 0.0000e+00, 6.0221e+00]],\n",
            "       grad_fn=<ReluBackward0>)\n",
            "x fc_pi output tensor([[ 53.3826, -34.0534,   3.5954, -35.0110],\n",
            "        [ 49.2083, -31.5249,   3.7365, -32.7824],\n",
            "        [ 45.0578, -29.0196,   3.8724, -30.5467]], grad_fn=<AddmmBackward0>)\n",
            "x F.softmax(x, dim=softmax_dim) tensor([[ 53.3826, -34.0534,   3.5954, -35.0110],\n",
            "        [ 49.2083, -31.5249,   3.7365, -32.7824],\n",
            "        [ 45.0578, -29.0196,   3.8724, -30.5467]], grad_fn=<AddmmBackward0>)\n",
            "prob tensor([[1.0000e+00, 1.0642e-38, 2.3863e-22, 4.0848e-39],\n",
            "        [1.0000e+00, 8.6702e-36, 1.7859e-20, 2.4654e-36],\n",
            "        [1.0000e+00, 6.7393e-33, 1.2984e-18, 1.4635e-33]],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "\n",
            "\n",
            "▶▶▶ 3801  : max cum reward :  1887  epsilon = 0.6198900000000419\n",
            "\n",
            "\n",
            "▶▶▶3802번째 에피소드 시작, env 초기화 완료.\n",
            "가져와야 할 아이템 : ['C', 'F', 'I', 'J', 'L', 'N', 'P']\n",
            "\n",
            "현재 state         :  [9 4 3 0]\n",
            "step 데이터 : [9 3 3 0] -100 -100 True False\n",
            "put_data    : [9 4 3 0] 2 -100 [9 3 3 0] True\n",
            "input x tensor([[9., 4., 3., 0.]])\n",
            "x F.relu output tensor([[0.0000, 3.1459, 3.7097, 4.0743, 0.0000, 0.1511, 0.0000, 1.3962, 0.0000,\n",
            "         0.0000, 4.0881, 3.0217, 2.8017, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 4.1878, 0.0000, 0.0000, 3.8348, 5.9022, 3.3720, 5.1839, 2.9379,\n",
            "         5.1333, 0.0000, 4.2757, 0.0000, 3.0516, 1.4444, 2.6925, 4.0987, 2.7906,\n",
            "         3.7089, 3.2505, 5.0978, 0.0000, 0.4137, 3.9128, 0.0000, 0.0000, 4.6075,\n",
            "         1.6151, 0.0000, 4.1271, 0.0000, 0.0000, 1.6993, 0.0000, 5.3088, 4.1829,\n",
            "         0.0000, 0.0000, 3.6108, 0.2289, 4.1764, 0.0000, 5.6398, 0.3243, 3.4102,\n",
            "         2.6399, 2.3956, 0.4372, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 2.9029,\n",
            "         0.0000, 0.5387, 1.6272, 0.0000, 1.9776, 0.0000, 4.3300, 0.0000, 4.8769,\n",
            "         1.6378, 0.0000, 5.4006, 0.0000, 4.4074, 0.1648, 6.6156, 0.0000, 0.0000,\n",
            "         0.0000, 3.0994, 0.0000, 5.5369, 0.0000, 4.2029, 0.0000, 1.0564, 3.4374,\n",
            "         0.0000, 0.0000, 5.4943, 0.3026, 5.7679, 3.5950, 0.0000, 1.0546, 0.0000,\n",
            "         1.4882, 4.9494, 0.0000, 0.1562, 0.0000, 2.8125, 3.7133, 4.9290, 0.0000,\n",
            "         0.0000, 0.0000, 2.9351, 0.0000, 2.6383, 0.0000, 4.5657, 2.6529, 0.0000,\n",
            "         0.0000, 0.0000, 5.2786, 5.2077, 0.0000, 2.2468, 2.9922, 0.0000, 0.0000,\n",
            "         0.0000, 3.4802, 2.1618, 3.8435, 1.1195, 0.0000, 0.0000, 3.3383, 0.0000,\n",
            "         1.3939, 2.8899, 0.0000, 7.0327, 3.3401, 1.7216, 0.0000, 6.9297, 0.1013,\n",
            "         5.3510, 0.0000, 0.0000, 0.0000, 4.8044, 1.8352, 5.7859, 0.0000, 2.8040,\n",
            "         0.0000, 3.9016, 2.6843, 0.0000, 3.0804, 0.0000, 5.3549, 0.0000, 0.7911,\n",
            "         0.0000, 4.5846, 0.0000, 0.0000, 4.0020, 6.8589, 0.0000, 6.2338, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.8393, 0.0000, 3.0301,\n",
            "         0.0000, 0.0000, 1.7879, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 3.1304, 3.3156, 3.6754, 0.0000, 3.2281, 5.7834, 3.0160, 0.0000,\n",
            "         3.6878, 0.0000, 1.7292, 0.0000, 0.0000, 0.0545, 1.0628, 0.0000, 2.5201,\n",
            "         0.0000, 3.1004, 0.0000, 1.0063, 1.6574, 0.0000, 1.5534, 0.0000, 0.0000,\n",
            "         5.2444, 6.4075, 3.3822, 5.1332, 2.6103, 4.9553, 4.4500, 5.6115, 0.0000,\n",
            "         0.2706, 0.4614, 0.0000, 5.4458, 0.0000, 8.1899, 2.2576, 0.0000, 2.0869,\n",
            "         2.0009, 0.0000, 4.7405, 0.0000, 3.5401, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 6.6068, 0.0000, 6.8777]], grad_fn=<ReluBackward0>)\n",
            "x fc_pi output tensor([[ 52.6206, -33.3155,   2.8269, -33.3317]], grad_fn=<AddmmBackward0>)\n",
            "x F.softmax(x, dim=softmax_dim) tensor([[ 52.6206, -33.3155,   2.8269, -33.3317]], grad_fn=<AddmmBackward0>)\n",
            "prob tensor([[1.0000e+00, 4.7690e-38, 2.3708e-22, 4.6927e-38]],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "\n",
            "\n",
            "▶▶▶ 3802  : max cum reward :  1887  epsilon = 0.6197900000000419\n",
            "\n",
            "\n",
            "▶▶▶3803번째 에피소드 시작, env 초기화 완료.\n",
            "가져와야 할 아이템 : ['A', 'F', 'G', 'J', 'P', 'Q']\n",
            "\n",
            "현재 state         :  [9 4 5 0]\n",
            "step 데이터 : [8 4 5 0] -1 -1 False False\n",
            "put_data    : [9 4 5 0] 0 -1 [8 4 5 0] False\n",
            "step 데이터 : [9 4 5 0] -1 -2 False False\n",
            "put_data    : [8 4 5 0] 1 -1 [9 4 5 0] False\n",
            "step 데이터 : [9 5 5 0] -100 -102 True False\n",
            "put_data    : [9 4 5 0] 3 -100 [9 5 5 0] True\n",
            "input x tensor([[9., 4., 5., 0.],\n",
            "        [8., 4., 5., 0.],\n",
            "        [9., 4., 5., 0.]])\n",
            "x F.relu output tensor([[0.0000, 2.5088, 3.1033, 3.8234, 0.3777, 0.0000, 0.0000, 0.8638, 0.0000,\n",
            "         0.0000, 4.1746, 2.3619, 2.8985, 0.0000, 0.9135, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 4.5262, 0.0000, 0.0000, 4.2531, 6.0741, 4.2580, 5.9372, 2.1871,\n",
            "         4.9207, 0.0000, 5.3997, 0.0000, 2.5751, 1.6186, 1.8092, 3.8972, 3.1593,\n",
            "         2.8852, 4.3662, 5.3221, 0.0000, 1.0669, 4.3492, 0.0000, 0.0000, 5.0696,\n",
            "         1.6601, 0.0000, 4.8342, 0.0000, 0.0000, 0.9286, 0.0000, 6.2834, 3.4938,\n",
            "         0.0000, 0.0000, 4.2327, 0.0976, 4.8693, 0.0000, 5.7268, 1.3786, 4.3469,\n",
            "         2.8933, 2.1027, 1.2282, 0.0000, 0.7848, 0.0000, 0.0000, 0.0000, 2.4618,\n",
            "         0.0000, 0.0235, 1.6094, 0.0000, 1.7883, 0.0000, 3.8534, 0.2407, 5.6903,\n",
            "         2.5766, 0.0000, 5.6401, 0.0000, 5.2871, 0.7060, 6.8375, 0.0000, 0.0000,\n",
            "         0.0000, 2.7092, 0.0000, 5.2626, 0.0000, 5.0561, 0.0000, 0.7983, 3.7668,\n",
            "         0.0000, 0.0000, 4.9958, 0.0000, 6.0096, 3.4287, 0.0000, 0.4819, 0.0000,\n",
            "         2.5091, 5.3308, 0.0000, 0.0000, 0.0000, 2.2740, 4.5882, 5.7575, 0.0000,\n",
            "         0.0000, 0.0000, 2.8518, 0.0000, 3.4595, 0.0000, 5.6049, 3.6371, 0.0000,\n",
            "         0.0000, 0.0000, 5.2410, 4.6689, 0.0000, 2.4570, 2.9333, 0.0000, 0.0000,\n",
            "         0.0000, 3.3747, 2.1194, 3.6560, 1.5228, 0.0000, 0.0000, 3.9064, 0.0000,\n",
            "         1.2046, 2.7404, 0.0000, 7.3086, 3.9320, 1.5189, 0.0000, 8.0726, 0.0000,\n",
            "         5.3404, 0.0000, 0.0000, 0.0000, 5.0251, 2.0674, 5.0324, 0.0000, 2.5411,\n",
            "         0.0000, 4.4841, 3.2289, 0.0315, 3.8090, 0.0000, 4.7415, 0.0000, 0.0722,\n",
            "         0.0000, 4.9838, 0.0000, 0.0000, 3.8892, 7.1397, 0.0000, 6.7232, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 2.4406, 0.0000, 2.6737,\n",
            "         0.0000, 0.0000, 1.1246, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 2.5743, 4.0824, 3.2633, 0.0000, 3.2307, 5.6201, 4.0660, 0.0000,\n",
            "         4.7344, 0.0000, 2.7518, 0.0000, 0.0000, 0.0000, 1.3110, 0.0000, 3.0725,\n",
            "         0.0000, 3.4618, 0.0000, 0.4007, 0.7905, 0.0000, 2.3991, 0.0000, 0.0000,\n",
            "         5.7446, 7.5275, 3.2420, 5.3593, 2.4542, 4.2731, 5.1839, 5.7346, 0.0000,\n",
            "         1.1625, 1.4454, 0.0000, 5.9927, 0.0000, 9.3023, 2.3338, 0.0000, 1.5847,\n",
            "         2.3698, 0.0000, 5.8856, 0.0000, 4.3243, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 7.8420, 0.0000, 7.1048],\n",
            "        [0.0000, 2.1493, 2.7628, 3.1956, 0.6918, 0.0000, 0.0000, 0.7362, 0.0000,\n",
            "         0.0000, 3.6177, 2.0144, 2.7948, 0.0000, 1.1545, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 4.2894, 0.0000, 0.0000, 3.9910, 5.4433, 4.0567, 5.6209, 1.6376,\n",
            "         4.3803, 0.0000, 5.0543, 0.0000, 2.3057, 1.5352, 1.5264, 3.7255, 3.0742,\n",
            "         2.2989, 4.0838, 4.8701, 0.0000, 1.2322, 3.9549, 0.0000, 0.0000, 4.8027,\n",
            "         1.5964, 0.0000, 4.4941, 0.0000, 0.0000, 0.8065, 0.0000, 5.9502, 3.0394,\n",
            "         0.0000, 0.0000, 3.9616, 0.0477, 4.6973, 0.0000, 5.3499, 1.6806, 4.0029,\n",
            "         2.7745, 1.7257, 1.2518, 0.0000, 0.9959, 0.0000, 0.0000, 0.0000, 2.0956,\n",
            "         0.0000, 0.0000, 1.5129, 0.0000, 1.7843, 0.0000, 3.3686, 0.2244, 5.4987,\n",
            "         2.6490, 0.0000, 5.1099, 0.0000, 4.8958, 0.8760, 6.3491, 0.0000, 0.0000,\n",
            "         0.0000, 2.2734, 0.0000, 4.8304, 0.0000, 4.6160, 0.0000, 0.5792, 3.3906,\n",
            "         0.0000, 0.0000, 4.4642, 0.0000, 5.5760, 3.2358, 0.0000, 0.3687, 0.0000,\n",
            "         2.6181, 5.1021, 0.0000, 0.0000, 0.0000, 2.0601, 4.5851, 5.5911, 0.0000,\n",
            "         0.0000, 0.0000, 2.7905, 0.0000, 3.4981, 0.0000, 5.4732, 3.5889, 0.0000,\n",
            "         0.0000, 0.1566, 4.8852, 4.2482, 0.0000, 2.3469, 2.7115, 0.0000, 0.0000,\n",
            "         0.0000, 2.9920, 1.7877, 3.3662, 1.3163, 0.0000, 0.0000, 3.8156, 0.0000,\n",
            "         1.2040, 2.3743, 0.0000, 6.8114, 3.7706, 1.2214, 0.0000, 7.7461, 0.0000,\n",
            "         4.7792, 0.0000, 0.0000, 0.0000, 4.6835, 2.0740, 4.4552, 0.0000, 2.1254,\n",
            "         0.0000, 4.1294, 3.3393, 0.2294, 3.7314, 0.0000, 4.3427, 0.0000, 0.0000,\n",
            "         0.0000, 4.7671, 0.0000, 0.0000, 3.5857, 6.6791, 0.0000, 6.2018, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 2.3163, 0.0000, 2.4494,\n",
            "         0.0000, 0.0000, 0.6727, 0.0000, 0.0000, 0.0000, 0.0140, 0.0000, 0.0000,\n",
            "         0.0000, 2.1767, 3.7399, 2.9774, 0.0000, 3.0099, 5.1757, 4.0550, 0.0000,\n",
            "         4.4873, 0.0000, 2.7638, 0.0000, 0.0000, 0.0000, 1.4142, 0.0000, 2.9805,\n",
            "         0.0000, 3.3930, 0.1132, 0.4162, 0.6653, 0.0000, 2.4040, 0.0000, 0.0000,\n",
            "         5.1889, 7.0947, 2.9464, 4.7949, 2.0750, 3.8321, 4.7845, 5.3443, 0.0000,\n",
            "         1.2432, 1.6063, 0.0000, 5.7158, 0.0000, 8.7675, 2.1683, 0.0000, 1.2620,\n",
            "         2.1580, 0.0000, 5.7452, 0.0000, 3.9052, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 7.6266, 0.0000, 6.6203],\n",
            "        [0.0000, 2.5088, 3.1033, 3.8234, 0.3777, 0.0000, 0.0000, 0.8638, 0.0000,\n",
            "         0.0000, 4.1746, 2.3619, 2.8985, 0.0000, 0.9135, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 4.5262, 0.0000, 0.0000, 4.2531, 6.0741, 4.2580, 5.9372, 2.1871,\n",
            "         4.9207, 0.0000, 5.3997, 0.0000, 2.5751, 1.6186, 1.8092, 3.8972, 3.1593,\n",
            "         2.8852, 4.3662, 5.3221, 0.0000, 1.0669, 4.3492, 0.0000, 0.0000, 5.0696,\n",
            "         1.6601, 0.0000, 4.8342, 0.0000, 0.0000, 0.9286, 0.0000, 6.2834, 3.4938,\n",
            "         0.0000, 0.0000, 4.2327, 0.0976, 4.8693, 0.0000, 5.7268, 1.3786, 4.3469,\n",
            "         2.8933, 2.1027, 1.2282, 0.0000, 0.7848, 0.0000, 0.0000, 0.0000, 2.4618,\n",
            "         0.0000, 0.0235, 1.6094, 0.0000, 1.7883, 0.0000, 3.8534, 0.2407, 5.6903,\n",
            "         2.5766, 0.0000, 5.6401, 0.0000, 5.2871, 0.7060, 6.8375, 0.0000, 0.0000,\n",
            "         0.0000, 2.7092, 0.0000, 5.2626, 0.0000, 5.0561, 0.0000, 0.7983, 3.7668,\n",
            "         0.0000, 0.0000, 4.9958, 0.0000, 6.0096, 3.4287, 0.0000, 0.4819, 0.0000,\n",
            "         2.5091, 5.3308, 0.0000, 0.0000, 0.0000, 2.2740, 4.5882, 5.7575, 0.0000,\n",
            "         0.0000, 0.0000, 2.8518, 0.0000, 3.4595, 0.0000, 5.6049, 3.6371, 0.0000,\n",
            "         0.0000, 0.0000, 5.2410, 4.6689, 0.0000, 2.4570, 2.9333, 0.0000, 0.0000,\n",
            "         0.0000, 3.3747, 2.1194, 3.6560, 1.5228, 0.0000, 0.0000, 3.9064, 0.0000,\n",
            "         1.2046, 2.7404, 0.0000, 7.3086, 3.9320, 1.5189, 0.0000, 8.0726, 0.0000,\n",
            "         5.3404, 0.0000, 0.0000, 0.0000, 5.0251, 2.0674, 5.0324, 0.0000, 2.5411,\n",
            "         0.0000, 4.4841, 3.2289, 0.0315, 3.8090, 0.0000, 4.7415, 0.0000, 0.0722,\n",
            "         0.0000, 4.9838, 0.0000, 0.0000, 3.8892, 7.1397, 0.0000, 6.7232, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 2.4406, 0.0000, 2.6737,\n",
            "         0.0000, 0.0000, 1.1246, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 2.5743, 4.0824, 3.2633, 0.0000, 3.2307, 5.6201, 4.0660, 0.0000,\n",
            "         4.7344, 0.0000, 2.7518, 0.0000, 0.0000, 0.0000, 1.3110, 0.0000, 3.0725,\n",
            "         0.0000, 3.4618, 0.0000, 0.4007, 0.7905, 0.0000, 2.3991, 0.0000, 0.0000,\n",
            "         5.7446, 7.5275, 3.2420, 5.3593, 2.4542, 4.2731, 5.1839, 5.7346, 0.0000,\n",
            "         1.1625, 1.4454, 0.0000, 5.9927, 0.0000, 9.3023, 2.3338, 0.0000, 1.5847,\n",
            "         2.3698, 0.0000, 5.8856, 0.0000, 4.3243, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 7.8420, 0.0000, 7.1048]], grad_fn=<ReluBackward0>)\n",
            "x fc_pi output tensor([[ 54.1561, -34.8148,   4.3828, -36.7151],\n",
            "        [ 49.9946, -32.2946,   4.5084, -34.4971],\n",
            "        [ 54.1561, -34.8148,   4.3828, -36.7151]], grad_fn=<AddmmBackward0>)\n",
            "x F.softmax(x, dim=softmax_dim) tensor([[ 54.1561, -34.8148,   4.3828, -36.7151],\n",
            "        [ 49.9946, -32.2946,   4.5084, -34.4971],\n",
            "        [ 54.1561, -34.8148,   4.3828, -36.7151]], grad_fn=<AddmmBackward0>)\n",
            "prob tensor([[1.0000e+00, 2.2931e-39, 2.4196e-22, 3.4287e-40],\n",
            "        [1.0000e+00, 1.8291e-36, 1.7604e-20, 2.0218e-37],\n",
            "        [1.0000e+00, 2.2931e-39, 2.4196e-22, 3.4287e-40]],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "\n",
            "\n",
            "▶▶▶ 3803  : max cum reward :  1887  epsilon = 0.6196900000000419\n",
            "\n",
            "\n",
            "▶▶▶3804번째 에피소드 시작, env 초기화 완료.\n",
            "가져와야 할 아이템 : ['H', 'I', 'J', 'M', 'P', 'Q']\n",
            "\n",
            "현재 state         :  [9 4 0 3]\n",
            "step 데이터 : [8 4 0 3] -1 -1 False False\n",
            "put_data    : [9 4 0 3] 0 -1 [8 4 0 3] False\n",
            "step 데이터 : [7 4 0 3] -1 -2 False False\n",
            "put_data    : [8 4 0 3] 0 -1 [7 4 0 3] False\n",
            "step 데이터 : [7 3 0 3] -1 -3 False False\n",
            "put_data    : [7 4 0 3] 2 -1 [7 3 0 3] False\n",
            "step 데이터 : [8 3 0 3] -1 -4 False False\n",
            "put_data    : [7 3 0 3] 1 -1 [8 3 0 3] False\n",
            "tensor([8, 3, 0, 3])\n",
            "tensor([8., 3., 0., 3.])\n",
            "end input\n",
            "input x tensor([8., 3., 0., 3.])\n",
            "x F.relu output tensor([0.0000, 2.8728, 3.7823, 5.1420, 0.0000, 0.0000, 0.0000, 2.5446, 0.0000,\n",
            "        0.0000, 4.3647, 3.8416, 1.4692, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        1.1153, 3.7039, 0.0000, 0.0000, 1.8522, 5.5323, 3.1204, 2.5598, 4.3759,\n",
            "        5.3727, 0.0000, 3.4896, 0.0000, 1.7051, 2.3175, 4.9680, 2.4924, 2.5024,\n",
            "        4.1786, 1.3896, 4.9680, 0.0000, 0.0000, 2.0163, 0.0000, 0.0000, 1.8988,\n",
            "        2.3133, 0.0000, 1.4808, 0.0000, 0.0000, 3.4029, 0.0000, 2.6548, 3.0270,\n",
            "        0.0000, 0.0000, 3.5848, 0.0000, 1.5640, 0.0000, 5.9987, 0.0000, 1.5411,\n",
            "        1.4106, 2.5922, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 3.8477,\n",
            "        0.0000, 0.9380, 1.8327, 0.0000, 0.5236, 0.0000, 4.7258, 0.0000, 2.7974,\n",
            "        0.5590, 0.3724, 3.3924, 0.0000, 2.3642, 0.0000, 5.6286, 0.0000, 0.0000,\n",
            "        0.0000, 4.2004, 0.0000, 6.5440, 1.3804, 2.7006, 1.1928, 0.4214, 3.4798,\n",
            "        0.0000, 1.2181, 4.3847, 0.0000, 5.4417, 3.1670, 0.0000, 1.9399, 0.0000,\n",
            "        0.4884, 4.7589, 0.0000, 2.1046, 0.0000, 2.8321, 2.3573, 4.1645, 0.0000,\n",
            "        0.0000, 0.0000, 3.1355, 0.5163, 1.0667, 0.0000, 1.7006, 0.9366, 0.0000,\n",
            "        0.0000, 0.0000, 5.5362, 4.7642, 0.0000, 0.5207, 2.0171, 0.0000, 0.0000,\n",
            "        0.0000, 2.6158, 1.3880, 2.3052, 2.0604, 0.0000, 0.0000, 3.4180, 0.0000,\n",
            "        0.8912, 1.8953, 0.0000, 4.8601, 2.4917, 0.6931, 0.0000, 4.1962, 0.0000,\n",
            "        5.2259, 0.1922, 0.0000, 0.0000, 2.6213, 1.4065, 7.2116, 0.0000, 2.4654,\n",
            "        0.0000, 4.2402, 0.9138, 0.0000, 2.9669, 0.0000, 4.5441, 0.0000, 1.7009,\n",
            "        0.0000, 3.6463, 0.4588, 0.0000, 4.3298, 5.1774, 0.0000, 5.0380, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.4410, 0.0000, 2.2819,\n",
            "        0.0000, 0.0000, 1.9980, 0.3296, 0.0000, 1.0907, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 3.9168, 3.0813, 2.4185, 0.0000, 1.9341, 6.3802, 0.0000, 1.7662,\n",
            "        2.8125, 0.0000, 0.7081, 0.0000, 0.0000, 1.9876, 0.0000, 0.0000, 1.8847,\n",
            "        0.0000, 1.3986, 0.0000, 1.3165, 3.3518, 0.0000, 0.0000, 0.3170, 0.0000,\n",
            "        4.5055, 4.0324, 4.1475, 3.4234, 1.6200, 5.3012, 2.0446, 3.4735, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 2.7267, 0.0000, 4.7798, 0.5005, 0.0000, 3.1849,\n",
            "        1.3963, 1.3375, 3.5814, 0.0000, 1.7140, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 4.5248, 0.0000, 6.7654], grad_fn=<ReluBackward0>)\n",
            "x fc_pi output tensor([ 43.1898, -26.5569,   0.1923, -23.7157], grad_fn=<AddBackward0>)\n",
            "x F.softmax(x, dim=softmax_dim) tensor([ 43.1898, -26.5569,   0.1923, -23.7157], grad_fn=<AddBackward0>)\n",
            "prob tensor([1.0000e+00, 5.1210e-31, 2.1204e-19, 8.7763e-30],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "step 데이터 : [7 3 0 3] -1 -5 False False\n",
            "put_data    : [8 3 0 3] 0 -1 [7 3 0 3] False\n",
            "step 데이터 : [6 3 0 3] -1 -6 False False\n",
            "put_data    : [7 3 0 3] 0 -1 [6 3 0 3] False\n",
            "step 데이터 : [7 3 0 3] -1 -7 False False\n",
            "put_data    : [6 3 0 3] 1 -1 [7 3 0 3] False\n",
            "tensor([7, 3, 0, 3])\n",
            "tensor([7., 3., 0., 3.])\n",
            "end input\n",
            "input x tensor([7., 3., 0., 3.])\n",
            "x F.relu output tensor([0.0000, 2.5132, 3.4418, 4.5141, 0.0000, 0.0000, 0.0000, 2.4170, 0.0000,\n",
            "        0.0000, 3.8078, 3.4941, 1.3654, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        1.1155, 3.4671, 0.0000, 0.0000, 1.5901, 4.9015, 2.9191, 2.2434, 3.8263,\n",
            "        4.8322, 0.0000, 3.1441, 0.0000, 1.4356, 2.2341, 4.6851, 2.3207, 2.4173,\n",
            "        3.5923, 1.1071, 4.5160, 0.0000, 0.0000, 1.6220, 0.0000, 0.0000, 1.6319,\n",
            "        2.2496, 0.0000, 1.1407, 0.0000, 0.0000, 3.2808, 0.0000, 2.3216, 2.5725,\n",
            "        0.0000, 0.0000, 3.3137, 0.0000, 1.3919, 0.0000, 5.6218, 0.0000, 1.1970,\n",
            "        1.2917, 2.2152, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 3.4815,\n",
            "        0.0000, 0.5816, 1.7361, 0.0000, 0.5196, 0.0000, 4.2410, 0.0000, 2.6058,\n",
            "        0.6314, 0.4263, 2.8622, 0.0000, 1.9729, 0.0000, 5.1401, 0.0000, 0.0000,\n",
            "        0.0000, 3.7645, 0.0000, 6.1117, 1.1812, 2.2605, 1.2739, 0.2023, 3.1035,\n",
            "        0.0000, 1.3473, 3.8531, 0.0000, 5.0081, 2.9741, 0.0000, 1.8268, 0.0000,\n",
            "        0.5973, 4.5302, 0.0000, 1.8780, 0.0000, 2.6183, 2.3541, 3.9980, 0.0000,\n",
            "        0.0000, 0.0000, 3.0742, 0.6825, 1.1053, 0.0000, 1.5689, 0.8884, 0.0000,\n",
            "        0.0000, 0.0000, 5.1804, 4.3434, 0.0785, 0.4106, 1.7953, 0.0000, 0.0000,\n",
            "        0.0000, 2.2331, 1.0563, 2.0154, 1.8539, 0.0000, 0.0000, 3.3272, 0.0000,\n",
            "        0.8906, 1.5292, 0.0000, 4.3629, 2.3303, 0.3956, 0.0000, 3.8696, 0.0000,\n",
            "        4.6646, 0.1973, 0.0000, 0.0000, 2.2797, 1.4131, 6.6344, 0.0000, 2.0497,\n",
            "        0.0000, 3.8855, 1.0242, 0.0000, 2.8894, 0.0472, 4.1452, 0.0000, 1.5689,\n",
            "        0.0000, 3.4295, 0.5337, 0.0000, 4.0263, 4.7168, 0.0000, 4.5166, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.3167, 0.0000, 2.0576,\n",
            "        0.0000, 0.0000, 1.5461, 0.2642, 0.0000, 0.9237, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 3.5192, 2.7388, 2.1327, 0.0000, 1.7133, 5.9358, 0.0000, 1.6934,\n",
            "        2.5653, 0.0000, 0.7201, 0.0000, 0.0000, 1.9986, 0.0000, 0.0000, 1.7926,\n",
            "        0.0000, 1.3298, 0.0000, 1.3319, 3.2265, 0.0000, 0.0000, 0.5088, 0.0000,\n",
            "        3.9498, 3.5996, 3.8519, 2.8591, 1.2408, 4.8601, 1.6451, 3.0831, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 2.4498, 0.0000, 4.2450, 0.3349, 0.0000, 2.8622,\n",
            "        1.1844, 1.1653, 3.4409, 0.0000, 1.2950, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 4.3093, 0.0000, 6.2808], grad_fn=<ReluBackward0>)\n",
            "x fc_pi output tensor([ 39.0100, -23.9777,   0.2775, -21.3654], grad_fn=<AddBackward0>)\n",
            "x F.softmax(x, dim=softmax_dim) tensor([ 39.0100, -23.9777,   0.2775, -21.3654], grad_fn=<AddBackward0>)\n",
            "prob tensor([1.0000e+00, 4.4134e-28, 1.5090e-17, 6.0157e-27],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "step 데이터 : [6 3 0 3] -1 -8 False False\n",
            "put_data    : [7 3 0 3] 0 -1 [6 3 0 3] False\n",
            "step 데이터 : [6 4 0 3] -100 -108 True False\n",
            "put_data    : [6 3 0 3] 3 -100 [6 4 0 3] True\n",
            "input x tensor([[9., 4., 0., 3.],\n",
            "        [8., 4., 0., 3.],\n",
            "        [7., 4., 0., 3.],\n",
            "        [7., 3., 0., 3.],\n",
            "        [8., 3., 0., 3.],\n",
            "        [7., 3., 0., 3.],\n",
            "        [6., 3., 0., 3.],\n",
            "        [7., 3., 0., 3.],\n",
            "        [6., 3., 0., 3.]])\n",
            "x F.relu output tensor([[0.0000, 3.5395, 4.5894,  ..., 5.2966, 0.0000, 7.7716],\n",
            "        [0.0000, 3.1800, 4.2489,  ..., 5.0811, 0.0000, 7.2871],\n",
            "        [0.0000, 2.8204, 3.9083,  ..., 4.8657, 0.0000, 6.8026],\n",
            "        ...,\n",
            "        [0.0000, 2.1537, 3.1012,  ..., 4.0939, 0.0000, 5.7963],\n",
            "        [0.0000, 2.5132, 3.4418,  ..., 4.3093, 0.0000, 6.2808],\n",
            "        [0.0000, 2.1537, 3.1012,  ..., 4.0939, 0.0000, 5.7963]],\n",
            "       grad_fn=<ReluBackward0>)\n",
            "x fc_pi output tensor([[ 50.2148, -30.9445,   0.4223, -27.7447],\n",
            "        [ 46.0396, -28.3797,   0.5199, -25.4019],\n",
            "        [ 41.8660, -25.8198,   0.6056, -23.0584],\n",
            "        [ 39.0100, -23.9777,   0.2775, -21.3654],\n",
            "        [ 43.1898, -26.5569,   0.1923, -23.7157],\n",
            "        [ 39.0100, -23.9777,   0.2775, -21.3654],\n",
            "        [ 34.8196, -21.4014,   0.3502, -19.0150],\n",
            "        [ 39.0100, -23.9777,   0.2775, -21.3654],\n",
            "        [ 34.8196, -21.4014,   0.3502, -19.0150]], grad_fn=<AddmmBackward0>)\n",
            "x F.softmax(x, dim=softmax_dim) tensor([[ 50.2148, -30.9445,   0.4223, -27.7447],\n",
            "        [ 46.0396, -28.3797,   0.5199, -25.4019],\n",
            "        [ 41.8660, -25.8198,   0.6056, -23.0584],\n",
            "        [ 39.0100, -23.9777,   0.2775, -21.3654],\n",
            "        [ 43.1898, -26.5569,   0.1923, -23.7157],\n",
            "        [ 39.0100, -23.9777,   0.2775, -21.3654],\n",
            "        [ 34.8196, -21.4014,   0.3502, -19.0150],\n",
            "        [ 39.0100, -23.9777,   0.2775, -21.3654],\n",
            "        [ 34.8196, -21.4014,   0.3502, -19.0150]], grad_fn=<AddmmBackward0>)\n",
            "prob tensor([[1.0000e+00, 5.6623e-36, 2.3736e-22, 1.3888e-34],\n",
            "        [1.0000e+00, 4.7879e-33, 1.7025e-20, 9.4053e-32],\n",
            "        [1.0000e+00, 4.0219e-30, 1.2046e-18, 6.3634e-29],\n",
            "        [1.0000e+00, 4.4134e-28, 1.5090e-17, 6.0158e-27],\n",
            "        [1.0000e+00, 5.1210e-31, 2.1204e-19, 8.7763e-30],\n",
            "        [1.0000e+00, 4.4134e-28, 1.5090e-17, 6.0158e-27],\n",
            "        [1.0000e+00, 3.8331e-25, 1.0719e-15, 4.1681e-24],\n",
            "        [1.0000e+00, 4.4134e-28, 1.5090e-17, 6.0158e-27],\n",
            "        [1.0000e+00, 3.8331e-25, 1.0719e-15, 4.1681e-24]],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "\n",
            "\n",
            "▶▶▶ 3804  : max cum reward :  1887  epsilon = 0.6195900000000419\n",
            "\n",
            "\n",
            "▶▶▶3805번째 에피소드 시작, env 초기화 완료.\n",
            "가져와야 할 아이템 : ['A', 'B', 'F', 'I', 'K', 'P', 'Q']\n",
            "\n",
            "현재 state         :  [9 4 5 0]\n",
            "step 데이터 : [9 5 5 0] -100 -100 True False\n",
            "put_data    : [9 4 5 0] 3 -100 [9 5 5 0] True\n",
            "input x tensor([[9., 4., 5., 0.]])\n",
            "x F.relu output tensor([[0.0000, 2.5099, 3.1038, 3.8241, 0.3782, 0.0000, 0.0000, 0.8649, 0.0000,\n",
            "         0.0000, 4.1752, 2.3624, 2.8994, 0.0000, 0.9139, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 4.5262, 0.0000, 0.0000, 4.2542, 6.0749, 4.2584, 5.9378, 2.1876,\n",
            "         4.9216, 0.0000, 5.4009, 0.0000, 2.5762, 1.6188, 1.8096, 3.8975, 3.1599,\n",
            "         2.8857, 4.3668, 5.3232, 0.0000, 1.0669, 4.3502, 0.0000, 0.0000, 5.0705,\n",
            "         1.6602, 0.0000, 4.8347, 0.0000, 0.0000, 0.9288, 0.0000, 6.2838, 3.4950,\n",
            "         0.0000, 0.0000, 4.2333, 0.0980, 4.8700, 0.0000, 5.7276, 1.3778, 4.3476,\n",
            "         2.8937, 2.1032, 1.2282, 0.0000, 0.7841, 0.0000, 0.0000, 0.0000, 2.4620,\n",
            "         0.0000, 0.0241, 1.6094, 0.0000, 1.7887, 0.0000, 3.8541, 0.2403, 5.6910,\n",
            "         2.5778, 0.0000, 5.6405, 0.0000, 5.2882, 0.7058, 6.8379, 0.0000, 0.0000,\n",
            "         0.0000, 2.7105, 0.0000, 5.2631, 0.0000, 5.0567, 0.0000, 0.7989, 3.7673,\n",
            "         0.0000, 0.0000, 4.9966, 0.0000, 6.0108, 3.4294, 0.0000, 0.4827, 0.0000,\n",
            "         2.5094, 5.3311, 0.0000, 0.0000, 0.0000, 2.2744, 4.5888, 5.7579, 0.0000,\n",
            "         0.0000, 0.0000, 2.8524, 0.0000, 3.4599, 0.0000, 5.6054, 3.6376, 0.0000,\n",
            "         0.0000, 0.0000, 5.2421, 4.6702, 0.0000, 2.4574, 2.9342, 0.0000, 0.0000,\n",
            "         0.0000, 3.3754, 2.1199, 3.6569, 1.5222, 0.0000, 0.0000, 3.9072, 0.0000,\n",
            "         1.2049, 2.7408, 0.0000, 7.3089, 3.9325, 1.5197, 0.0000, 8.0735, 0.0000,\n",
            "         5.3411, 0.0000, 0.0000, 0.0000, 5.0259, 2.0679, 5.0333, 0.0000, 2.5421,\n",
            "         0.0000, 4.4850, 3.2293, 0.0308, 3.8095, 0.0000, 4.7420, 0.0000, 0.0731,\n",
            "         0.0000, 4.9842, 0.0000, 0.0000, 3.8899, 7.1401, 0.0000, 6.7238, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 2.4417, 0.0000, 2.6745,\n",
            "         0.0000, 0.0000, 1.1250, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 2.5746, 4.0832, 3.2638, 0.0000, 3.2316, 5.6210, 4.0669, 0.0000,\n",
            "         4.7351, 0.0000, 2.7524, 0.0000, 0.0000, 0.0000, 1.3109, 0.0000, 3.0735,\n",
            "         0.0000, 3.4620, 0.0000, 0.4021, 0.7909, 0.0000, 2.3990, 0.0000, 0.0000,\n",
            "         5.7450, 7.5278, 3.2426, 5.3603, 2.4552, 4.2743, 5.1845, 5.7359, 0.0000,\n",
            "         1.1620, 1.4446, 0.0000, 5.9931, 0.0000, 9.3033, 2.3343, 0.0000, 1.5855,\n",
            "         2.3713, 0.0000, 5.8867, 0.0000, 4.3249, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 7.8427, 0.0000, 7.1056]], grad_fn=<ReluBackward0>)\n",
            "x fc_pi output tensor([[ 54.1833, -34.8233,   4.3751, -36.7378]], grad_fn=<AddmmBackward0>)\n",
            "x F.softmax(x, dim=softmax_dim) tensor([[ 54.1833, -34.8233,   4.3751, -36.7378]], grad_fn=<AddmmBackward0>)\n",
            "prob tensor([[1.0000e+00, 2.2127e-39, 2.3365e-22, 3.2620e-40]],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "\n",
            "\n",
            "▶▶▶ 3805  : max cum reward :  1887  epsilon = 0.619490000000042\n",
            "\n",
            "\n",
            "▶▶▶3806번째 에피소드 시작, env 초기화 완료.\n",
            "가져와야 할 아이템 : ['A', 'C', 'J', 'N']\n",
            "\n",
            "현재 state         :  [9 4 5 0]\n",
            "step 데이터 : [9 3 5 0] -100 -100 True False\n",
            "put_data    : [9 4 5 0] 2 -100 [9 3 5 0] True\n",
            "input x tensor([[9., 4., 5., 0.]])\n",
            "x F.relu output tensor([[0.0000, 2.5111, 3.1046, 3.8250, 0.3782, 0.0000, 0.0000, 0.8658, 0.0000,\n",
            "         0.0000, 4.1760, 2.3632, 2.9004, 0.0000, 0.9138, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 4.5269, 0.0000, 0.0000, 4.2556, 6.0758, 4.2592, 5.9387, 2.1885,\n",
            "         4.9227, 0.0000, 5.4022, 0.0000, 2.5769, 1.6192, 1.8102, 3.8982, 3.1608,\n",
            "         2.8865, 4.3679, 5.3243, 0.0000, 1.0669, 4.3515, 0.0000, 0.0000, 5.0715,\n",
            "         1.6611, 0.0000, 4.8353, 0.0000, 0.0000, 0.9292, 0.0000, 6.2846, 3.4960,\n",
            "         0.0000, 0.0000, 4.2341, 0.0988, 4.8710, 0.0000, 5.7285, 1.3782, 4.3487,\n",
            "         2.8946, 2.1038, 1.2289, 0.0000, 0.7843, 0.0000, 0.0000, 0.0000, 2.4629,\n",
            "         0.0000, 0.0244, 1.6100, 0.0000, 1.7895, 0.0000, 3.8548, 0.2411, 5.6920,\n",
            "         2.5790, 0.0000, 5.6411, 0.0000, 5.2894, 0.7064, 6.8387, 0.0000, 0.0000,\n",
            "         0.0000, 2.7117, 0.0000, 5.2639, 0.0000, 5.0574, 0.0000, 0.7996, 3.7683,\n",
            "         0.0000, 0.0000, 4.9976, 0.0000, 6.0121, 3.4302, 0.0000, 0.4836, 0.0000,\n",
            "         2.5104, 5.3320, 0.0000, 0.0000, 0.0000, 2.2751, 4.5897, 5.7586, 0.0000,\n",
            "         0.0000, 0.0000, 2.8531, 0.0000, 3.4609, 0.0000, 5.6066, 3.6385, 0.0000,\n",
            "         0.0000, 0.0000, 5.2430, 4.6715, 0.0000, 2.4581, 2.9352, 0.0000, 0.0000,\n",
            "         0.0000, 3.3762, 2.1207, 3.6580, 1.5223, 0.0000, 0.0000, 3.9082, 0.0000,\n",
            "         1.2057, 2.7415, 0.0000, 7.3098, 3.9335, 1.5207, 0.0000, 8.0747, 0.0000,\n",
            "         5.3418, 0.0000, 0.0000, 0.0000, 5.0269, 2.0687, 5.0342, 0.0000, 2.5431,\n",
            "         0.0000, 4.4861, 3.2301, 0.0315, 3.8104, 0.0000, 4.7430, 0.0000, 0.0744,\n",
            "         0.0000, 4.9848, 0.0000, 0.0000, 3.8906, 7.1407, 0.0000, 6.7246, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 2.4430, 0.0000, 2.6754,\n",
            "         0.0000, 0.0000, 1.1258, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 2.5752, 4.0842, 3.2647, 0.0000, 3.2328, 5.6217, 4.0680, 0.0000,\n",
            "         4.7361, 0.0000, 2.7533, 0.0000, 0.0000, 0.0000, 1.3116, 0.0000, 3.0747,\n",
            "         0.0000, 3.4628, 0.0000, 0.4033, 0.7916, 0.0000, 2.3995, 0.0000, 0.0000,\n",
            "         5.7457, 7.5286, 3.2435, 5.3611, 2.4562, 4.2754, 5.1854, 5.7372, 0.0000,\n",
            "         1.1625, 1.4449, 0.0000, 5.9938, 0.0000, 9.3045, 2.3353, 0.0000, 1.5864,\n",
            "         2.3725, 0.0000, 5.8880, 0.0000, 4.3258, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 7.8438, 0.0000, 7.1066]], grad_fn=<ReluBackward0>)\n",
            "x fc_pi output tensor([[ 54.2159, -34.8334,   4.3740, -36.7762]], grad_fn=<AddmmBackward0>)\n",
            "x F.softmax(x, dim=softmax_dim) tensor([[ 54.2159, -34.8334,   4.3740, -36.7762]], grad_fn=<AddmmBackward0>)\n",
            "prob tensor([[1.0000e+00, 2.1203e-39, 2.2592e-22, 3.0383e-40]],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "\n",
            "\n",
            "▶▶▶ 3806  : max cum reward :  1887  epsilon = 0.619390000000042\n",
            "\n",
            "\n",
            "▶▶▶3807번째 에피소드 시작, env 초기화 완료.\n",
            "가져와야 할 아이템 : ['B', 'F', 'H', 'K']\n",
            "\n",
            "현재 state         :  [9 4 4 0]\n",
            "step 데이터 : [10  4  4  0] -100 -100 True False\n",
            "put_data    : [9 4 4 0] 1 -100 [10  4  4  0] True\n",
            "input x tensor([[9., 4., 4., 0.]])\n",
            "x F.relu output tensor([[0.0000, 2.8312, 3.4088, 3.9516, 0.0088, 0.0000, 0.0000, 1.1336, 0.0000,\n",
            "         0.0000, 4.1339, 2.6942, 2.8533, 0.0000, 0.4220, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 4.3586, 0.0000, 0.0000, 4.0478, 5.9911, 3.8174, 5.5631, 2.5650,\n",
            "         5.0305, 0.0000, 4.8414, 0.0000, 2.8163, 1.5329, 2.2530, 3.9998, 2.9776,\n",
            "         3.2994, 3.8112, 5.2136, 0.0000, 0.7397, 4.1348, 0.0000, 0.0000, 4.8417,\n",
            "         1.6393, 0.0000, 4.4827, 0.0000, 0.0000, 1.3153, 0.0000, 5.7983, 3.8420,\n",
            "         0.0000, 0.0000, 3.9243, 0.1658, 4.5257, 0.0000, 5.6861, 0.8509, 3.8816,\n",
            "         2.7690, 2.2513, 0.8342, 0.0000, 0.3459, 0.0000, 0.0000, 0.0000, 2.6845,\n",
            "         0.0000, 0.2832, 1.6196, 0.0000, 1.8850, 0.0000, 4.0942, 0.0646, 5.2865,\n",
            "         2.1105, 0.0000, 5.5223, 0.0000, 4.8509, 0.4361, 6.7289, 0.0000, 0.0000,\n",
            "         0.0000, 2.9083, 0.0000, 5.4021, 0.0000, 4.6318, 0.0000, 0.9299, 3.6048,\n",
            "         0.0000, 0.0000, 5.2481, 0.1476, 5.8927, 3.5145, 0.0000, 0.7715, 0.0000,\n",
            "         2.0009, 5.1419, 0.0000, 0.0000, 0.0000, 2.5454, 4.1535, 5.3453, 0.0000,\n",
            "         0.0000, 0.0000, 2.8959, 0.0000, 3.0513, 0.0000, 5.0880, 3.1476, 0.0000,\n",
            "         0.0000, 0.0000, 5.2631, 4.9424, 0.0000, 2.3540, 2.9660, 0.0000, 0.0000,\n",
            "         0.0000, 3.4301, 2.1431, 3.7531, 1.3207, 0.0000, 0.0000, 3.6253, 0.0000,\n",
            "         1.3014, 2.8172, 0.0000, 7.1727, 3.6387, 1.6234, 0.0000, 7.5046, 0.0000,\n",
            "         5.3482, 0.0000, 0.0000, 0.0000, 4.9178, 1.9536, 5.4122, 0.0000, 2.6760,\n",
            "         0.0000, 4.1962, 2.9587, 0.0000, 3.4471, 0.0000, 5.0508, 0.0000, 0.4356,\n",
            "         0.0000, 4.7861, 0.0000, 0.0000, 3.9481, 7.0012, 0.0000, 6.4810, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 2.1434, 0.0000, 2.8545,\n",
            "         0.0000, 0.0000, 1.4585, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 2.8543, 3.7020, 3.4719, 0.0000, 3.2328, 5.7045, 3.5438, 0.0000,\n",
            "         4.2139, 0.0000, 2.2431, 0.0000, 0.0000, 0.0000, 1.1881, 0.0000, 2.7998,\n",
            "         0.0000, 3.2830, 0.0000, 0.7078, 1.2262, 0.0000, 1.9767, 0.0000, 0.0000,\n",
            "         5.4966, 6.9695, 3.3148, 5.2492, 2.5357, 4.6180, 4.8195, 5.6770, 0.0000,\n",
            "         0.7172, 0.9532, 0.0000, 5.7214, 0.0000, 8.7497, 2.2983, 0.0000, 1.8388,\n",
            "         2.1895, 0.0000, 5.3168, 0.0000, 3.9348, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 7.2274, 0.0000, 6.9942]], grad_fn=<ReluBackward0>)\n",
            "x fc_pi output tensor([[ 53.4976, -34.0908,   3.5674, -35.1142]], grad_fn=<AddmmBackward0>)\n",
            "x F.softmax(x, dim=softmax_dim) tensor([[ 53.4976, -34.0908,   3.5674, -35.1142]], grad_fn=<AddmmBackward0>)\n",
            "prob tensor([[1.0000e+00, 9.1374e-39, 2.0681e-22, 3.2838e-39]],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "\n",
            "\n",
            "▶▶▶ 3807  : max cum reward :  1887  epsilon = 0.619290000000042\n",
            "\n",
            "\n",
            "▶▶▶3808번째 에피소드 시작, env 초기화 완료.\n",
            "가져와야 할 아이템 : ['A', 'C', 'L', 'O', 'P']\n",
            "\n",
            "현재 state         :  [9 4 5 0]\n",
            "tensor([9, 4, 5, 0])\n",
            "tensor([9., 4., 5., 0.])\n",
            "end input\n",
            "input x tensor([9., 4., 5., 0.])\n",
            "x F.relu output tensor([0.0000, 2.5145, 3.1070, 3.8276, 0.3768, 0.0000, 0.0000, 0.8690, 0.0000,\n",
            "        0.0000, 4.1784, 2.3657, 2.9030, 0.0000, 0.9127, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 4.5293, 0.0000, 0.0000, 4.2584, 6.0783, 4.2616, 5.9410, 2.1912,\n",
            "        4.9258, 0.0000, 5.4045, 0.0000, 2.5791, 1.6211, 1.8127, 3.9004, 3.1633,\n",
            "        2.8889, 4.3704, 5.3272, 0.0000, 1.0657, 4.3545, 0.0000, 0.0000, 5.0740,\n",
            "        1.6629, 0.0000, 4.8375, 0.0000, 0.0000, 0.9312, 0.0000, 6.2869, 3.4987,\n",
            "        0.0000, 0.0000, 4.2365, 0.1018, 4.8735, 0.0000, 5.7309, 1.3787, 4.3513,\n",
            "        2.8970, 2.1061, 1.2310, 0.0000, 0.7856, 0.0000, 0.0000, 0.0000, 2.4653,\n",
            "        0.0000, 0.0269, 1.6120, 0.0000, 1.7917, 0.0000, 3.8572, 0.2420, 5.6944,\n",
            "        2.5805, 0.0000, 5.6433, 0.0000, 5.2920, 0.7071, 6.8411, 0.0000, 0.0000,\n",
            "        0.0000, 2.7146, 0.0000, 5.2663, 0.0000, 5.0597, 0.0000, 0.8020, 3.7709,\n",
            "        0.0000, 0.0000, 5.0001, 0.0000, 6.0150, 3.4327, 0.0000, 0.4867, 0.0000,\n",
            "        2.5126, 5.3334, 0.0000, 0.0000, 0.0000, 2.2773, 4.5923, 5.7608, 0.0000,\n",
            "        0.0000, 0.0000, 2.8555, 0.0000, 3.4633, 0.0000, 5.6087, 3.6410, 0.0000,\n",
            "        0.0000, 0.0000, 5.2456, 4.6745, 0.0000, 2.4603, 2.9378, 0.0000, 0.0000,\n",
            "        0.0000, 3.3787, 2.1231, 3.6607, 1.5231, 0.0000, 0.0000, 3.9108, 0.0000,\n",
            "        1.2082, 2.7439, 0.0000, 7.3120, 3.9361, 1.5235, 0.0000, 8.0774, 0.0000,\n",
            "        5.3443, 0.0000, 0.0000, 0.0000, 5.0296, 2.0710, 5.0366, 0.0000, 2.5459,\n",
            "        0.0000, 4.4890, 3.2323, 0.0335, 3.8127, 0.0000, 4.7455, 0.0000, 0.0785,\n",
            "        0.0000, 4.9871, 0.0000, 0.0000, 3.8929, 7.1428, 0.0000, 6.7271, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 2.4451, 0.0000, 2.6774,\n",
            "        0.0000, 0.0000, 1.1283, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 2.5775, 4.0867, 3.2672, 0.0000, 3.2354, 5.6241, 4.0694, 0.0000,\n",
            "        4.7386, 0.0000, 2.7557, 0.0000, 0.0000, 0.0000, 1.3132, 0.0000, 3.0775,\n",
            "        0.0000, 3.4651, 0.0000, 0.4068, 0.7942, 0.0000, 2.3999, 0.0000, 0.0000,\n",
            "        5.7479, 7.5308, 3.2461, 5.3635, 2.4591, 4.2781, 5.1879, 5.7399, 0.0000,\n",
            "        1.1643, 1.4462, 0.0000, 5.9961, 0.0000, 9.3073, 2.3378, 0.0000, 1.5890,\n",
            "        2.3753, 0.0000, 5.8908, 0.0000, 4.3282, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 7.8464, 0.0000, 7.1092], grad_fn=<ReluBackward0>)\n",
            "x fc_pi output tensor([ 54.3113, -34.8733,   4.3451, -36.8489], grad_fn=<AddBackward0>)\n",
            "x F.softmax(x, dim=softmax_dim) tensor([ 54.3113, -34.8733,   4.3451, -36.8489], grad_fn=<AddBackward0>)\n",
            "prob tensor([1.0000e+00, 1.8519e-39, 1.9951e-22, 2.5683e-40],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "step 데이터 : [8 4 5 0] -1 -1 False False\n",
            "put_data    : [9 4 5 0] 0 -1 [8 4 5 0] False\n",
            "step 데이터 : [7 4 5 0] -1 -2 False False\n",
            "put_data    : [8 4 5 0] 0 -1 [7 4 5 0] False\n",
            "step 데이터 : [7 5 5 0] -1 -3 False False\n",
            "put_data    : [7 4 5 0] 3 -1 [7 5 5 0] False\n",
            "step 데이터 : [7 4 5 0] -1 -4 False False\n",
            "put_data    : [7 5 5 0] 2 -1 [7 4 5 0] False\n",
            "step 데이터 : [7 5 5 0] -1 -5 False False\n",
            "put_data    : [7 4 5 0] 3 -1 [7 5 5 0] False\n",
            "step 데이터 : [7 4 5 0] -1 -6 False False\n",
            "put_data    : [7 5 5 0] 2 -1 [7 4 5 0] False\n",
            "tensor([7, 4, 5, 0])\n",
            "tensor([7., 4., 5., 0.])\n",
            "end input\n",
            "input x tensor([7., 4., 5., 0.])\n",
            "x F.relu output tensor([0.0000e+00, 1.7948e+00, 2.4255e+00, 2.5714e+00, 1.0052e+00, 0.0000e+00,\n",
            "        0.0000e+00, 6.1326e-01, 0.0000e+00, 0.0000e+00, 3.0641e+00, 1.6703e+00,\n",
            "        2.6951e+00, 0.0000e+00, 1.3947e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 4.0553e+00, 0.0000e+00, 0.0000e+00, 3.7336e+00, 4.8162e+00,\n",
            "        3.8586e+00, 5.3079e+00, 1.0916e+00, 3.8442e+00, 0.0000e+00, 4.7130e+00,\n",
            "        0.0000e+00, 2.0397e+00, 1.4541e+00, 1.2466e+00, 3.5566e+00, 2.9925e+00,\n",
            "        1.7159e+00, 3.8050e+00, 4.4227e+00, 0.0000e+00, 1.3964e+00, 3.5653e+00,\n",
            "        0.0000e+00, 0.0000e+00, 4.5397e+00, 1.5352e+00, 0.0000e+00, 4.1568e+00,\n",
            "        0.0000e+00, 0.0000e+00, 6.8670e-01, 0.0000e+00, 5.6201e+00, 2.5891e+00,\n",
            "        0.0000e+00, 0.0000e+00, 3.6939e+00, 1.6313e-03, 4.5289e+00, 0.0000e+00,\n",
            "        4.9767e+00, 1.9827e+00, 3.6626e+00, 2.6590e+00, 1.3516e+00, 1.2779e+00,\n",
            "        0.0000e+00, 1.2076e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.7326e+00,\n",
            "        0.0000e+00, 0.0000e+00, 1.4186e+00, 0.0000e+00, 1.7832e+00, 0.0000e+00,\n",
            "        2.8871e+00, 2.0921e-01, 5.3107e+00, 2.7249e+00, 0.0000e+00, 4.5825e+00,\n",
            "        0.0000e+00, 4.5087e+00, 1.0470e+00, 5.8638e+00, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 1.8422e+00, 0.0000e+00, 4.4014e+00, 0.0000e+00, 4.1790e+00,\n",
            "        0.0000e+00, 3.6336e-01, 3.0180e+00, 0.0000e+00, 0.0000e+00, 3.9363e+00,\n",
            "        0.0000e+00, 5.1472e+00, 3.0464e+00, 0.0000e+00, 2.5991e-01, 0.0000e+00,\n",
            "        2.7300e+00, 4.8756e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.8493e+00,\n",
            "        4.5855e+00, 5.4274e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.7324e+00,\n",
            "        0.0000e+00, 3.5400e+00, 0.0000e+00, 5.3449e+00, 3.5441e+00, 0.0000e+00,\n",
            "        0.0000e+00, 4.7446e-01, 4.5333e+00, 3.8323e+00, 0.0000e+00, 2.2398e+00,\n",
            "        2.4938e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.6128e+00, 1.4593e+00,\n",
            "        3.0806e+00, 1.1101e+00, 0.0000e+00, 0.0000e+00, 3.7287e+00, 0.0000e+00,\n",
            "        1.2065e+00, 2.0112e+00, 0.0000e+00, 6.3172e+00, 3.6128e+00, 9.2786e-01,\n",
            "        0.0000e+00, 7.4237e+00, 0.0000e+00, 4.2214e+00, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 4.3459e+00, 2.0837e+00, 3.8817e+00, 0.0000e+00, 1.7139e+00,\n",
            "        0.0000e+00, 3.7790e+00, 3.4527e+00, 4.2890e-01, 3.6573e+00, 0.0000e+00,\n",
            "        3.9474e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.5532e+00, 0.0000e+00,\n",
            "        0.0000e+00, 3.2856e+00, 6.2212e+00, 0.0000e+00, 5.6839e+00, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        2.1959e+00, 0.0000e+00, 2.2285e+00, 0.0000e+00, 0.0000e+00, 2.2406e-01,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 1.5501e-01, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 1.7819e+00, 3.4012e+00, 2.6951e+00, 0.0000e+00, 2.7932e+00,\n",
            "        4.7348e+00, 4.0468e+00, 0.0000e+00, 4.2439e+00, 0.0000e+00, 2.7791e+00,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 1.5193e+00, 0.0000e+00, 2.8927e+00,\n",
            "        0.0000e+00, 3.3271e+00, 2.7180e-01, 4.3703e-01, 5.4332e-01, 0.0000e+00,\n",
            "        2.4096e+00, 0.0000e+00, 0.0000e+00, 4.6361e+00, 6.6649e+00, 2.6544e+00,\n",
            "        4.2342e+00, 1.7002e+00, 3.3955e+00, 4.3884e+00, 4.9586e+00, 0.0000e+00,\n",
            "        1.3255e+00, 1.7680e+00, 0.0000e+00, 5.4418e+00, 0.0000e+00, 8.2371e+00,\n",
            "        2.0063e+00, 0.0000e+00, 9.4311e-01, 1.9510e+00, 0.0000e+00, 5.6093e+00,\n",
            "        0.0000e+00, 3.4897e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 7.4151e+00, 0.0000e+00, 6.1397e+00],\n",
            "       grad_fn=<ReluBackward0>)\n",
            "x fc_pi output tensor([ 45.9809, -29.8396,   4.6048, -32.4022], grad_fn=<AddBackward0>)\n",
            "x F.softmax(x, dim=softmax_dim) tensor([ 45.9809, -29.8396,   4.6048, -32.4022], grad_fn=<AddBackward0>)\n",
            "prob tensor([1.0000e+00, 1.1792e-33, 1.0731e-18, 9.0918e-35],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "step 데이터 : [6 4 5 0] -100 -106 True False\n",
            "put_data    : [7 4 5 0] 0 -100 [6 4 5 0] True\n",
            "input x tensor([[9., 4., 5., 0.],\n",
            "        [8., 4., 5., 0.],\n",
            "        [7., 4., 5., 0.],\n",
            "        [7., 5., 5., 0.],\n",
            "        [7., 4., 5., 0.],\n",
            "        [7., 5., 5., 0.],\n",
            "        [7., 4., 5., 0.]])\n",
            "x F.relu output tensor([[0.0000, 2.5145, 3.1070,  ..., 7.8464, 0.0000, 7.1092],\n",
            "        [0.0000, 2.1546, 2.7663,  ..., 7.6308, 0.0000, 6.6244],\n",
            "        [0.0000, 1.7948, 2.4255,  ..., 7.4151, 0.0000, 6.1397],\n",
            "        ...,\n",
            "        [0.0000, 1.7948, 2.4255,  ..., 7.4151, 0.0000, 6.1397],\n",
            "        [0.0000, 2.1023, 2.8922,  ..., 7.9717, 0.0000, 6.6616],\n",
            "        [0.0000, 1.7948, 2.4255,  ..., 7.4151, 0.0000, 6.1397]],\n",
            "       grad_fn=<ReluBackward0>)\n",
            "x fc_pi output tensor([[ 54.3113, -34.8733,   4.3451, -36.8489],\n",
            "        [ 50.1379, -32.3483,   4.4734, -34.6214],\n",
            "        [ 45.9809, -29.8396,   4.6048, -32.4022],\n",
            "        [ 48.8904, -31.7468,   4.9843, -34.2031],\n",
            "        [ 45.9809, -29.8396,   4.6048, -32.4022],\n",
            "        [ 48.8904, -31.7468,   4.9843, -34.2031],\n",
            "        [ 45.9809, -29.8396,   4.6048, -32.4022]], grad_fn=<AddmmBackward0>)\n",
            "x F.softmax(x, dim=softmax_dim) tensor([[ 54.3113, -34.8733,   4.3451, -36.8489],\n",
            "        [ 50.1379, -32.3483,   4.4734, -34.6214],\n",
            "        [ 45.9809, -29.8396,   4.6048, -32.4022],\n",
            "        [ 48.8904, -31.7468,   4.9843, -34.2031],\n",
            "        [ 45.9809, -29.8396,   4.6048, -32.4022],\n",
            "        [ 48.8904, -31.7468,   4.9843, -34.2031],\n",
            "        [ 45.9809, -29.8396,   4.6048, -32.4022]], grad_fn=<AddmmBackward0>)\n",
            "prob tensor([[1.0000e+00, 1.8519e-39, 1.9952e-22, 2.5683e-40],\n",
            "        [1.0000e+00, 1.5021e-36, 1.4729e-20, 1.5470e-37],\n",
            "        [1.0000e+00, 1.1792e-33, 1.0731e-18, 9.0920e-35],\n",
            "        [1.0000e+00, 9.5441e-36, 8.5473e-20, 8.1841e-37],\n",
            "        [1.0000e+00, 1.1792e-33, 1.0731e-18, 9.0920e-35],\n",
            "        [1.0000e+00, 9.5441e-36, 8.5473e-20, 8.1841e-37],\n",
            "        [1.0000e+00, 1.1792e-33, 1.0731e-18, 9.0920e-35]],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "\n",
            "\n",
            "▶▶▶ 3808  : max cum reward :  1887  epsilon = 0.619190000000042\n",
            "\n",
            "\n",
            "▶▶▶3809번째 에피소드 시작, env 초기화 완료.\n",
            "가져와야 할 아이템 : ['F', 'N', 'O']\n",
            "\n",
            "현재 state         :  [9 4 0 1]\n",
            "step 데이터 : [9 3 0 1] -100 -100 True False\n",
            "put_data    : [9 4 0 1] 2 -100 [9 3 0 1] True\n",
            "input x tensor([[9., 4., 0., 1.]])\n",
            "x F.relu output tensor([[0.0000e+00, 3.9209e+00, 4.6135e+00, 4.7842e+00, 0.0000e+00, 2.5194e-01,\n",
            "         0.0000e+00, 2.4248e+00, 0.0000e+00, 0.0000e+00, 4.1959e+00, 4.1754e+00,\n",
            "         2.4733e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "         1.3770e-01, 3.9214e+00, 0.0000e+00, 0.0000e+00, 2.8874e+00, 5.8219e+00,\n",
            "         2.5229e+00, 3.7192e+00, 4.2364e+00, 5.6608e+00, 0.0000e+00, 2.9350e+00,\n",
            "         0.0000e+00, 3.3154e+00, 1.6159e+00, 4.5170e+00, 4.0146e+00, 2.4364e+00,\n",
            "         4.8738e+00, 1.5549e+00, 5.0550e+00, 0.0000e+00, 0.0000e+00, 2.9452e+00,\n",
            "         0.0000e+00, 0.0000e+00, 3.4996e+00, 1.8787e+00, 0.0000e+00, 2.6862e+00,\n",
            "         0.0000e+00, 0.0000e+00, 3.1979e+00, 0.0000e+00, 3.6550e+00, 4.7559e+00,\n",
            "         0.0000e+00, 0.0000e+00, 3.0996e+00, 1.8339e-02, 2.8239e+00, 0.0000e+00,\n",
            "         5.9626e+00, 0.0000e+00, 1.8933e+00, 2.1022e+00, 2.8362e+00, 0.0000e+00,\n",
            "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.8336e+00,\n",
            "         0.0000e+00, 1.1400e+00, 1.7972e+00, 0.0000e+00, 1.8845e+00, 0.0000e+00,\n",
            "         5.1734e+00, 0.0000e+00, 3.5727e+00, 3.9325e-01, 0.0000e+00, 4.6976e+00,\n",
            "         0.0000e+00, 2.9647e+00, 0.0000e+00, 6.3922e+00, 0.0000e+00, 0.0000e+00,\n",
            "         0.0000e+00, 4.0148e+00, 0.0000e+00, 6.4551e+00, 4.7107e-01, 2.9442e+00,\n",
            "         7.2045e-01, 1.0916e+00, 3.1940e+00, 1.4466e-01, 8.1359e-01, 5.9347e+00,\n",
            "         4.5758e-01, 5.6605e+00, 3.8663e+00, 0.0000e+00, 2.0515e+00, 0.0000e+00,\n",
            "         2.0483e-01, 4.7430e+00, 0.0000e+00, 1.5457e+00, 0.0000e+00, 3.5461e+00,\n",
            "         2.5581e+00, 4.0584e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.2690e+00,\n",
            "         0.0000e+00, 1.3839e+00, 0.0000e+00, 2.7266e+00, 1.1317e+00, 0.0000e+00,\n",
            "         0.0000e+00, 0.0000e+00, 5.6596e+00, 5.9326e+00, 5.0938e-04, 1.5999e+00,\n",
            "         2.8666e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.4164e+00, 2.0156e+00,\n",
            "         3.7706e+00, 9.4875e-01, 0.0000e+00, 0.0000e+00, 2.9625e+00, 0.0000e+00,\n",
            "         1.5168e+00, 2.7889e+00, 0.0000e+00, 6.3579e+00, 2.6232e+00, 1.6449e+00,\n",
            "         0.0000e+00, 5.1430e+00, 6.6860e-01, 5.5085e+00, 0.0000e+00, 0.0000e+00,\n",
            "         0.0000e+00, 4.1172e+00, 1.5926e+00, 7.3691e+00, 0.0000e+00, 3.0446e+00,\n",
            "         0.0000e+00, 3.5494e+00, 1.7062e+00, 0.0000e+00, 2.4781e+00, 0.0000e+00,\n",
            "         6.0218e+00, 0.0000e+00, 1.9189e+00, 0.0000e+00, 4.1243e+00, 0.0000e+00,\n",
            "         0.0000e+00, 4.4790e+00, 6.3194e+00, 0.0000e+00, 5.5848e+00, 0.0000e+00,\n",
            "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "         1.1650e+00, 0.0000e+00, 3.3193e+00, 0.0000e+00, 0.0000e+00, 2.5479e+00,\n",
            "         0.0000e+00, 0.0000e+00, 9.8128e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "         0.0000e+00, 4.0868e+00, 2.5417e+00, 3.9261e+00, 0.0000e+00, 2.9988e+00,\n",
            "         6.4571e+00, 1.0262e+00, 1.0834e+00, 2.3801e+00, 0.0000e+00, 3.5903e-01,\n",
            "         0.0000e+00, 0.0000e+00, 1.8649e+00, 4.5963e-01, 0.0000e+00, 1.8714e+00,\n",
            "         0.0000e+00, 2.3269e+00, 0.0000e+00, 1.8815e+00, 3.2423e+00, 0.0000e+00,\n",
            "         1.1078e-01, 0.0000e+00, 0.0000e+00, 4.6377e+00, 4.7447e+00, 3.9688e+00,\n",
            "         4.4859e+00, 2.5131e+00, 6.0785e+00, 3.0373e+00, 5.0826e+00, 0.0000e+00,\n",
            "         0.0000e+00, 0.0000e+00, 0.0000e+00, 4.2177e+00, 0.0000e+00, 6.2308e+00,\n",
            "         1.7014e+00, 0.0000e+00, 3.0349e+00, 1.4645e+00, 5.3573e-01, 3.4116e+00,\n",
            "         0.0000e+00, 2.1987e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "         0.0000e+00, 4.9404e+00, 0.0000e+00, 6.9539e+00]],\n",
            "       grad_fn=<ReluBackward0>)\n",
            "x fc_pi output tensor([[ 50.5321, -31.3255,   0.6114, -28.5713]], grad_fn=<AddmmBackward0>)\n",
            "x F.softmax(x, dim=softmax_dim) tensor([[ 50.5321, -31.3255,   0.6114, -28.5713]], grad_fn=<AddmmBackward0>)\n",
            "prob tensor([[1.0000e+00, 2.8163e-36, 2.0877e-22, 4.4241e-35]],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "\n",
            "\n",
            "▶▶▶ 3809  : max cum reward :  1887  epsilon = 0.619090000000042\n",
            "\n",
            "\n",
            "▶▶▶3810번째 에피소드 시작, env 초기화 완료.\n",
            "가져와야 할 아이템 : ['C', 'D', 'H', 'J', 'L', 'P']\n",
            "\n",
            "현재 state         :  [9 4 3 0]\n",
            "tensor([9, 4, 3, 0])\n",
            "tensor([9., 4., 3., 0.])\n",
            "end input\n",
            "input x tensor([9., 4., 3., 0.])\n",
            "x F.relu output tensor([0.0000, 3.1545, 3.7154, 4.0807, 0.0000, 0.1529, 0.0000, 1.4036, 0.0000,\n",
            "        0.0000, 4.0939, 3.0273, 2.8086, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 4.1927, 0.0000, 0.0000, 3.8429, 5.9087, 3.3775, 5.1900, 2.9443,\n",
            "        5.1410, 0.0000, 4.2829, 0.0000, 3.0577, 1.4485, 2.6976, 4.1035, 2.7969,\n",
            "        3.7145, 3.2569, 5.1056, 0.0000, 0.4122, 3.9211, 0.0000, 0.0000, 4.6140,\n",
            "        1.6198, 0.0000, 4.1320, 0.0000, 0.0000, 1.7031, 0.0000, 5.3142, 4.1901,\n",
            "        0.0000, 0.0000, 3.6166, 0.2362, 4.1830, 0.0000, 5.6463, 0.3251, 3.4167,\n",
            "        2.6457, 2.4007, 0.4417, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 2.9085,\n",
            "        0.0000, 0.5441, 1.6313, 0.0000, 1.9832, 0.0000, 4.3359, 0.0000, 4.8831,\n",
            "        1.6440, 0.0000, 5.4056, 0.0000, 4.4146, 0.1660, 6.6210, 0.0000, 0.0000,\n",
            "        0.0000, 3.1076, 0.0000, 5.5426, 0.0000, 4.2087, 0.0000, 1.0621, 3.4435,\n",
            "        0.0000, 0.0000, 5.5009, 0.3063, 5.7763, 3.6012, 0.0000, 1.0617, 0.0000,\n",
            "        1.4936, 4.9538, 0.0000, 0.1600, 0.0000, 2.8176, 3.7196, 4.9341, 0.0000,\n",
            "        0.0000, 0.0000, 2.9408, 0.0000, 2.6443, 0.0000, 4.5717, 2.6590, 0.0000,\n",
            "        0.0000, 0.0000, 5.2855, 5.2162, 0.0000, 2.2519, 2.9992, 0.0000, 0.0000,\n",
            "        0.0000, 3.4864, 2.1676, 3.8509, 1.1206, 0.0000, 0.0000, 3.3452, 0.0000,\n",
            "        1.3994, 2.8953, 0.0000, 7.0381, 3.3465, 1.7284, 0.0000, 6.9370, 0.1032,\n",
            "        5.3570, 0.0000, 0.0000, 0.0000, 4.8114, 1.8408, 5.7924, 0.0000, 2.8112,\n",
            "        0.0000, 3.9091, 2.6898, 0.0000, 3.0864, 0.0000, 5.3611, 0.0000, 0.8005,\n",
            "        0.0000, 4.5897, 0.0000, 0.0000, 4.0079, 6.8637, 0.0000, 6.2397, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.8465, 0.0000, 3.0363,\n",
            "        0.0000, 0.0000, 1.7941, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 3.1353, 3.3220, 3.6815, 0.0000, 3.2358, 5.7895, 3.0216, 0.0000,\n",
            "        3.6946, 0.0000, 1.7354, 0.0000, 0.0000, 0.0535, 1.0666, 0.0000, 2.5276,\n",
            "        0.0000, 3.1057, 0.0000, 1.0151, 1.6628, 0.0000, 1.5551, 0.0000, 0.0000,\n",
            "        5.2496, 6.4129, 3.3885, 5.1398, 2.6178, 4.9628, 4.4562, 5.6198, 0.0000,\n",
            "        0.2734, 0.4633, 0.0000, 5.4510, 0.0000, 8.1976, 2.2639, 0.0000, 2.0933,\n",
            "        2.0092, 0.0000, 4.7486, 0.0000, 3.5463, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 6.6139, 0.0000, 6.8845], grad_fn=<ReluBackward0>)\n",
            "x fc_pi output tensor([ 52.8625, -33.4245,   2.7796, -33.5373], grad_fn=<AddBackward0>)\n",
            "x F.softmax(x, dim=softmax_dim) tensor([ 52.8625, -33.4245,   2.7796, -33.5373], grad_fn=<AddBackward0>)\n",
            "prob tensor([1.0000e+00, 3.3576e-38, 1.7753e-22, 2.9994e-38],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "step 데이터 : [8 4 3 0] -1 -1 False False\n",
            "put_data    : [9 4 3 0] 0 -1 [8 4 3 0] False\n",
            "step 데이터 : [8 3 3 0] -1 -2 False False\n",
            "put_data    : [8 4 3 0] 2 -1 [8 3 3 0] False\n",
            "step 데이터 : [7 3 3 0] -1 -3 False False\n",
            "put_data    : [8 3 3 0] 0 -1 [7 3 3 0] False\n",
            "step 데이터 : [7 2 3 0] -1 -4 False False\n",
            "put_data    : [7 3 3 0] 2 -1 [7 2 3 0] False\n",
            "step 데이터 : [6 2 3 0] -100 -104 True False\n",
            "put_data    : [7 2 3 0] 0 -100 [6 2 3 0] True\n",
            "input x tensor([[9., 4., 3., 0.],\n",
            "        [8., 4., 3., 0.],\n",
            "        [8., 3., 3., 0.],\n",
            "        [7., 3., 3., 0.],\n",
            "        [7., 2., 3., 0.]])\n",
            "x F.relu output tensor([[0.0000, 3.1545, 3.7154,  ..., 6.6139, 0.0000, 6.8845],\n",
            "        [0.0000, 2.7945, 3.3745,  ..., 6.3981, 0.0000, 6.3996],\n",
            "        [0.0000, 2.4868, 2.9077,  ..., 5.8413, 0.0000, 5.8775],\n",
            "        [0.0000, 2.1268, 2.5668,  ..., 5.6255, 0.0000, 5.3925],\n",
            "        [0.0000, 1.8192, 2.0999,  ..., 5.0687, 0.0000, 4.8705]],\n",
            "       grad_fn=<ReluBackward0>)\n",
            "x fc_pi output tensor([[ 52.8625, -33.4245,   2.7796, -33.5373],\n",
            "        [ 48.6762, -30.8848,   2.9252, -31.2864],\n",
            "        [ 45.8084, -29.0453,   2.5371, -29.4625],\n",
            "        [ 41.6106, -26.4955,   2.6767, -27.2225],\n",
            "        [ 38.7629, -24.6832,   2.3215, -25.4124]], grad_fn=<AddmmBackward0>)\n",
            "x F.softmax(x, dim=softmax_dim) tensor([[ 52.8625, -33.4245,   2.7796, -33.5373],\n",
            "        [ 48.6762, -30.8848,   2.9252, -31.2864],\n",
            "        [ 45.8084, -29.0453,   2.5371, -29.4625],\n",
            "        [ 41.6106, -26.4955,   2.6767, -27.2225],\n",
            "        [ 38.7629, -24.6832,   2.3215, -25.4124]], grad_fn=<AddmmBackward0>)\n",
            "prob tensor([[1.0000e+00, 3.3576e-38, 1.7753e-22, 2.9994e-38],\n",
            "        [1.0000e+00, 2.7995e-35, 1.3508e-20, 1.8735e-35],\n",
            "        [1.0000e+00, 3.1005e-33, 1.6124e-19, 2.0430e-33],\n",
            "        [1.0000e+00, 2.6417e-30, 1.2337e-17, 1.2769e-30],\n",
            "        [1.0000e+00, 2.7908e-28, 1.4918e-16, 1.3459e-28]],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "\n",
            "\n",
            "▶▶▶ 3810  : max cum reward :  1887  epsilon = 0.618990000000042\n",
            "\n",
            "\n",
            "▶▶▶3811번째 에피소드 시작, env 초기화 완료.\n",
            "가져와야 할 아이템 : ['C', 'E', 'G', 'M', 'O', 'P']\n",
            "\n",
            "현재 state         :  [9 4 3 0]\n",
            "tensor([9, 4, 3, 0])\n",
            "tensor([9., 4., 3., 0.])\n",
            "end input\n",
            "input x tensor([9., 4., 3., 0.])\n",
            "x F.relu output tensor([0.0000, 3.1556, 3.7162, 4.0815, 0.0000, 0.1530, 0.0000, 1.4043, 0.0000,\n",
            "        0.0000, 4.0946, 3.0280, 2.8095, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 4.1935, 0.0000, 0.0000, 3.8440, 5.9095, 3.3782, 5.1908, 2.9452,\n",
            "        5.1420, 0.0000, 4.2840, 0.0000, 3.0583, 1.4490, 2.6980, 4.1042, 2.7978,\n",
            "        3.7153, 3.2578, 5.1065, 0.0000, 0.4123, 3.9223, 0.0000, 0.0000, 4.6147,\n",
            "        1.6208, 0.0000, 4.1326, 0.0000, 0.0000, 1.7036, 0.0000, 5.3150, 4.1909,\n",
            "        0.0000, 0.0000, 3.6173, 0.2373, 4.1840, 0.0000, 5.6472, 0.3257, 3.4176,\n",
            "        2.6465, 2.4013, 0.4425, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 2.9093,\n",
            "        0.0000, 0.5446, 1.6320, 0.0000, 1.9842, 0.0000, 4.3366, 0.0000, 4.8838,\n",
            "        1.6450, 0.0000, 5.4063, 0.0000, 4.4156, 0.1662, 6.6217, 0.0000, 0.0000,\n",
            "        0.0000, 3.1087, 0.0000, 5.5433, 0.0000, 4.2096, 0.0000, 1.0627, 3.4443,\n",
            "        0.0000, 0.0000, 5.5017, 0.3063, 5.7775, 3.6019, 0.0000, 1.0623, 0.0000,\n",
            "        1.4945, 4.9546, 0.0000, 0.1603, 0.0000, 2.8182, 3.7204, 4.9347, 0.0000,\n",
            "        0.0000, 0.0000, 2.9415, 0.0000, 2.6452, 0.0000, 4.5727, 2.6598, 0.0000,\n",
            "        0.0000, 0.0000, 5.2863, 5.2173, 0.0000, 2.2526, 3.0000, 0.0000, 0.0000,\n",
            "        0.0000, 3.4872, 2.1684, 3.8519, 1.1211, 0.0000, 0.0000, 3.3463, 0.0000,\n",
            "        1.4002, 2.8960, 0.0000, 7.0389, 3.3474, 1.7292, 0.0000, 6.9380, 0.1038,\n",
            "        5.3578, 0.0000, 0.0000, 0.0000, 4.8123, 1.8416, 5.7931, 0.0000, 2.8121,\n",
            "        0.0000, 3.9101, 2.6907, 0.0000, 3.0873, 0.0000, 5.3621, 0.0000, 0.8017,\n",
            "        0.0000, 4.5904, 0.0000, 0.0000, 4.0086, 6.8643, 0.0000, 6.2405, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.8477, 0.0000, 3.0372,\n",
            "        0.0000, 0.0000, 1.7951, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 3.1359, 3.3228, 3.6823, 0.0000, 3.2369, 5.7902, 3.0225, 0.0000,\n",
            "        3.6956, 0.0000, 1.7363, 0.0000, 0.0000, 0.0534, 1.0675, 0.0000, 2.5287,\n",
            "        0.0000, 3.1065, 0.0000, 1.0160, 1.6635, 0.0000, 1.5557, 0.0000, 0.0000,\n",
            "        5.2503, 6.4138, 3.3894, 5.1406, 2.6187, 4.9637, 4.4571, 5.6210, 0.0000,\n",
            "        0.2739, 0.4638, 0.0000, 5.4517, 0.0000, 8.1987, 2.2648, 0.0000, 2.0940,\n",
            "        2.0102, 0.0000, 4.7497, 0.0000, 3.5471, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 6.6150, 0.0000, 6.8854], grad_fn=<ReluBackward0>)\n",
            "x fc_pi output tensor([ 52.8918, -33.4435,   2.7834, -33.5679], grad_fn=<AddBackward0>)\n",
            "x F.softmax(x, dim=softmax_dim) tensor([ 52.8918, -33.4435,   2.7834, -33.5679], grad_fn=<AddBackward0>)\n",
            "prob tensor([1.0000e+00, 3.1992e-38, 1.7306e-22, 2.8249e-38],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "step 데이터 : [8 4 3 0] -1 -1 False False\n",
            "put_data    : [9 4 3 0] 0 -1 [8 4 3 0] False\n",
            "step 데이터 : [7 4 3 0] -1 -2 False False\n",
            "put_data    : [8 4 3 0] 0 -1 [7 4 3 0] False\n",
            "tensor([7, 4, 3, 0])\n",
            "tensor([7., 4., 3., 0.])\n",
            "end input\n",
            "input x tensor([7., 4., 3., 0.])\n",
            "x F.relu output tensor([0.0000, 2.4354, 3.0343, 2.8249, 0.2669, 0.0000, 0.0000, 1.1482, 0.0000,\n",
            "        0.0000, 2.9800, 2.3323, 2.6011, 0.0000, 0.4118, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 3.7192, 0.0000, 0.0000, 3.3187, 4.6470, 2.9749, 4.5574, 1.8452,\n",
            "        4.0600, 0.0000, 3.5921, 0.0000, 2.5186, 1.2817, 2.1317, 3.7601, 2.6266,\n",
            "        2.5419, 2.6920, 4.2016, 0.0000, 0.7430, 3.1326, 0.0000, 0.0000, 4.0800,\n",
            "        1.4927, 0.0000, 3.4517, 0.0000, 0.0000, 1.4588, 0.0000, 4.6479, 3.2810,\n",
            "        0.0000, 0.0000, 3.0743, 0.1366, 3.8389, 0.0000, 4.8926, 0.9295, 2.7285,\n",
            "        2.4080, 1.6464, 0.4890, 0.0000, 0.3310, 0.0000, 0.0000, 0.0000, 2.1762,\n",
            "        0.0000, 0.0000, 1.4383, 0.0000, 1.9754, 0.0000, 3.3662, 0.0000, 4.4998,\n",
            "        1.7890, 0.0000, 4.3452, 0.0000, 3.6319, 0.5061, 5.6440, 0.0000, 0.0000,\n",
            "        0.0000, 2.2358, 0.0000, 4.6780, 0.0000, 3.3286, 0.0000, 0.6237, 2.6910,\n",
            "        0.0000, 0.0000, 4.4375, 0.2713, 4.9091, 3.2153, 0.0000, 0.8351, 0.0000,\n",
            "        1.7116, 4.4965, 0.0000, 0.0000, 0.0000, 2.3898, 3.7133, 4.6010, 0.0000,\n",
            "        0.0000, 0.0000, 2.8181, 0.0000, 2.7215, 0.0000, 4.3085, 2.5625, 0.0000,\n",
            "        0.0000, 0.0000, 4.5736, 4.3746, 0.0000, 2.0318, 2.5555, 0.0000, 0.0000,\n",
            "        0.0000, 2.7210, 1.5042, 3.2713, 0.7079, 0.0000, 0.0000, 3.1637, 0.0000,\n",
            "        1.3981, 2.1630, 0.0000, 6.0438, 3.0237, 1.1332, 0.0000, 6.2838, 0.3940,\n",
            "        4.2345, 0.0000, 0.0000, 0.0000, 4.1282, 1.8539, 4.6378, 0.0000, 1.9797,\n",
            "        0.0000, 3.1997, 2.9107, 0.0000, 2.9314, 0.0000, 4.5635, 0.0000, 0.5366,\n",
            "        0.0000, 4.1563, 0.0000, 0.0000, 3.4009, 5.9423, 0.0000, 5.1969, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.5981, 0.0000, 2.5878,\n",
            "        0.0000, 0.0000, 0.8904, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 2.3400, 2.6368, 3.1098, 0.0000, 2.7942, 4.9005, 2.9995, 0.0000,\n",
            "        3.2004, 0.0000, 1.7593, 0.0000, 0.0000, 0.0754, 1.2733, 0.0000, 2.3435,\n",
            "        0.0000, 2.9682, 0.0000, 1.0458, 1.4123, 0.0000, 1.5652, 0.0000, 0.0000,\n",
            "        4.1381, 5.5475, 2.7973, 4.0110, 1.8594, 4.0806, 3.6572, 4.8391, 0.0000,\n",
            "        0.4349, 0.7854, 0.0000, 4.8971, 0.0000, 7.1281, 1.9328, 0.0000, 1.4477,\n",
            "        1.5855, 0.0000, 4.4677, 0.0000, 2.7082, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 6.1832, 0.0000, 5.9154], grad_fn=<ReluBackward0>)\n",
            "x fc_pi output tensor([ 44.5196, -28.3744,   3.0735, -29.0629], grad_fn=<AddBackward0>)\n",
            "x F.softmax(x, dim=softmax_dim) tensor([ 44.5196, -28.3744,   3.0735, -29.0629], grad_fn=<AddBackward0>)\n",
            "prob tensor([1.0000e+00, 2.2007e-32, 1.0005e-18, 1.1054e-32],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "step 데이터 : [6 4 3 0] -100 -102 True False\n",
            "put_data    : [7 4 3 0] 0 -100 [6 4 3 0] True\n",
            "input x tensor([[9., 4., 3., 0.],\n",
            "        [8., 4., 3., 0.],\n",
            "        [7., 4., 3., 0.]])\n",
            "x F.relu output tensor([[0.0000, 3.1556, 3.7162, 4.0815, 0.0000, 0.1530, 0.0000, 1.4043, 0.0000,\n",
            "         0.0000, 4.0946, 3.0280, 2.8095, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 4.1935, 0.0000, 0.0000, 3.8440, 5.9095, 3.3782, 5.1908, 2.9452,\n",
            "         5.1420, 0.0000, 4.2840, 0.0000, 3.0583, 1.4490, 2.6980, 4.1042, 2.7978,\n",
            "         3.7153, 3.2578, 5.1065, 0.0000, 0.4123, 3.9223, 0.0000, 0.0000, 4.6147,\n",
            "         1.6208, 0.0000, 4.1326, 0.0000, 0.0000, 1.7036, 0.0000, 5.3150, 4.1909,\n",
            "         0.0000, 0.0000, 3.6173, 0.2373, 4.1840, 0.0000, 5.6472, 0.3257, 3.4176,\n",
            "         2.6465, 2.4013, 0.4425, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 2.9093,\n",
            "         0.0000, 0.5446, 1.6320, 0.0000, 1.9842, 0.0000, 4.3366, 0.0000, 4.8838,\n",
            "         1.6450, 0.0000, 5.4063, 0.0000, 4.4156, 0.1662, 6.6217, 0.0000, 0.0000,\n",
            "         0.0000, 3.1087, 0.0000, 5.5433, 0.0000, 4.2096, 0.0000, 1.0627, 3.4443,\n",
            "         0.0000, 0.0000, 5.5017, 0.3063, 5.7775, 3.6019, 0.0000, 1.0623, 0.0000,\n",
            "         1.4945, 4.9546, 0.0000, 0.1603, 0.0000, 2.8182, 3.7204, 4.9347, 0.0000,\n",
            "         0.0000, 0.0000, 2.9415, 0.0000, 2.6452, 0.0000, 4.5727, 2.6598, 0.0000,\n",
            "         0.0000, 0.0000, 5.2863, 5.2173, 0.0000, 2.2526, 3.0000, 0.0000, 0.0000,\n",
            "         0.0000, 3.4872, 2.1684, 3.8519, 1.1211, 0.0000, 0.0000, 3.3463, 0.0000,\n",
            "         1.4002, 2.8960, 0.0000, 7.0389, 3.3474, 1.7292, 0.0000, 6.9380, 0.1038,\n",
            "         5.3578, 0.0000, 0.0000, 0.0000, 4.8123, 1.8416, 5.7931, 0.0000, 2.8121,\n",
            "         0.0000, 3.9101, 2.6907, 0.0000, 3.0873, 0.0000, 5.3621, 0.0000, 0.8017,\n",
            "         0.0000, 4.5904, 0.0000, 0.0000, 4.0086, 6.8643, 0.0000, 6.2405, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.8477, 0.0000, 3.0372,\n",
            "         0.0000, 0.0000, 1.7951, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 3.1359, 3.3228, 3.6823, 0.0000, 3.2369, 5.7902, 3.0225, 0.0000,\n",
            "         3.6956, 0.0000, 1.7363, 0.0000, 0.0000, 0.0534, 1.0675, 0.0000, 2.5287,\n",
            "         0.0000, 3.1065, 0.0000, 1.0160, 1.6635, 0.0000, 1.5557, 0.0000, 0.0000,\n",
            "         5.2503, 6.4138, 3.3894, 5.1406, 2.6187, 4.9637, 4.4571, 5.6210, 0.0000,\n",
            "         0.2739, 0.4638, 0.0000, 5.4517, 0.0000, 8.1987, 2.2648, 0.0000, 2.0940,\n",
            "         2.0102, 0.0000, 4.7497, 0.0000, 3.5471, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 6.6150, 0.0000, 6.8854],\n",
            "        [0.0000, 2.7955, 3.3752, 3.4532, 0.0000, 0.0000, 0.0000, 1.2762, 0.0000,\n",
            "         0.0000, 3.5373, 2.6801, 2.7053, 0.0000, 0.1707, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 3.9564, 0.0000, 0.0000, 3.5813, 5.2783, 3.1765, 4.8741, 2.3952,\n",
            "         4.6010, 0.0000, 3.9380, 0.0000, 2.7884, 1.3654, 2.4149, 3.9321, 2.7122,\n",
            "         3.1286, 2.9749, 4.6541, 0.0000, 0.5777, 3.5274, 0.0000, 0.0000, 4.3474,\n",
            "         1.5567, 0.0000, 3.7922, 0.0000, 0.0000, 1.5812, 0.0000, 4.9815, 3.7359,\n",
            "         0.0000, 0.0000, 3.3458, 0.1869, 4.0114, 0.0000, 5.2699, 0.6276, 3.0730,\n",
            "         2.5273, 2.0239, 0.4657, 0.0000, 0.1201, 0.0000, 0.0000, 0.0000, 2.5427,\n",
            "         0.0000, 0.1880, 1.5351, 0.0000, 1.9798, 0.0000, 3.8514, 0.0000, 4.6918,\n",
            "         1.7170, 0.0000, 4.8757, 0.0000, 4.0237, 0.3361, 6.1329, 0.0000, 0.0000,\n",
            "         0.0000, 2.6723, 0.0000, 5.1107, 0.0000, 3.7691, 0.0000, 0.8432, 3.0677,\n",
            "         0.0000, 0.0000, 4.9696, 0.2888, 5.3433, 3.4086, 0.0000, 0.9487, 0.0000,\n",
            "         1.6030, 4.7256, 0.0000, 0.0000, 0.0000, 2.6040, 3.7169, 4.7679, 0.0000,\n",
            "         0.0000, 0.0000, 2.8798, 0.0000, 2.6833, 0.0000, 4.4406, 2.6112, 0.0000,\n",
            "         0.0000, 0.0000, 4.9300, 4.7959, 0.0000, 2.1422, 2.7778, 0.0000, 0.0000,\n",
            "         0.0000, 3.1041, 1.8363, 3.5616, 0.9145, 0.0000, 0.0000, 3.2550, 0.0000,\n",
            "         1.3992, 2.5295, 0.0000, 6.5414, 3.1855, 1.4312, 0.0000, 6.6109, 0.2489,\n",
            "         4.7961, 0.0000, 0.0000, 0.0000, 4.4702, 1.8477, 5.2154, 0.0000, 2.3959,\n",
            "         0.0000, 3.5549, 2.8007, 0.0000, 3.0093, 0.0000, 4.9628, 0.0000, 0.6692,\n",
            "         0.0000, 4.3733, 0.0000, 0.0000, 3.7047, 6.4033, 0.0000, 5.7187, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.7229, 0.0000, 2.8125,\n",
            "         0.0000, 0.0000, 1.3427, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 2.7379, 2.9798, 3.3961, 0.0000, 3.0156, 5.3453, 3.0110, 0.0000,\n",
            "         3.4480, 0.0000, 1.7478, 0.0000, 0.0000, 0.0644, 1.1704, 0.0000, 2.4361,\n",
            "         0.0000, 3.0373, 0.0000, 1.0309, 1.5379, 0.0000, 1.5604, 0.0000, 0.0000,\n",
            "         4.6942, 5.9807, 3.0934, 4.5758, 2.2390, 4.5221, 4.0572, 5.2300, 0.0000,\n",
            "         0.3544, 0.6246, 0.0000, 5.1744, 0.0000, 7.6634, 2.0988, 0.0000, 1.7708,\n",
            "         1.7978, 0.0000, 4.6087, 0.0000, 3.1277, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 6.3991, 0.0000, 6.4004],\n",
            "        [0.0000, 2.4354, 3.0343, 2.8249, 0.2669, 0.0000, 0.0000, 1.1482, 0.0000,\n",
            "         0.0000, 2.9800, 2.3323, 2.6011, 0.0000, 0.4118, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 3.7192, 0.0000, 0.0000, 3.3187, 4.6470, 2.9749, 4.5574, 1.8452,\n",
            "         4.0600, 0.0000, 3.5921, 0.0000, 2.5186, 1.2817, 2.1317, 3.7601, 2.6266,\n",
            "         2.5419, 2.6920, 4.2016, 0.0000, 0.7430, 3.1326, 0.0000, 0.0000, 4.0800,\n",
            "         1.4927, 0.0000, 3.4517, 0.0000, 0.0000, 1.4588, 0.0000, 4.6479, 3.2810,\n",
            "         0.0000, 0.0000, 3.0743, 0.1366, 3.8389, 0.0000, 4.8926, 0.9295, 2.7285,\n",
            "         2.4080, 1.6464, 0.4890, 0.0000, 0.3310, 0.0000, 0.0000, 0.0000, 2.1762,\n",
            "         0.0000, 0.0000, 1.4383, 0.0000, 1.9754, 0.0000, 3.3662, 0.0000, 4.4998,\n",
            "         1.7890, 0.0000, 4.3452, 0.0000, 3.6319, 0.5061, 5.6440, 0.0000, 0.0000,\n",
            "         0.0000, 2.2358, 0.0000, 4.6780, 0.0000, 3.3286, 0.0000, 0.6237, 2.6910,\n",
            "         0.0000, 0.0000, 4.4375, 0.2713, 4.9091, 3.2153, 0.0000, 0.8351, 0.0000,\n",
            "         1.7116, 4.4965, 0.0000, 0.0000, 0.0000, 2.3898, 3.7133, 4.6010, 0.0000,\n",
            "         0.0000, 0.0000, 2.8181, 0.0000, 2.7215, 0.0000, 4.3085, 2.5625, 0.0000,\n",
            "         0.0000, 0.0000, 4.5736, 4.3746, 0.0000, 2.0318, 2.5555, 0.0000, 0.0000,\n",
            "         0.0000, 2.7210, 1.5042, 3.2713, 0.7079, 0.0000, 0.0000, 3.1637, 0.0000,\n",
            "         1.3981, 2.1630, 0.0000, 6.0438, 3.0237, 1.1332, 0.0000, 6.2838, 0.3940,\n",
            "         4.2345, 0.0000, 0.0000, 0.0000, 4.1282, 1.8539, 4.6378, 0.0000, 1.9797,\n",
            "         0.0000, 3.1997, 2.9107, 0.0000, 2.9314, 0.0000, 4.5635, 0.0000, 0.5366,\n",
            "         0.0000, 4.1563, 0.0000, 0.0000, 3.4009, 5.9423, 0.0000, 5.1969, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.5981, 0.0000, 2.5878,\n",
            "         0.0000, 0.0000, 0.8904, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 2.3400, 2.6368, 3.1098, 0.0000, 2.7942, 4.9005, 2.9995, 0.0000,\n",
            "         3.2004, 0.0000, 1.7593, 0.0000, 0.0000, 0.0754, 1.2733, 0.0000, 2.3435,\n",
            "         0.0000, 2.9682, 0.0000, 1.0458, 1.4123, 0.0000, 1.5652, 0.0000, 0.0000,\n",
            "         4.1381, 5.5475, 2.7973, 4.0110, 1.8594, 4.0806, 3.6572, 4.8391, 0.0000,\n",
            "         0.4349, 0.7854, 0.0000, 4.8971, 0.0000, 7.1281, 1.9328, 0.0000, 1.4477,\n",
            "         1.5855, 0.0000, 4.4677, 0.0000, 2.7082, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 6.1832, 0.0000, 5.9154]], grad_fn=<ReluBackward0>)\n",
            "x fc_pi output tensor([[ 52.8918, -33.4435,   2.7834, -33.5679],\n",
            "        [ 48.7034, -30.9025,   2.9288, -31.3149],\n",
            "        [ 44.5196, -28.3744,   3.0735, -29.0629]], grad_fn=<AddmmBackward0>)\n",
            "x F.softmax(x, dim=softmax_dim) tensor([[ 52.8918, -33.4435,   2.7834, -33.5679],\n",
            "        [ 48.7034, -30.9025,   2.9288, -31.3149],\n",
            "        [ 44.5196, -28.3744,   3.0735, -29.0629]], grad_fn=<AddmmBackward0>)\n",
            "prob tensor([[1.0000e+00, 3.1992e-38, 1.7306e-22, 2.8249e-38],\n",
            "        [1.0000e+00, 2.6766e-35, 1.3193e-20, 1.7721e-35],\n",
            "        [1.0000e+00, 2.2007e-32, 1.0005e-18, 1.1054e-32]],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "\n",
            "\n",
            "▶▶▶ 3811  : max cum reward :  1887  epsilon = 0.618890000000042\n",
            "\n",
            "\n",
            "▶▶▶3812번째 에피소드 시작, env 초기화 완료.\n",
            "가져와야 할 아이템 : ['A', 'D', 'N']\n",
            "\n",
            "현재 state         :  [9 4 5 0]\n",
            "step 데이터 : [10  4  5  0] -100 -100 True False\n",
            "put_data    : [9 4 5 0] 1 -100 [10  4  5  0] True\n",
            "input x tensor([[9., 4., 5., 0.]])\n",
            "x F.relu output tensor([[0.0000, 2.5200, 3.1111, 3.8319, 0.3754, 0.0000, 0.0000, 0.8729, 0.0000,\n",
            "         0.0000, 4.1821, 2.3692, 2.9074, 0.0000, 0.9122, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 4.5333, 0.0000, 0.0000, 4.2638, 6.0824, 4.2651, 5.9452, 2.1958,\n",
            "         4.9306, 0.0000, 5.4093, 0.0000, 2.5824, 1.6240, 1.8155, 3.9037, 3.1677,\n",
            "         2.8927, 4.3750, 5.3319, 0.0000, 1.0658, 4.3601, 0.0000, 0.0000, 5.0776,\n",
            "         1.6671, 0.0000, 4.8406, 0.0000, 0.0000, 0.9338, 0.0000, 6.2907, 3.5025,\n",
            "         0.0000, 0.0000, 4.2401, 0.1076, 4.8782, 0.0000, 5.7353, 1.3814, 4.3556,\n",
            "         2.9011, 2.1093, 1.2347, 0.0000, 0.7878, 0.0000, 0.0000, 0.0000, 2.4695,\n",
            "         0.0000, 0.0305, 1.6152, 0.0000, 1.7964, 0.0000, 3.8610, 0.2453, 5.6983,\n",
            "         2.5850, 0.0000, 5.6466, 0.0000, 5.2966, 0.7081, 6.8447, 0.0000, 0.0000,\n",
            "         0.0000, 2.7198, 0.0000, 5.2701, 0.0000, 5.0639, 0.0000, 0.8053, 3.7751,\n",
            "         0.0000, 0.0000, 5.0043, 0.0000, 6.0205, 3.4366, 0.0000, 0.4906, 0.0000,\n",
            "         2.5168, 5.3372, 0.0000, 0.0000, 0.0000, 2.2805, 4.5966, 5.7641, 0.0000,\n",
            "         0.0000, 0.0000, 2.8592, 0.0000, 3.4678, 0.0000, 5.6134, 3.6450, 0.0000,\n",
            "         0.0000, 0.0000, 5.2496, 4.6798, 0.0000, 2.4638, 2.9422, 0.0000, 0.0000,\n",
            "         0.0000, 3.3827, 2.1269, 3.6658, 1.5252, 0.0000, 0.0000, 3.9158, 0.0000,\n",
            "         1.2121, 2.7477, 0.0000, 7.3162, 3.9405, 1.5277, 0.0000, 8.0824, 0.0000,\n",
            "         5.3482, 0.0000, 0.0000, 0.0000, 5.0342, 2.0749, 5.0404, 0.0000, 2.5503,\n",
            "         0.0000, 4.4940, 3.2366, 0.0367, 3.8171, 0.0000, 4.7501, 0.0000, 0.0852,\n",
            "         0.0000, 4.9908, 0.0000, 0.0000, 3.8965, 7.1460, 0.0000, 6.7309, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 2.4506, 0.0000, 2.6819,\n",
            "         0.0000, 0.0000, 1.1332, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 2.5807, 4.0907, 3.2714, 0.0000, 3.2410, 5.6277, 4.0737, 0.0000,\n",
            "         4.7435, 0.0000, 2.7603, 0.0000, 0.0000, 0.0000, 1.3170, 0.0000, 3.0827,\n",
            "         0.0000, 3.4693, 0.0000, 0.4117, 0.7977, 0.0000, 2.4024, 0.0000, 0.0000,\n",
            "         5.7517, 7.5351, 3.2505, 5.3678, 2.4637, 4.2825, 5.1925, 5.7454, 0.0000,\n",
            "         1.1669, 1.4490, 0.0000, 5.9997, 0.0000, 9.3126, 2.3423, 0.0000, 1.5927,\n",
            "         2.3802, 0.0000, 5.8963, 0.0000, 4.3324, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 7.8516, 0.0000, 7.1137]], grad_fn=<ReluBackward0>)\n",
            "x fc_pi output tensor([[ 54.4580, -34.9616,   4.3468, -36.9912]], grad_fn=<AddmmBackward0>)\n",
            "x F.softmax(x, dim=softmax_dim) tensor([[ 54.4580, -34.9616,   4.3468, -36.9912]], grad_fn=<AddmmBackward0>)\n",
            "prob tensor([[1.0000e+00, 1.4641e-39, 1.7257e-22, 1.9235e-40]],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "\n",
            "\n",
            "▶▶▶ 3812  : max cum reward :  1887  epsilon = 0.618790000000042\n",
            "\n",
            "\n",
            "▶▶▶3813번째 에피소드 시작, env 초기화 완료.\n",
            "가져와야 할 아이템 : ['D', 'K', 'N', 'O']\n",
            "\n",
            "현재 state         :  [9 4 2 0]\n",
            "step 데이터 : [10  4  2  0] -100 -100 True False\n",
            "put_data    : [9 4 2 0] 1 -100 [10  4  2  0] True\n",
            "input x tensor([[9., 4., 2., 0.]])\n",
            "x F.relu output tensor([[0.0000, 3.4749, 4.0198, 4.2076, 0.0000, 0.3368, 0.0000, 1.6710, 0.0000,\n",
            "         0.0000, 4.0518, 3.3581, 2.7620, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 4.0244, 0.0000, 0.0000, 3.6361, 5.8243, 2.9357, 4.8148, 3.3209,\n",
            "         5.2490, 0.0000, 3.7235, 0.0000, 3.2973, 1.3618, 3.1397, 4.2051, 2.6140,\n",
            "         4.1275, 2.7008, 4.9955, 0.0000, 0.0865, 3.7052, 0.0000, 0.0000, 4.3844,\n",
            "         1.5988, 0.0000, 3.7793, 0.0000, 0.0000, 2.0887, 0.0000, 4.8281, 4.5364,\n",
            "         0.0000, 0.0000, 3.3069, 0.3035, 3.8383, 0.0000, 5.6044, 0.0000, 2.9500,\n",
            "         2.5203, 2.5479, 0.0470, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 3.1301,\n",
            "         0.0000, 0.8022, 1.6407, 0.0000, 2.0793, 0.0000, 4.5753, 0.0000, 4.4779,\n",
            "         1.1773, 0.0000, 5.2867, 0.0000, 3.9770, 0.0000, 6.5112, 0.0000, 0.0000,\n",
            "         0.0000, 3.3050, 0.0000, 5.6809, 0.0000, 3.7834, 0.0000, 1.1922, 3.2802,\n",
            "         0.0674, 0.0000, 5.7516, 0.4630, 5.6578, 3.6857, 0.0000, 1.3490, 0.0000,\n",
            "         0.9846, 4.7648, 0.0000, 0.5121, 0.0000, 3.0877, 3.2837, 4.5207, 0.0000,\n",
            "         0.0000, 0.0000, 2.9836, 0.0000, 2.2351, 0.0000, 4.0541, 2.1682, 0.0000,\n",
            "         0.0000, 0.0000, 5.3059, 5.4879, 0.0000, 2.1478, 3.0303, 0.0000, 0.0000,\n",
            "         0.0000, 3.5405, 2.1901, 3.9466, 0.9189, 0.0000, 0.0000, 3.0630, 0.0000,\n",
            "         1.4952, 2.9710, 0.0000, 6.9014, 3.0520, 1.8313, 0.0000, 6.3676, 0.3917,\n",
            "         5.3634, 0.0000, 0.0000, 0.0000, 4.7027, 1.7259, 6.1705, 0.0000, 2.9444,\n",
            "         0.0000, 3.6198, 2.4188, 0.0000, 2.7235, 0.0000, 5.6694, 0.0000, 1.1616,\n",
            "         0.0000, 4.3909, 0.0000, 0.0000, 4.0654, 6.7240, 0.0000, 5.9962, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.5486, 0.0000, 3.2161,\n",
            "         0.0000, 0.0000, 2.1272, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 3.4140, 2.9401, 3.8889, 0.0000, 3.2368, 5.8723, 2.4989, 0.0000,\n",
            "         3.1731, 0.0000, 1.2256, 0.0000, 0.0000, 0.5661, 0.9438, 0.0000, 2.2537,\n",
            "         0.0000, 2.9261, 0.0000, 1.3197, 2.0971, 0.0000, 1.1335, 0.0000, 0.0000,\n",
            "         5.0006, 5.8542, 3.4601, 5.0283, 2.6976, 5.3060, 4.0908, 5.5607, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 5.1786, 0.0000, 7.6437, 2.2273, 0.0000, 2.3457,\n",
            "         1.8272, 0.0000, 4.1784, 0.0000, 3.1556, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 5.9982, 0.0000, 6.7726]], grad_fn=<ReluBackward0>)\n",
            "x fc_pi output tensor([[ 52.1478, -32.7504,   2.0523, -31.9843]], grad_fn=<AddmmBackward0>)\n",
            "x F.softmax(x, dim=softmax_dim) tensor([[ 52.1478, -32.7504,   2.0523, -31.9843]], grad_fn=<AddmmBackward0>)\n",
            "prob tensor([[1.0000e+00, 1.3465e-37, 1.7532e-22, 2.8969e-37]],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "\n",
            "\n",
            "▶▶▶ 3813  : max cum reward :  1887  epsilon = 0.618690000000042\n",
            "\n",
            "\n",
            "▶▶▶3814번째 에피소드 시작, env 초기화 완료.\n",
            "가져와야 할 아이템 : ['B', 'C', 'D', 'K', 'M', 'N', 'P']\n",
            "\n",
            "현재 state         :  [9 4 4 0]\n",
            "tensor([9, 4, 4, 0])\n",
            "tensor([9., 4., 4., 0.])\n",
            "end input\n",
            "input x tensor([9., 4., 4., 0.])\n",
            "x F.relu output tensor([0.0000e+00, 2.8381e+00, 3.4138e+00, 3.9572e+00, 6.9125e-03, 0.0000e+00,\n",
            "        0.0000e+00, 1.1388e+00, 0.0000e+00, 0.0000e+00, 4.1385e+00, 2.6984e+00,\n",
            "        2.8591e+00, 0.0000e+00, 4.2126e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 4.3631e+00, 0.0000e+00, 0.0000e+00, 4.0553e+00, 5.9963e+00,\n",
            "        3.8219e+00, 5.5681e+00, 2.5705e+00, 5.0368e+00, 0.0000e+00, 4.8484e+00,\n",
            "        0.0000e+00, 2.8206e+00, 1.5357e+00, 2.2564e+00, 4.0038e+00, 2.9830e+00,\n",
            "        3.3042e+00, 3.8173e+00, 5.2201e+00, 0.0000e+00, 7.4030e-01, 4.1421e+00,\n",
            "        0.0000e+00, 0.0000e+00, 4.8469e+00, 1.6444e+00, 0.0000e+00, 4.4865e+00,\n",
            "        0.0000e+00, 0.0000e+00, 1.3179e+00, 0.0000e+00, 5.8030e+00, 3.8475e+00,\n",
            "        0.0000e+00, 0.0000e+00, 3.9291e+00, 1.7270e-01, 4.5316e+00, 0.0000e+00,\n",
            "        5.6913e+00, 8.5422e-01, 3.8875e+00, 2.7742e+00, 2.2552e+00, 8.3824e-01,\n",
            "        0.0000e+00, 3.4796e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.6894e+00,\n",
            "        0.0000e+00, 2.8733e-01, 1.6229e+00, 0.0000e+00, 1.8903e+00, 0.0000e+00,\n",
            "        4.0986e+00, 7.0332e-02, 5.2918e+00, 2.1170e+00, 0.0000e+00, 5.5260e+00,\n",
            "        0.0000e+00, 4.8578e+00, 4.3858e-01, 6.7336e+00, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 2.9152e+00, 0.0000e+00, 5.4068e+00, 0.0000e+00, 4.6366e+00,\n",
            "        0.0000e+00, 9.3409e-01, 3.6103e+00, 0.0000e+00, 0.0000e+00, 5.2534e+00,\n",
            "        1.4926e-01, 5.8998e+00, 3.5194e+00, 0.0000e+00, 7.7644e-01, 0.0000e+00,\n",
            "        2.0063e+00, 5.1469e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.5492e+00,\n",
            "        4.1591e+00, 5.3493e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.9004e+00,\n",
            "        0.0000e+00, 3.0567e+00, 0.0000e+00, 5.0944e+00, 3.1527e+00, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 5.2683e+00, 4.9494e+00, 0.0000e+00, 2.3581e+00,\n",
            "        2.9717e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.4351e+00, 2.1479e+00,\n",
            "        3.7594e+00, 1.3220e+00, 0.0000e+00, 0.0000e+00, 3.6316e+00, 0.0000e+00,\n",
            "        1.3064e+00, 2.8217e+00, 0.0000e+00, 7.1777e+00, 3.6443e+00, 1.6291e+00,\n",
            "        0.0000e+00, 7.5115e+00, 0.0000e+00, 5.3528e+00, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 4.9236e+00, 1.9584e+00, 5.4170e+00, 0.0000e+00, 2.6820e+00,\n",
            "        0.0000e+00, 4.2028e+00, 2.9637e+00, 0.0000e+00, 3.4522e+00, 0.0000e+00,\n",
            "        5.0566e+00, 0.0000e+00, 4.4344e-01, 0.0000e+00, 4.7902e+00, 0.0000e+00,\n",
            "        0.0000e+00, 3.9523e+00, 7.0050e+00, 0.0000e+00, 6.4857e+00, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        2.1508e+00, 0.0000e+00, 2.8596e+00, 0.0000e+00, 0.0000e+00, 1.4643e+00,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 2.8580e+00, 3.7074e+00, 3.4772e+00, 0.0000e+00, 3.2397e+00,\n",
            "        5.7089e+00, 3.5498e+00, 0.0000e+00, 4.2200e+00, 0.0000e+00, 2.2487e+00,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 1.1927e+00, 0.0000e+00, 2.8070e+00,\n",
            "        0.0000e+00, 3.2878e+00, 0.0000e+00, 7.1452e-01, 1.2306e+00, 0.0000e+00,\n",
            "        1.9801e+00, 0.0000e+00, 0.0000e+00, 5.5011e+00, 6.9745e+00, 3.3202e+00,\n",
            "        5.2543e+00, 2.5417e+00, 4.6243e+00, 4.8253e+00, 5.6841e+00, 0.0000e+00,\n",
            "        7.2049e-01, 9.5578e-01, 0.0000e+00, 5.7258e+00, 0.0000e+00, 8.7567e+00,\n",
            "        2.3040e+00, 0.0000e+00, 1.8438e+00, 2.1963e+00, 0.0000e+00, 5.3240e+00,\n",
            "        0.0000e+00, 3.9398e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 7.2338e+00, 0.0000e+00, 7.0000e+00],\n",
            "       grad_fn=<ReluBackward0>)\n",
            "x fc_pi output tensor([ 53.6885, -34.1663,   3.5609, -35.3236], grad_fn=<AddBackward0>)\n",
            "x F.softmax(x, dim=softmax_dim) tensor([ 53.6885, -34.1663,   3.5609, -35.3236], grad_fn=<AddBackward0>)\n",
            "prob tensor([1.0000e+00, 7.0010e-39, 1.6976e-22, 2.2004e-39],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "step 데이터 : [8 4 4 0] -1 -1 False False\n",
            "put_data    : [9 4 4 0] 0 -1 [8 4 4 0] False\n",
            "tensor([8, 4, 4, 0])\n",
            "tensor([8., 4., 4., 0.])\n",
            "end input\n",
            "input x tensor([8., 4., 4., 0.])\n",
            "x F.relu output tensor([0.0000, 2.4779, 3.0728, 3.3288, 0.3212, 0.0000, 0.0000, 1.0107, 0.0000,\n",
            "        0.0000, 3.5811, 2.3505, 2.7549, 0.0000, 0.6623, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 4.1259, 0.0000, 0.0000, 3.7925, 5.3650, 3.6203, 5.2513, 2.0204,\n",
            "        4.4957, 0.0000, 4.5023, 0.0000, 2.5507, 1.4521, 1.9732, 3.8317, 2.8973,\n",
            "        2.7174, 3.5343, 4.7675, 0.0000, 0.9056, 3.7472, 0.0000, 0.0000, 4.5795,\n",
            "        1.5803, 0.0000, 4.1460, 0.0000, 0.0000, 1.1956, 0.0000, 5.4694, 3.3924,\n",
            "        0.0000, 0.0000, 3.6576, 0.1223, 4.3590, 0.0000, 5.3140, 1.1561, 3.5428,\n",
            "        2.6550, 1.8778, 0.8615, 0.0000, 0.5589, 0.0000, 0.0000, 0.0000, 2.3228,\n",
            "        0.0000, 0.0000, 1.5261, 0.0000, 1.8858, 0.0000, 3.6133, 0.0536, 5.0996,\n",
            "        2.1888, 0.0000, 4.9955, 0.0000, 4.4658, 0.6084, 6.2447, 0.0000, 0.0000,\n",
            "        0.0000, 2.4787, 0.0000, 4.9741, 0.0000, 4.1961, 0.0000, 0.7146, 3.2336,\n",
            "        0.0000, 0.0000, 4.7212, 0.1317, 5.4656, 3.3260, 0.0000, 0.6628, 0.0000,\n",
            "        2.1147, 4.9177, 0.0000, 0.0000, 0.0000, 2.3350, 4.1554, 5.1824, 0.0000,\n",
            "        0.0000, 0.0000, 2.8386, 0.0000, 3.0948, 0.0000, 4.9621, 3.1041, 0.0000,\n",
            "        0.0000, 0.0000, 4.9119, 4.5279, 0.0000, 2.2477, 2.7493, 0.0000, 0.0000,\n",
            "        0.0000, 3.0519, 1.8157, 3.4690, 1.1155, 0.0000, 0.0000, 3.5402, 0.0000,\n",
            "        1.3054, 2.4552, 0.0000, 6.6801, 3.4824, 1.3310, 0.0000, 7.1843, 0.0000,\n",
            "        4.7912, 0.0000, 0.0000, 0.0000, 4.5815, 1.9645, 4.8392, 0.0000, 2.2657,\n",
            "        0.0000, 3.8475, 3.0736, 0.0000, 3.3743, 0.0000, 4.6573, 0.0000, 0.3108,\n",
            "        0.0000, 4.5731, 0.0000, 0.0000, 3.6485, 6.5440, 0.0000, 5.9639, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 2.0258, 0.0000, 2.6349,\n",
            "        0.0000, 0.0000, 1.0120, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 2.4601, 3.3644, 3.1909, 0.0000, 3.0182, 5.2641, 3.5382, 0.0000,\n",
            "        3.9724, 0.0000, 2.2601, 0.0000, 0.0000, 0.0000, 1.2955, 0.0000, 2.7143,\n",
            "        0.0000, 3.2186, 0.0000, 0.7293, 1.1050, 0.0000, 1.9848, 0.0000, 0.0000,\n",
            "        4.9450, 6.5413, 3.0241, 4.6894, 2.1620, 4.1826, 4.4253, 5.2930, 0.0000,\n",
            "        0.8010, 1.1166, 0.0000, 5.4485, 0.0000, 8.2212, 2.1380, 0.0000, 1.5206,\n",
            "        1.9838, 0.0000, 5.1829, 0.0000, 3.5203, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 7.0178, 0.0000, 6.5149], grad_fn=<ReluBackward0>)\n",
            "x fc_pi output tensor([ 49.4917, -31.6287,   3.7053, -33.0731], grad_fn=<AddBackward0>)\n",
            "x F.softmax(x, dim=softmax_dim) tensor([ 49.4917, -31.6287,   3.7053, -33.0731], grad_fn=<AddBackward0>)\n",
            "prob tensor([1.0000e+00, 5.8865e-36, 1.3039e-20, 1.3886e-36],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "step 데이터 : [7 4 4 0] -1 -2 False False\n",
            "put_data    : [8 4 4 0] 0 -1 [7 4 4 0] False\n",
            "step 데이터 : [7 5 4 0] -1 -3 False False\n",
            "put_data    : [7 4 4 0] 3 -1 [7 5 4 0] False\n",
            "step 데이터 : [6 5 4 0] -1 -4 False False\n",
            "put_data    : [7 5 4 0] 0 -1 [6 5 4 0] False\n",
            "tensor([6, 5, 4, 0])\n",
            "tensor([6., 5., 4., 0.])\n",
            "end input\n",
            "input x tensor([6., 5., 4., 0.])\n",
            "x F.relu output tensor([0.0000, 2.0654, 2.8577, 1.7396, 1.4093, 0.0000, 0.0000, 0.9503, 0.0000,\n",
            "        0.0000, 2.2027, 1.9571, 3.0640, 0.0000, 1.2512, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 4.1049, 0.0000, 0.0000, 3.3815, 4.1013, 3.3657, 4.7775, 0.5623,\n",
            "        3.5608, 0.0000, 3.5837, 0.0000, 2.4348, 1.3567, 1.6614, 4.0552, 2.9587,\n",
            "        1.4994, 2.7931, 4.0661, 0.0000, 1.5218, 2.8461, 0.0000, 0.0000, 4.5340,\n",
            "        1.6059, 0.0000, 3.5588, 0.0000, 0.0000, 1.3014, 0.0000, 5.0736, 2.8180,\n",
            "        0.0000, 0.0000, 3.1885, 0.0000, 4.4599, 0.0000, 5.0378, 1.9995, 2.6238,\n",
            "        2.6616, 0.9813, 0.7024, 0.0000, 1.1983, 0.0000, 0.0000, 0.0000, 1.7358,\n",
            "        0.0000, 0.0000, 1.4790, 0.0000, 2.4671, 0.0000, 2.8493, 0.0000, 5.1167,\n",
            "        2.5510, 0.0000, 4.0108, 0.0811, 3.6280, 1.2057, 5.7495, 0.0000, 0.0000,\n",
            "        0.0000, 1.6251, 0.0000, 4.5885, 0.0000, 3.1476, 0.0000, 0.0095, 2.3066,\n",
            "        0.0000, 0.0000, 4.0454, 0.2492, 4.8728, 3.4749, 0.0000, 0.6939, 0.0000,\n",
            "        2.6417, 4.9366, 0.0000, 0.0000, 0.0000, 2.2470, 4.6462, 5.3092, 0.0000,\n",
            "        0.0000, 0.0000, 3.1926, 0.0000, 3.4687, 0.0000, 5.0181, 3.0502, 0.0000,\n",
            "        0.0000, 0.7648, 4.5991, 4.2460, 0.0000, 2.3214, 2.4882, 0.0000, 0.0000,\n",
            "        0.0000, 2.2451, 1.0146, 3.3382, 0.2520, 0.0000, 0.0000, 3.7482, 0.3559,\n",
            "        1.5945, 1.5875, 0.0000, 6.1520, 3.4565, 0.6114, 0.0000, 6.9891, 0.7767,\n",
            "        3.6591, 0.0000, 0.0000, 0.0000, 4.3234, 2.3686, 4.1545, 0.0000, 1.2722,\n",
            "        0.0000, 3.1170, 3.8618, 0.0853, 3.6198, 0.5372, 4.4175, 0.0000, 0.2114,\n",
            "        0.0000, 4.6666, 0.0000, 0.0000, 3.4883, 6.0565, 0.0000, 5.1026, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.8135, 0.0000, 2.4932,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 1.6704, 2.5343, 3.0915, 0.0000, 2.9503, 4.8500, 3.8474, 0.0000,\n",
            "        3.3066, 0.0000, 2.2597, 0.0000, 0.0000, 0.0094, 1.8076, 0.0000, 2.7664,\n",
            "        0.0000, 3.4659, 0.0000, 1.2533, 1.1768, 0.0000, 1.9585, 0.0000, 0.0000,\n",
            "        3.6853, 5.9773, 2.6962, 3.4261, 1.2360, 3.8178, 3.5813, 5.0215, 0.0000,\n",
            "        0.7840, 1.5980, 0.0000, 5.2812, 0.0000, 7.4676, 1.9428, 0.0000, 0.7765,\n",
            "        1.4291, 0.0000, 5.3491, 0.0000, 2.4027, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 7.1428, 0.0000, 6.0670], grad_fn=<ReluBackward0>)\n",
            "x fc_pi output tensor([ 44.1029, -28.5636,   4.3851, -30.3819], grad_fn=<AddBackward0>)\n",
            "x F.softmax(x, dim=softmax_dim) tensor([ 44.1029, -28.5636,   4.3851, -30.3819], grad_fn=<AddBackward0>)\n",
            "prob tensor([1.0000e+00, 2.7625e-32, 5.6335e-18, 4.4836e-33],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "step 데이터 : [5 5 4 0] -1 -5 False False\n",
            "put_data    : [6 5 4 0] 0 -1 [5 5 4 0] False\n",
            "step 데이터 : [4 5 4 0] -1 -6 False False\n",
            "put_data    : [5 5 4 0] 0 -1 [4 5 4 0] False\n",
            "tensor([4, 5, 4, 0])\n",
            "tensor([4., 5., 4., 0.])\n",
            "end input\n",
            "input x tensor([4., 5., 4., 0.])\n",
            "x F.relu output tensor([0.0000, 1.3451, 2.1758, 0.4829, 2.0378, 0.0000, 0.0000, 0.6941, 0.0902,\n",
            "        0.0000, 1.0880, 1.2614, 2.8555, 0.0000, 1.7333, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 3.6305, 0.0000, 0.0000, 2.8559, 2.8387, 2.9623, 4.1439, 0.0000,\n",
            "        2.4786, 0.0000, 2.8915, 0.0000, 1.8950, 1.1895, 1.0951, 3.7111, 2.7874,\n",
            "        0.3259, 2.2271, 3.1609, 0.0000, 1.8523, 2.0562, 0.0000, 0.0000, 3.9992,\n",
            "        1.4777, 0.0000, 2.8779, 0.0000, 0.0000, 1.0567, 0.0000, 4.4064, 1.9080,\n",
            "        0.0000, 0.2458, 2.6454, 0.0000, 4.1147, 0.0000, 4.2831, 2.6032, 1.9345,\n",
            "        2.4230, 0.2265, 0.7489, 0.0000, 1.6201, 0.0000, 0.0000, 0.3580, 1.0026,\n",
            "        0.0000, 0.0000, 1.2854, 0.2135, 2.4582, 0.0000, 1.8789, 0.0000, 4.7325,\n",
            "        2.6947, 0.0000, 2.9497, 1.0469, 2.8440, 1.5454, 4.7717, 0.0000, 0.0000,\n",
            "        0.0000, 0.7521, 0.0000, 3.7232, 0.0000, 2.2665, 0.0000, 0.0000, 1.5532,\n",
            "        0.0000, 0.0000, 2.9811, 0.2142, 4.0043, 3.0881, 0.0068, 0.4666, 0.0000,\n",
            "        2.8586, 4.4783, 0.0000, 0.0000, 0.0000, 1.8186, 4.6389, 4.9755, 0.0000,\n",
            "        0.0000, 0.0000, 3.0691, 0.0000, 3.5449, 0.0000, 4.7537, 2.9529, 0.0000,\n",
            "        0.0000, 1.4002, 3.8863, 3.4031, 0.0000, 2.1006, 2.0435, 0.0000, 0.0000,\n",
            "        0.0000, 1.4788, 0.3503, 2.7574, 0.0000, 0.0000, 0.0000, 3.5655, 0.7971,\n",
            "        1.5925, 0.8545, 0.0000, 5.1567, 3.1327, 0.0153, 0.0000, 6.3347, 1.0665,\n",
            "        2.5358, 0.0000, 0.0000, 0.5199, 3.6391, 2.3809, 2.9990, 0.0000, 0.4396,\n",
            "        0.0000, 2.4064, 4.0818, 0.4801, 3.4639, 1.1672, 3.6189, 0.0000, 0.0000,\n",
            "        0.0000, 4.2324, 0.0000, 0.0000, 2.8805, 5.1345, 0.0000, 4.0589, 0.0000,\n",
            "        0.0000, 0.2685, 0.6169, 0.0000, 0.0000, 0.0000, 1.5635, 0.0000, 2.0438,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.8745, 1.8482, 2.5189, 0.0000, 2.5075, 3.9602, 3.8242, 0.0000,\n",
            "        2.8114, 0.0000, 2.2826, 0.0000, 0.0000, 0.0314, 2.0133, 0.0000, 2.5809,\n",
            "        0.0000, 3.3275, 0.3125, 1.2830, 0.9256, 0.0000, 1.9679, 0.0000, 0.0000,\n",
            "        2.5731, 5.1110, 2.1040, 2.2964, 0.4765, 2.9345, 2.7813, 4.2395, 0.0000,\n",
            "        0.9449, 1.9196, 0.0000, 4.7266, 0.0000, 6.3967, 1.6107, 0.0000, 0.1301,\n",
            "        1.0041, 0.0000, 5.0669, 0.0000, 1.5637, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 6.7108, 0.0000, 5.0970], grad_fn=<ReluBackward0>)\n",
            "x fc_pi output tensor([ 35.9102, -23.7406,   4.7988, -26.0195], grad_fn=<AddBackward0>)\n",
            "x F.softmax(x, dim=softmax_dim) tensor([ 35.9102, -23.7406,   4.7988, -26.0195], grad_fn=<AddBackward0>)\n",
            "prob tensor([1.0000e+00, 1.2416e-26, 3.0795e-14, 1.2714e-27],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "step 데이터 : [3 5 4 0] -1 -7 False False\n",
            "put_data    : [4 5 4 0] 0 -1 [3 5 4 0] False\n",
            "step 데이터 : [2 5 4 0] -1 -8 False False\n",
            "put_data    : [3 5 4 0] 0 -1 [2 5 4 0] False\n",
            "step 데이터 : [2 6 4 0] -1 -9 False False\n",
            "put_data    : [2 5 4 0] 3 -1 [2 6 4 0] False\n",
            "tensor([2, 6, 4, 0])\n",
            "tensor([2., 6., 4., 0.])\n",
            "end input\n",
            "input x tensor([2., 6., 4., 0.])\n",
            "x F.relu output tensor([0.0000, 0.9325, 1.9607, 0.0000, 3.1259, 0.0000, 0.0000, 0.6337, 1.0178,\n",
            "        0.2588, 0.0000, 0.8680, 3.1646, 0.0000, 2.3223, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 3.6094, 0.0000, 0.0000, 2.4448, 1.5749, 2.7077, 3.6701, 0.0000,\n",
            "        1.5437, 0.0000, 1.9728, 0.0000, 1.7792, 1.0941, 0.7833, 3.9346, 2.8487,\n",
            "        0.0000, 1.4859, 2.4595, 0.0000, 2.4685, 1.1551, 0.0000, 0.0000, 3.9537,\n",
            "        1.5033, 0.7989, 2.2907, 0.0000, 0.0000, 1.1625, 0.3835, 4.0105, 1.3336,\n",
            "        0.0000, 0.9734, 2.1763, 0.0000, 4.2156, 0.0000, 4.0070, 3.4466, 1.0155,\n",
            "        2.4297, 0.0000, 0.5898, 0.4716, 2.2596, 0.0000, 0.9284, 1.1430, 0.4155,\n",
            "        0.0000, 0.0000, 1.2382, 1.6231, 3.0395, 0.0000, 1.1148, 0.0000, 4.7496,\n",
            "        3.0569, 0.0000, 1.9650, 2.2914, 2.0063, 2.1427, 4.2765, 0.0000, 1.0435,\n",
            "        0.0000, 0.0000, 0.0000, 3.3376, 0.0000, 1.2181, 0.0000, 0.0000, 0.6263,\n",
            "        0.0000, 0.1923, 2.3053, 0.3316, 3.4115, 3.2369, 1.2683, 0.4977, 0.0000,\n",
            "        3.3855, 4.4972, 0.0000, 0.0000, 0.0000, 1.7307, 5.1296, 5.1023, 0.0000,\n",
            "        0.0000, 1.0877, 3.4231, 0.0000, 3.9188, 0.3899, 4.8096, 2.8990, 0.0000,\n",
            "        0.0000, 2.2852, 3.5736, 3.1212, 0.0000, 2.1743, 1.7823, 0.0000, 0.0000,\n",
            "        0.0000, 0.6720, 0.0000, 2.6265, 0.0000, 0.0364, 0.0000, 3.7735, 1.6448,\n",
            "        1.8816, 0.0000, 0.0000, 4.6286, 3.1068, 0.0000, 0.0294, 6.1395, 1.8786,\n",
            "        1.4036, 0.0000, 0.2940, 1.8564, 3.3810, 2.7850, 2.3143, 0.0000, 0.0000,\n",
            "        0.0000, 1.6759, 4.8699, 0.7963, 3.7095, 2.2034, 3.3791, 0.7265, 0.0000,\n",
            "        0.0000, 4.3259, 0.0000, 0.0000, 2.7203, 4.6471, 0.0000, 3.1977, 0.0000,\n",
            "        0.3846, 1.4063, 2.0306, 0.0000, 0.0000, 0.0000, 1.3512, 0.0000, 1.9021,\n",
            "        0.0000, 0.2763, 0.0000, 0.0000, 0.8704, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0848, 1.0182, 2.4195, 0.0000, 2.4396, 3.5462, 4.1334, 0.0000,\n",
            "        2.1456, 0.0000, 2.2822, 0.0000, 0.0000, 0.4889, 2.5254, 0.0000, 2.6330,\n",
            "        0.0000, 3.5747, 0.5922, 1.8070, 0.9975, 0.0000, 1.9416, 0.2466, 0.4873,\n",
            "        1.3134, 4.5470, 1.7762, 1.0331, 0.0000, 2.5697, 1.9374, 3.9679, 0.0000,\n",
            "        0.9280, 2.4010, 0.0000, 4.5593, 1.2499, 5.6430, 1.4155, 0.0000, 0.0000,\n",
            "        0.4493, 0.0000, 5.2331, 0.0000, 0.4460, 0.0000, 0.2002, 0.0000, 0.6623,\n",
            "        0.0000, 6.8358, 0.0000, 4.6491], grad_fn=<ReluBackward0>)\n",
            "x fc_pi output tensor([ 31.0868, -21.1469,   6.3436, -24.2190], grad_fn=<AddBackward0>)\n",
            "x F.softmax(x, dim=softmax_dim) tensor([ 31.0868, -21.1469,   6.3436, -24.2190], grad_fn=<AddBackward0>)\n",
            "prob tensor([1.0000e+00, 2.0663e-23, 1.7955e-11, 9.5718e-25],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "step 데이터 : [1 6 4 0] -1 -10 False False\n",
            "put_data    : [2 6 4 0] 0 -1 [1 6 4 0] False\n",
            "input x tensor([[9., 4., 4., 0.],\n",
            "        [8., 4., 4., 0.],\n",
            "        [7., 4., 4., 0.],\n",
            "        [7., 5., 4., 0.],\n",
            "        [6., 5., 4., 0.],\n",
            "        [5., 5., 4., 0.],\n",
            "        [4., 5., 4., 0.],\n",
            "        [3., 5., 4., 0.],\n",
            "        [2., 5., 4., 0.],\n",
            "        [2., 6., 4., 0.]])\n",
            "x F.relu output tensor([[0.0000, 2.8381, 3.4138,  ..., 7.2338, 0.0000, 7.0000],\n",
            "        [0.0000, 2.4779, 3.0728,  ..., 7.0178, 0.0000, 6.5149],\n",
            "        [0.0000, 2.1178, 2.7318,  ..., 6.8019, 0.0000, 6.0299],\n",
            "        ...,\n",
            "        [0.0000, 0.9849, 1.8348,  ..., 6.4949, 0.0000, 4.6119],\n",
            "        [0.0000, 0.6247, 1.4938,  ..., 6.2789, 0.0000, 4.1269],\n",
            "        [0.0000, 0.9325, 1.9607,  ..., 6.8358, 0.0000, 4.6491]],\n",
            "       grad_fn=<ReluBackward0>)\n",
            "x fc_pi output tensor([[ 53.6885, -34.1663,   3.5609, -35.3237],\n",
            "        [ 49.4917, -31.6287,   3.7053, -33.0731],\n",
            "        [ 45.3192, -29.1152,   3.8445, -30.8153],\n",
            "        [ 48.2296, -31.0170,   4.2396, -32.6196],\n",
            "        [ 44.1029, -28.5636,   4.3851, -30.3819],\n",
            "        [ 40.0149, -26.1386,   4.5585, -28.1670],\n",
            "        [ 35.9102, -23.7406,   4.7988, -26.0195],\n",
            "        [ 31.8901, -21.3587,   5.1897, -23.9981],\n",
            "        [ 28.1251, -19.0728,   5.6010, -22.2103],\n",
            "        [ 31.0868, -21.1469,   6.3436, -24.2190]], grad_fn=<AddmmBackward0>)\n",
            "x F.softmax(x, dim=softmax_dim) tensor([[ 53.6885, -34.1663,   3.5609, -35.3237],\n",
            "        [ 49.4917, -31.6287,   3.7053, -33.0731],\n",
            "        [ 45.3192, -29.1152,   3.8445, -30.8153],\n",
            "        [ 48.2296, -31.0170,   4.2396, -32.6196],\n",
            "        [ 44.1029, -28.5636,   4.3851, -30.3819],\n",
            "        [ 40.0149, -26.1386,   4.5585, -28.1670],\n",
            "        [ 35.9102, -23.7406,   4.7988, -26.0195],\n",
            "        [ 31.8901, -21.3587,   5.1897, -23.9981],\n",
            "        [ 28.1251, -19.0728,   5.6010, -22.2103],\n",
            "        [ 31.0868, -21.1469,   6.3436, -24.2190]], grad_fn=<AddmmBackward0>)\n",
            "prob tensor([[1.0000e+00, 7.0010e-39, 1.6977e-22, 2.2004e-39],\n",
            "        [1.0000e+00, 5.8865e-36, 1.3039e-20, 1.3886e-36],\n",
            "        [1.0000e+00, 4.7156e-33, 9.7218e-19, 8.6138e-34],\n",
            "        [1.0000e+00, 3.8337e-35, 7.8589e-20, 7.7203e-36],\n",
            "        [1.0000e+00, 2.7625e-32, 5.6335e-18, 4.4836e-33],\n",
            "        [1.0000e+00, 1.8617e-29, 3.9947e-16, 2.4489e-30],\n",
            "        [1.0000e+00, 1.2416e-26, 3.0795e-14, 1.2714e-27],\n",
            "        [1.0000e+00, 7.4874e-24, 2.5360e-12, 5.3463e-25],\n",
            "        [1.0000e+00, 3.1783e-21, 1.6516e-10, 1.3791e-22],\n",
            "        [1.0000e+00, 2.0663e-23, 1.7955e-11, 9.5718e-25]],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "\n",
            "\n",
            "▶▶▶ 3814  : max cum reward :  1887  epsilon = 0.618590000000042\n",
            "step 데이터 : [2 6 4 0] -1 -11 False False\n",
            "put_data    : [1 6 4 0] 1 -1 [2 6 4 0] False\n",
            "step 데이터 : [1 6 4 0] -1 -12 False False\n",
            "put_data    : [2 6 4 0] 0 -1 [1 6 4 0] False\n",
            "step 데이터 : [0 6 4 0] -1 -13 False False\n",
            "put_data    : [1 6 4 0] 0 -1 [0 6 4 0] False\n",
            "tensor([0, 6, 4, 0])\n",
            "tensor([0., 6., 4., 0.])\n",
            "end input\n",
            "input x tensor([0., 6., 4., 0.])\n",
            "x F.relu output tensor([0.0000e+00, 2.1224e-01, 1.2788e+00, 0.0000e+00, 3.7545e+00, 0.0000e+00,\n",
            "        5.8988e-01, 3.7747e-01, 1.6447e+00, 1.1801e+00, 0.0000e+00, 1.7219e-01,\n",
            "        2.9563e+00, 0.0000e+00, 2.8044e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 3.1351e+00, 0.0000e+00, 0.0000e+00, 1.9197e+00, 3.1244e-01,\n",
            "        2.3045e+00, 3.0366e+00, 0.0000e+00, 4.6167e-01, 0.0000e+00, 1.2811e+00,\n",
            "        0.0000e+00, 1.2393e+00, 9.2663e-01, 2.1690e-01, 3.5904e+00, 2.6775e+00,\n",
            "        0.0000e+00, 9.2027e-01, 1.5546e+00, 0.0000e+00, 2.7994e+00, 3.6553e-01,\n",
            "        6.0016e-01, 0.0000e+00, 3.4191e+00, 1.3753e+00, 1.3973e+00, 1.6097e+00,\n",
            "        3.9139e-01, 0.0000e+00, 9.1763e-01, 9.7672e-01, 3.3435e+00, 4.2369e-01,\n",
            "        0.0000e+00, 1.4243e+00, 1.6333e+00, 0.0000e+00, 3.8705e+00, 0.0000e+00,\n",
            "        3.2522e+00, 4.0506e+00, 3.2649e-01, 2.1913e+00, 0.0000e+00, 6.3637e-01,\n",
            "        1.2926e+00, 2.6814e+00, 0.0000e+00, 1.8585e+00, 1.8285e+00, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 1.0444e+00, 2.6290e+00, 3.0306e+00, 0.0000e+00,\n",
            "        1.4427e-01, 0.0000e+00, 4.3656e+00, 3.2010e+00, 0.0000e+00, 9.0376e-01,\n",
            "        3.2570e+00, 1.2228e+00, 2.4829e+00, 3.2989e+00, 0.0000e+00, 1.8105e+00,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 2.4722e+00, 0.0000e+00, 3.3696e-01,\n",
            "        1.3197e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.5120e-01, 1.2411e+00,\n",
            "        2.9649e-01, 2.5432e+00, 2.8502e+00, 2.0810e+00, 2.7047e-01, 3.5488e-03,\n",
            "        3.6027e+00, 4.0392e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.3022e+00,\n",
            "        5.1225e+00, 4.7686e+00, 0.0000e+00, 0.0000e+00, 1.9005e+00, 3.2996e+00,\n",
            "        0.0000e+00, 3.9951e+00, 1.3239e+00, 4.5456e+00, 2.8018e+00, 0.0000e+00,\n",
            "        0.0000e+00, 2.9212e+00, 2.8608e+00, 2.2785e+00, 2.4063e-02, 1.9535e+00,\n",
            "        1.3378e+00, 0.0000e+00, 6.0758e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        2.0459e+00, 0.0000e+00, 5.3548e-01, 0.0000e+00, 3.5910e+00, 2.0863e+00,\n",
            "        1.8797e+00, 0.0000e+00, 4.7337e-01, 3.6334e+00, 2.7831e+00, 0.0000e+00,\n",
            "        1.0266e+00, 5.4855e+00, 2.1686e+00, 2.8027e-01, 0.0000e+00, 1.1573e+00,\n",
            "        2.8408e+00, 2.6968e+00, 2.7974e+00, 1.1589e+00, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 9.6546e-01, 5.0899e+00, 1.1916e+00, 3.5536e+00, 2.8333e+00,\n",
            "        2.5807e+00, 1.6577e+00, 0.0000e+00, 0.0000e+00, 3.8916e+00, 0.0000e+00,\n",
            "        0.0000e+00, 2.1125e+00, 3.7251e+00, 0.0000e+00, 2.1540e+00, 0.0000e+00,\n",
            "        9.8769e-01, 2.2621e+00, 2.9399e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        1.1017e+00, 0.0000e+00, 1.4526e+00, 0.0000e+00, 6.9532e-01, 0.0000e+00,\n",
            "        0.0000e+00, 1.8496e+00, 0.0000e+00, 2.0607e-01, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 3.3232e-01, 1.8470e+00, 0.0000e+00, 1.9968e+00,\n",
            "        2.6563e+00, 4.1106e+00, 0.0000e+00, 1.6505e+00, 0.0000e+00, 2.3052e+00,\n",
            "        0.0000e+00, 3.4714e-01, 5.1079e-01, 2.7314e+00, 0.0000e+00, 2.4479e+00,\n",
            "        0.0000e+00, 3.4363e+00, 9.0942e-01, 1.8367e+00, 7.4628e-01, 0.0000e+00,\n",
            "        1.9514e+00, 6.3024e-01, 9.6542e-01, 2.0123e-01, 3.6807e+00, 1.1840e+00,\n",
            "        0.0000e+00, 0.0000e+00, 1.6868e+00, 1.1376e+00, 3.1861e+00, 0.0000e+00,\n",
            "        1.0891e+00, 2.7226e+00, 0.0000e+00, 4.0047e+00, 2.1551e+00, 4.5725e+00,\n",
            "        1.0836e+00, 0.0000e+00, 0.0000e+00, 2.4567e-02, 0.0000e+00, 4.9512e+00,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0412e+00, 0.0000e+00, 1.2642e+00,\n",
            "        0.0000e+00, 6.4040e+00, 3.7243e-01, 3.6791e+00],\n",
            "       grad_fn=<ReluBackward0>)\n",
            "x fc_pi output tensor([ 23.8273, -16.9138,   7.4716, -20.8895], grad_fn=<AddBackward0>)\n",
            "x F.softmax(x, dim=softmax_dim) tensor([ 23.8273, -16.9138,   7.4716, -20.8895], grad_fn=<AddBackward0>)\n",
            "prob tensor([1.0000e+00, 2.0248e-18, 7.8852e-08, 3.7995e-20],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "step 데이터 : [-1  6  4  0] -100 -113 True False\n",
            "put_data    : [0 6 4 0] 0 -100 [-1  6  4  0] True\n",
            "input x tensor([[1., 6., 4., 0.],\n",
            "        [2., 6., 4., 0.],\n",
            "        [1., 6., 4., 0.],\n",
            "        [0., 6., 4., 0.]])\n",
            "x F.relu output tensor([[0.0000, 0.5724, 1.6198,  ..., 6.6200, 0.1269, 4.1642],\n",
            "        [0.0000, 0.9326, 1.9608,  ..., 6.8360, 0.0000, 4.6492],\n",
            "        [0.0000, 0.5724, 1.6198,  ..., 6.6200, 0.1269, 4.1642],\n",
            "        [0.0000, 0.2122, 1.2788,  ..., 6.4040, 0.3724, 3.6791]],\n",
            "       grad_fn=<ReluBackward0>)\n",
            "x fc_pi output tensor([[ 27.4248, -18.9630,   6.8924, -22.5421],\n",
            "        [ 31.0905, -21.1352,   6.3458, -24.2365],\n",
            "        [ 27.4248, -18.9630,   6.8924, -22.5421],\n",
            "        [ 23.8273, -16.9138,   7.4716, -20.8895]], grad_fn=<AddmmBackward0>)\n",
            "x F.softmax(x, dim=softmax_dim) tensor([[ 27.4248, -18.9630,   6.8924, -22.5421],\n",
            "        [ 31.0905, -21.1352,   6.3458, -24.2365],\n",
            "        [ 27.4248, -18.9630,   6.8924, -22.5421],\n",
            "        [ 23.8273, -16.9138,   7.4716, -20.8895]], grad_fn=<AddmmBackward0>)\n",
            "prob tensor([[1.0000e+00, 7.1456e-21, 1.2103e-09, 1.9937e-22],\n",
            "        [1.0000e+00, 2.0829e-23, 1.7926e-11, 9.3709e-25],\n",
            "        [1.0000e+00, 7.1456e-21, 1.2103e-09, 1.9937e-22],\n",
            "        [1.0000e+00, 2.0248e-18, 7.8851e-08, 3.7995e-20]],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "\n",
            "\n",
            "▶▶▶ 3814  : max cum reward :  1887  epsilon = 0.618590000000042\n",
            "\n",
            "\n",
            "▶▶▶3815번째 에피소드 시작, env 초기화 완료.\n",
            "가져와야 할 아이템 : ['A', 'B', 'H', 'I', 'L']\n",
            "\n",
            "현재 state         :  [9 4 5 0]\n",
            "tensor([9, 4, 5, 0])\n",
            "tensor([9., 4., 5., 0.])\n",
            "end input\n",
            "input x tensor([9., 4., 5., 0.])\n",
            "x F.relu output tensor([0.0000, 2.5195, 3.1106, 3.8321, 0.3758, 0.0000, 0.0000, 0.8726, 0.0000,\n",
            "        0.0000, 4.1818, 2.3682, 2.9080, 0.0000, 0.9129, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 4.5317, 0.0000, 0.0000, 4.2659, 6.0824, 4.2651, 5.9445, 2.1949,\n",
            "        4.9307, 0.0000, 5.4123, 0.0000, 2.5822, 1.6215, 1.8142, 3.9027, 3.1673,\n",
            "        2.8924, 4.3760, 5.3328, 0.0000, 1.0685, 4.3609, 0.0000, 0.0000, 5.0786,\n",
            "        1.6671, 0.0000, 4.8397, 0.0000, 0.0000, 0.9316, 0.0000, 6.2903, 3.5034,\n",
            "        0.0000, 0.0000, 4.2403, 0.1072, 4.8783, 0.0000, 5.7344, 1.3825, 4.3567,\n",
            "        2.9013, 2.1087, 1.2333, 0.0000, 0.7863, 0.0000, 0.0000, 0.0000, 2.4690,\n",
            "        0.0000, 0.0296, 1.6131, 0.0000, 1.7952, 0.0000, 3.8596, 0.2499, 5.6991,\n",
            "        2.5883, 0.0000, 5.6450, 0.0000, 5.2994, 0.7113, 6.8449, 0.0000, 0.0000,\n",
            "        0.0000, 2.7207, 0.0000, 5.2696, 0.0000, 5.0626, 0.0000, 0.8049, 3.7758,\n",
            "        0.0000, 0.0000, 5.0043, 0.0000, 6.0212, 3.4361, 0.0000, 0.4899, 0.0000,\n",
            "        2.5173, 5.3385, 0.0000, 0.0000, 0.0000, 2.2797, 4.5969, 5.7631, 0.0000,\n",
            "        0.0000, 0.0000, 2.8585, 0.0000, 3.4673, 0.0000, 5.6153, 3.6449, 0.0000,\n",
            "        0.0000, 0.0000, 5.2494, 4.6805, 0.0000, 2.4628, 2.9425, 0.0000, 0.0000,\n",
            "        0.0000, 3.3822, 2.1267, 3.6660, 1.5225, 0.0000, 0.0000, 3.9159, 0.0000,\n",
            "        1.2120, 2.7470, 0.0000, 7.3157, 3.9404, 1.5282, 0.0000, 8.0842, 0.0000,\n",
            "        5.3470, 0.0000, 0.0000, 0.0000, 5.0340, 2.0744, 5.0401, 0.0000, 2.5511,\n",
            "        0.0000, 4.4945, 3.2357, 0.0384, 3.8163, 0.0000, 4.7504, 0.0000, 0.0840,\n",
            "        0.0000, 4.9891, 0.0000, 0.0000, 3.8953, 7.1450, 0.0000, 6.7301, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 2.4530, 0.0000, 2.6809,\n",
            "        0.0000, 0.0000, 1.1327, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 2.5799, 4.0914, 3.2714, 0.0000, 3.2413, 5.6269, 4.0766, 0.0000,\n",
            "        4.7435, 0.0000, 2.7601, 0.0000, 0.0000, 0.0000, 1.3172, 0.0000, 3.0846,\n",
            "        0.0000, 3.4682, 0.0000, 0.4123, 0.7971, 0.0000, 2.4043, 0.0000, 0.0000,\n",
            "        5.7511, 7.5343, 3.2502, 5.3665, 2.4639, 4.2842, 5.1925, 5.7461, 0.0000,\n",
            "        1.1668, 1.4472, 0.0000, 5.9993, 0.0000, 9.3136, 2.3424, 0.0000, 1.5931,\n",
            "        2.3815, 0.0000, 5.8974, 0.0000, 4.3316, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 7.8516, 0.0000, 7.1136], grad_fn=<ReluBackward0>)\n",
            "x fc_pi output tensor([ 54.4521, -34.8732,   4.3567, -37.0738], grad_fn=<AddBackward0>)\n",
            "x F.softmax(x, dim=softmax_dim) tensor([ 54.4521, -34.8732,   4.3567, -37.0738], grad_fn=<AddBackward0>)\n",
            "prob tensor([1.0000e+00, 1.6088e-39, 1.7532e-22, 1.7816e-40],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "step 데이터 : [8 4 5 0] -1 -1 False False\n",
            "put_data    : [9 4 5 0] 0 -1 [8 4 5 0] False\n",
            "step 데이터 : [7 4 5 0] -1 -2 False False\n",
            "put_data    : [8 4 5 0] 0 -1 [7 4 5 0] False\n",
            "step 데이터 : [8 4 5 0] -1 -3 False False\n",
            "put_data    : [7 4 5 0] 1 -1 [8 4 5 0] False\n",
            "step 데이터 : [8 5 5 0] -1 -4 False False\n",
            "put_data    : [8 4 5 0] 3 -1 [8 5 5 0] False\n",
            "step 데이터 : [8 6 5 0] -1 -5 False False\n",
            "put_data    : [8 5 5 0] 3 -1 [8 6 5 0] False\n",
            "step 데이터 : [7 6 5 0] -1 -6 False False\n",
            "put_data    : [8 6 5 0] 0 -1 [7 6 5 0] False\n",
            "step 데이터 : [7 7 5 0] -1 -7 False False\n",
            "put_data    : [7 6 5 0] 3 -1 [7 7 5 0] False\n",
            "step 데이터 : [6 7 5 0] -1 -8 False False\n",
            "put_data    : [7 7 5 0] 0 -1 [6 7 5 0] False\n",
            "step 데이터 : [5 7 5 0] -1 -9 False False\n",
            "put_data    : [6 7 5 0] 0 -1 [5 7 5 0] False\n",
            "tensor([5, 7, 5, 0])\n",
            "tensor([5., 7., 5., 0.])\n",
            "end input\n",
            "input x tensor([5., 7., 5., 0.])\n",
            "x F.relu output tensor([0.0000e+00, 2.0021e+00, 3.1473e+00, 3.2120e-01, 3.0116e+00, 0.0000e+00,\n",
            "        0.0000e+00, 9.4758e-01, 4.1809e-01, 0.0000e+00, 1.1612e+00, 1.8837e+00,\n",
            "        4.0440e+00, 0.0000e+00, 2.1976e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 4.9429e+00, 0.0000e+00, 0.0000e+00, 3.5582e+00, 3.5537e+00,\n",
            "        3.9047e+00, 5.1565e+00, 0.0000e+00, 3.2079e+00, 0.0000e+00, 3.3485e+00,\n",
            "        0.0000e+00, 2.7745e+00, 1.5026e+00, 1.4450e+00, 4.9173e+00, 3.5225e+00,\n",
            "        4.1168e-01, 2.7183e+00, 4.1336e+00, 0.0000e+00, 2.5865e+00, 2.4475e+00,\n",
            "        0.0000e+00, 0.0000e+00, 5.4767e+00, 1.8721e+00, 8.4962e-02, 3.7592e+00,\n",
            "        0.0000e+00, 0.0000e+00, 1.4937e+00, 0.0000e+00, 5.7698e+00, 2.6903e+00,\n",
            "        0.0000e+00, 6.3232e-01, 3.3761e+00, 0.0000e+00, 5.5263e+00, 0.0000e+00,\n",
            "        5.6605e+00, 3.3089e+00, 2.2888e+00, 3.1596e+00, 1.7415e-01, 7.0925e-01,\n",
            "        0.0000e+00, 2.2828e+00, 0.0000e+00, 8.0960e-03, 4.1063e-01, 1.4411e+00,\n",
            "        0.0000e+00, 0.0000e+00, 1.6651e+00, 4.5429e-01, 3.5481e+00, 0.0000e+00,\n",
            "        2.5380e+00, 0.0000e+00, 6.1345e+00, 3.5312e+00, 0.0000e+00, 3.7519e+00,\n",
            "        1.4701e+00, 3.5700e+00, 2.1634e+00, 6.3370e+00, 0.0000e+00, 1.2397e-01,\n",
            "        0.0000e+00, 1.0331e+00, 0.0000e+00, 4.9781e+00, 0.0000e+00, 2.7982e+00,\n",
            "        0.0000e+00, 0.0000e+00, 1.7484e+00, 0.0000e+00, 0.0000e+00, 4.0411e+00,\n",
            "        3.7856e-01, 5.1115e+00, 4.2693e+00, 3.1461e-01, 8.1034e-01, 0.0000e+00,\n",
            "        3.8811e+00, 5.8533e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.4441e+00,\n",
            "        6.0764e+00, 6.4772e+00, 0.0000e+00, 0.0000e+00, 1.2797e-01, 4.0439e+00,\n",
            "        0.0000e+00, 4.5128e+00, 0.0000e+00, 6.0477e+00, 3.5805e+00, 0.0000e+00,\n",
            "        0.0000e+00, 1.8620e+00, 5.0240e+00, 4.6777e+00, 0.0000e+00, 2.9048e+00,\n",
            "        2.6035e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.7279e+00, 3.8745e-01,\n",
            "        3.8541e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.7225e+00, 1.1892e+00,\n",
            "        2.0816e+00, 8.7699e-01, 0.0000e+00, 6.7265e+00, 4.1864e+00, 0.0000e+00,\n",
            "        0.0000e+00, 8.1530e+00, 1.6805e+00, 3.0740e+00, 0.0000e+00, 0.0000e+00,\n",
            "        9.1613e-01, 4.9438e+00, 3.2743e+00, 4.1412e+00, 0.0000e+00, 4.0318e-01,\n",
            "        0.0000e+00, 3.0136e+00, 5.3801e+00, 5.9185e-01, 4.7089e+00, 1.6517e+00,\n",
            "        4.8297e+00, 0.0000e+00, 5.1150e-02, 0.0000e+00, 5.7036e+00, 0.0000e+00,\n",
            "        0.0000e+00, 4.0222e+00, 6.6045e+00, 0.0000e+00, 5.1899e+00, 0.0000e+00,\n",
            "        0.0000e+00, 4.5104e-01, 1.1756e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        2.0659e+00, 0.0000e+00, 2.7055e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 1.0070e+00, 2.2874e+00, 3.5458e+00, 0.0000e+00, 3.4804e+00,\n",
            "        5.2745e+00, 5.0274e+00, 0.0000e+00, 3.2414e+00, 0.0000e+00, 2.7360e+00,\n",
            "        0.0000e+00, 0.0000e+00, 3.7893e-01, 2.6478e+00, 0.0000e+00, 3.4262e+00,\n",
            "        0.0000e+00, 4.3484e+00, 4.7817e-01, 1.9545e+00, 1.2638e+00, 0.0000e+00,\n",
            "        2.3161e+00, 0.0000e+00, 0.0000e+00, 3.0844e+00, 6.7086e+00, 2.8587e+00,\n",
            "        2.7063e+00, 4.4527e-01, 4.0731e+00, 3.4607e+00, 5.7136e+00, 0.0000e+00,\n",
            "        9.5493e-01, 2.5697e+00, 0.0000e+00, 6.0521e+00, 1.6808e-01, 8.1234e+00,\n",
            "        2.0888e+00, 0.0000e+00, 7.0269e-03, 1.1423e+00, 0.0000e+00, 6.6781e+00,\n",
            "        0.0000e+00, 1.8175e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 8.6584e+00, 0.0000e+00, 6.7401e+00],\n",
            "       grad_fn=<ReluBackward0>)\n",
            "x fc_pi output tensor([ 46.7510, -30.8993,   6.3825, -33.7665], grad_fn=<AddBackward0>)\n",
            "x F.softmax(x, dim=softmax_dim) tensor([ 46.7510, -30.8993,   6.3825, -33.7665], grad_fn=<AddBackward0>)\n",
            "prob tensor([1.0000e+00, 1.8919e-34, 2.9387e-18, 1.0756e-35],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "step 데이터 : [4 7 5 0] -1 -10 False False\n",
            "put_data    : [5 7 5 0] 0 -1 [4 7 5 0] False\n",
            "input x tensor([[9., 4., 5., 0.],\n",
            "        [8., 4., 5., 0.],\n",
            "        [7., 4., 5., 0.],\n",
            "        [8., 4., 5., 0.],\n",
            "        [8., 5., 5., 0.],\n",
            "        [8., 6., 5., 0.],\n",
            "        [7., 6., 5., 0.],\n",
            "        [7., 7., 5., 0.],\n",
            "        [6., 7., 5., 0.],\n",
            "        [5., 7., 5., 0.]])\n",
            "x F.relu output tensor([[0.0000, 2.5195, 3.1106,  ..., 7.8516, 0.0000, 7.1136],\n",
            "        [0.0000, 2.1594, 2.7696,  ..., 7.6356, 0.0000, 6.6286],\n",
            "        [0.0000, 1.7992, 2.4286,  ..., 7.4196, 0.0000, 6.1436],\n",
            "        ...,\n",
            "        [0.0000, 2.7225, 3.8293,  ..., 9.0903, 0.0000, 7.7101],\n",
            "        [0.0000, 2.3623, 3.4883,  ..., 8.8744, 0.0000, 7.2251],\n",
            "        [0.0000, 2.0021, 3.1473,  ..., 8.6584, 0.0000, 6.7401]],\n",
            "       grad_fn=<ReluBackward0>)\n",
            "x fc_pi output tensor([[ 54.4521, -34.8732,   4.3567, -37.0738],\n",
            "        [ 50.2678, -32.3463,   4.4850, -34.8319],\n",
            "        [ 46.1007, -29.8357,   4.6163, -32.5982],\n",
            "        [ 50.2678, -32.3463,   4.4850, -34.8319],\n",
            "        [ 53.1708, -34.2211,   4.8646, -36.6370],\n",
            "        [ 56.1042, -36.1478,   5.2533, -38.4422],\n",
            "        [ 52.0233, -33.7226,   5.3960, -36.2270],\n",
            "        [ 55.0156, -35.7025,   5.8231, -38.0476],\n",
            "        [ 50.9098, -33.3018,   6.0607, -35.8844],\n",
            "        [ 46.7511, -30.8993,   6.3825, -33.7665]], grad_fn=<AddmmBackward0>)\n",
            "x F.softmax(x, dim=softmax_dim) tensor([[ 54.4521, -34.8732,   4.3567, -37.0738],\n",
            "        [ 50.2678, -32.3463,   4.4850, -34.8319],\n",
            "        [ 46.1007, -29.8357,   4.6163, -32.5982],\n",
            "        [ 50.2678, -32.3463,   4.4850, -34.8319],\n",
            "        [ 53.1708, -34.2211,   4.8646, -36.6370],\n",
            "        [ 56.1042, -36.1478,   5.2533, -38.4422],\n",
            "        [ 52.0233, -33.7226,   5.3960, -36.2270],\n",
            "        [ 55.0156, -35.7025,   5.8231, -38.0476],\n",
            "        [ 50.9098, -33.3018,   6.0607, -35.8844],\n",
            "        [ 46.7511, -30.8993,   6.3825, -33.7665]], grad_fn=<AddmmBackward0>)\n",
            "prob tensor([[1.0000e+00, 1.6088e-39, 1.7531e-22, 1.7816e-40],\n",
            "        [1.0000e+00, 1.3218e-36, 1.3086e-20, 1.1007e-37],\n",
            "        [1.0000e+00, 1.0501e-33, 9.6283e-19, 6.6298e-35],\n",
            "        [1.0000e+00, 1.3218e-36, 1.3086e-20, 1.1007e-37],\n",
            "        [1.0000e+00, 1.1122e-38, 1.0493e-21, 9.9309e-40],\n",
            "        [1.0000e+00, 8.6185e-41, 8.2359e-23, 8.6895e-42],\n",
            "        [1.0000e+00, 5.7680e-38, 5.6237e-21, 4.7142e-39],\n",
            "        [1.0000e+00, 3.9959e-40, 4.3246e-22, 3.8297e-41],\n",
            "        [1.0000e+00, 2.6752e-37, 3.3287e-20, 2.0219e-38],\n",
            "        [1.0000e+00, 1.8919e-34, 2.9386e-18, 1.0756e-35]],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "\n",
            "\n",
            "▶▶▶ 3815  : max cum reward :  1887  epsilon = 0.6184900000000421\n",
            "tensor([4, 7, 5, 0])\n",
            "tensor([4., 7., 5., 0.])\n",
            "end input\n",
            "input x tensor([4., 7., 5., 0.])\n",
            "x F.relu output tensor([0.0000, 1.6419, 2.8062, 0.0000, 3.3260, 0.0000, 0.0000, 0.8195, 0.7320,\n",
            "        0.0000, 0.6039, 1.5355, 3.9400, 0.0000, 2.4389, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 4.7052, 0.0000, 0.0000, 3.2961, 2.9224, 3.7030, 4.8396, 0.0000,\n",
            "        2.6669, 0.0000, 3.0034, 0.0000, 2.5046, 1.4182, 1.1614, 4.7449, 3.4367,\n",
            "        0.0000, 2.4356, 3.6814, 0.0000, 2.7527, 2.0529, 0.0000, 0.0000, 5.2097,\n",
            "        1.8079, 0.3869, 3.4184, 0.0000, 0.0000, 1.3707, 0.0613, 5.4360, 2.2357,\n",
            "        0.0000, 0.8594, 3.1046, 0.0000, 5.3537, 0.0000, 5.2830, 3.6111, 1.9445,\n",
            "        3.0404, 0.0000, 0.7321, 0.0000, 2.4933, 0.0000, 0.4725, 0.7550, 1.0746,\n",
            "        0.0000, 0.0000, 1.5677, 0.9573, 3.5432, 0.0000, 2.0523, 0.0000, 5.9426,\n",
            "        3.6042, 0.0000, 3.2208, 1.9532, 3.1789, 2.3343, 5.8481, 0.0000, 0.5063,\n",
            "        0.0000, 0.5970, 0.0000, 4.5453, 0.0000, 2.3574, 0.0000, 0.0000, 1.3721,\n",
            "        0.0000, 0.0000, 3.5090, 0.3601, 4.6776, 4.0758, 0.7217, 0.6966, 0.0000,\n",
            "        3.9897, 5.6245, 0.0000, 0.0000, 0.0000, 2.2296, 6.0728, 6.3101, 0.0000,\n",
            "        0.0000, 0.5352, 3.9819, 0.0000, 4.5507, 0.0000, 5.9160, 3.5318, 0.0000,\n",
            "        0.0000, 2.1796, 4.6676, 4.2565, 0.0000, 2.7941, 2.3814, 0.0000, 0.0000,\n",
            "        0.0000, 1.3445, 0.0555, 3.5639, 0.0000, 0.0000, 0.0000, 4.6312, 1.4085,\n",
            "        2.0804, 0.5106, 0.0000, 6.2287, 4.0244, 0.0000, 0.0000, 7.8263, 1.8258,\n",
            "        2.5120, 0.0000, 0.0000, 1.4100, 4.6016, 3.2803, 3.5635, 0.0000, 0.0000,\n",
            "        0.0000, 2.6585, 5.4899, 0.7891, 4.6308, 1.9658, 4.4304, 0.0532, 0.0000,\n",
            "        0.0000, 5.4860, 0.0000, 0.0000, 3.7181, 6.1432, 0.0000, 4.6679, 0.0000,\n",
            "        0.0000, 0.8799, 1.6313, 0.0000, 0.0000, 0.0000, 1.9417, 0.0000, 2.4806,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.2017, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.6092, 1.9446, 3.2595, 0.0000, 3.2591, 4.8295, 5.0168, 0.0000,\n",
            "        2.9938, 0.0000, 2.7474, 0.0000, 0.0000, 0.3902, 2.7507, 0.0000, 3.3340,\n",
            "        0.0000, 4.2788, 0.6372, 1.9697, 1.1380, 0.0000, 2.3214, 0.0000, 0.2373,\n",
            "        2.5281, 6.2751, 2.5625, 2.1408, 0.0658, 3.6321, 3.0608, 5.3229, 0.0000,\n",
            "        1.0353, 2.7300, 0.0000, 5.7746, 0.6219, 7.5884, 1.9228, 0.0000, 0.0000,\n",
            "        0.9304, 0.0000, 6.5374, 0.0000, 1.3978, 0.0000, 0.0000, 0.0000, 0.0962,\n",
            "        0.0000, 8.4424, 0.0000, 6.2550], grad_fn=<ReluBackward0>)\n",
            "x fc_pi output tensor([ 42.7142, -28.4860,   6.7985, -31.8016], grad_fn=<AddBackward0>)\n",
            "x F.softmax(x, dim=softmax_dim) tensor([ 42.7142, -28.4860,   6.7985, -31.8016], grad_fn=<AddBackward0>)\n",
            "prob tensor([1.0000e+00, 1.1971e-31, 2.5234e-16, 4.3470e-33],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "step 데이터 : [3 7 5 0] -1 -11 False False\n",
            "put_data    : [4 7 5 0] 0 -1 [3 7 5 0] False\n",
            "step 데이터 : [4 7 5 0] -1 -12 False False\n",
            "put_data    : [3 7 5 0] 1 -1 [4 7 5 0] False\n",
            "tensor([4, 7, 5, 0])\n",
            "tensor([4., 7., 5., 0.])\n",
            "end input\n",
            "input x tensor([4., 7., 5., 0.])\n",
            "x F.relu output tensor([0.0000, 1.6419, 2.8062, 0.0000, 3.3260, 0.0000, 0.0000, 0.8195, 0.7320,\n",
            "        0.0000, 0.6039, 1.5355, 3.9400, 0.0000, 2.4389, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 4.7052, 0.0000, 0.0000, 3.2961, 2.9224, 3.7030, 4.8396, 0.0000,\n",
            "        2.6669, 0.0000, 3.0034, 0.0000, 2.5046, 1.4182, 1.1614, 4.7449, 3.4367,\n",
            "        0.0000, 2.4356, 3.6814, 0.0000, 2.7527, 2.0529, 0.0000, 0.0000, 5.2097,\n",
            "        1.8079, 0.3869, 3.4184, 0.0000, 0.0000, 1.3707, 0.0613, 5.4360, 2.2357,\n",
            "        0.0000, 0.8594, 3.1046, 0.0000, 5.3537, 0.0000, 5.2830, 3.6111, 1.9445,\n",
            "        3.0404, 0.0000, 0.7321, 0.0000, 2.4933, 0.0000, 0.4725, 0.7550, 1.0746,\n",
            "        0.0000, 0.0000, 1.5677, 0.9573, 3.5432, 0.0000, 2.0523, 0.0000, 5.9426,\n",
            "        3.6042, 0.0000, 3.2208, 1.9532, 3.1789, 2.3343, 5.8481, 0.0000, 0.5063,\n",
            "        0.0000, 0.5970, 0.0000, 4.5453, 0.0000, 2.3574, 0.0000, 0.0000, 1.3721,\n",
            "        0.0000, 0.0000, 3.5090, 0.3601, 4.6776, 4.0758, 0.7217, 0.6966, 0.0000,\n",
            "        3.9897, 5.6245, 0.0000, 0.0000, 0.0000, 2.2296, 6.0728, 6.3101, 0.0000,\n",
            "        0.0000, 0.5352, 3.9819, 0.0000, 4.5507, 0.0000, 5.9160, 3.5318, 0.0000,\n",
            "        0.0000, 2.1796, 4.6676, 4.2565, 0.0000, 2.7941, 2.3814, 0.0000, 0.0000,\n",
            "        0.0000, 1.3445, 0.0555, 3.5639, 0.0000, 0.0000, 0.0000, 4.6312, 1.4085,\n",
            "        2.0804, 0.5106, 0.0000, 6.2287, 4.0244, 0.0000, 0.0000, 7.8263, 1.8258,\n",
            "        2.5120, 0.0000, 0.0000, 1.4100, 4.6016, 3.2803, 3.5635, 0.0000, 0.0000,\n",
            "        0.0000, 2.6585, 5.4899, 0.7891, 4.6308, 1.9658, 4.4304, 0.0532, 0.0000,\n",
            "        0.0000, 5.4860, 0.0000, 0.0000, 3.7181, 6.1432, 0.0000, 4.6679, 0.0000,\n",
            "        0.0000, 0.8799, 1.6313, 0.0000, 0.0000, 0.0000, 1.9417, 0.0000, 2.4806,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.2017, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.6092, 1.9446, 3.2595, 0.0000, 3.2591, 4.8295, 5.0168, 0.0000,\n",
            "        2.9938, 0.0000, 2.7474, 0.0000, 0.0000, 0.3902, 2.7507, 0.0000, 3.3340,\n",
            "        0.0000, 4.2788, 0.6372, 1.9697, 1.1380, 0.0000, 2.3214, 0.0000, 0.2373,\n",
            "        2.5281, 6.2751, 2.5625, 2.1408, 0.0658, 3.6321, 3.0608, 5.3229, 0.0000,\n",
            "        1.0353, 2.7300, 0.0000, 5.7746, 0.6219, 7.5884, 1.9228, 0.0000, 0.0000,\n",
            "        0.9304, 0.0000, 6.5374, 0.0000, 1.3978, 0.0000, 0.0000, 0.0000, 0.0962,\n",
            "        0.0000, 8.4424, 0.0000, 6.2550], grad_fn=<ReluBackward0>)\n",
            "x fc_pi output tensor([ 42.7142, -28.4860,   6.7985, -31.8016], grad_fn=<AddBackward0>)\n",
            "x F.softmax(x, dim=softmax_dim) tensor([ 42.7142, -28.4860,   6.7985, -31.8016], grad_fn=<AddBackward0>)\n",
            "prob tensor([1.0000e+00, 1.1971e-31, 2.5234e-16, 4.3470e-33],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "step 데이터 : [3 7 5 0] -1 -13 False False\n",
            "put_data    : [4 7 5 0] 0 -1 [3 7 5 0] False\n",
            "step 데이터 : [4 7 5 0] -1 -14 False False\n",
            "put_data    : [3 7 5 0] 1 -1 [4 7 5 0] False\n",
            "step 데이터 : [4 8 5 0] -1 -15 False False\n",
            "put_data    : [4 7 5 0] 3 -1 [4 8 5 0] False\n",
            "step 데이터 : [4 9 5 0] -100 -115 True False\n",
            "put_data    : [4 8 5 0] 3 -100 [4 9 5 0] True\n",
            "input x tensor([[4., 7., 5., 0.],\n",
            "        [3., 7., 5., 0.],\n",
            "        [4., 7., 5., 0.],\n",
            "        [3., 7., 5., 0.],\n",
            "        [4., 7., 5., 0.],\n",
            "        [4., 8., 5., 0.]])\n",
            "x F.relu output tensor([[0.0000, 1.6419, 2.8062,  ..., 8.4424, 0.0000, 6.2550],\n",
            "        [0.0000, 1.2818, 2.4652,  ..., 8.2264, 0.0000, 5.7700],\n",
            "        [0.0000, 1.6419, 2.8062,  ..., 8.4424, 0.0000, 6.2550],\n",
            "        [0.0000, 1.2818, 2.4652,  ..., 8.2264, 0.0000, 5.7700],\n",
            "        [0.0000, 1.6419, 2.8062,  ..., 8.4424, 0.0000, 6.2550],\n",
            "        [0.0000, 1.9497, 3.2730,  ..., 8.9993, 0.0000, 6.7772]],\n",
            "       grad_fn=<ReluBackward0>)\n",
            "x fc_pi output tensor([[ 42.7142, -28.4860,   6.7985, -31.8016],\n",
            "        [ 38.9371, -26.1955,   7.2276, -29.9717],\n",
            "        [ 42.7142, -28.4860,   6.7985, -31.8016],\n",
            "        [ 38.9371, -26.1955,   7.2276, -29.9717],\n",
            "        [ 42.7142, -28.4860,   6.7985, -31.8016],\n",
            "        [ 45.6602, -30.5296,   7.4503, -33.8005]], grad_fn=<AddmmBackward0>)\n",
            "x F.softmax(x, dim=softmax_dim) tensor([[ 42.7142, -28.4860,   6.7985, -31.8016],\n",
            "        [ 38.9371, -26.1955,   7.2276, -29.9717],\n",
            "        [ 42.7142, -28.4860,   6.7985, -31.8016],\n",
            "        [ 38.9371, -26.1955,   7.2276, -29.9717],\n",
            "        [ 42.7142, -28.4860,   6.7985, -31.8016],\n",
            "        [ 45.6602, -30.5296,   7.4503, -33.8005]], grad_fn=<AddmmBackward0>)\n",
            "prob tensor([[1.0000e+00, 1.1971e-31, 2.5234e-16, 4.3471e-33],\n",
            "        [1.0000e+00, 5.1674e-29, 1.6933e-14, 1.1839e-30],\n",
            "        [1.0000e+00, 1.1971e-31, 2.5234e-16, 4.3471e-33],\n",
            "        [1.0000e+00, 5.1674e-29, 1.6933e-14, 1.1839e-30],\n",
            "        [1.0000e+00, 1.1971e-31, 2.5234e-16, 4.3471e-33],\n",
            "        [1.0000e+00, 8.1509e-34, 2.5450e-17, 3.0952e-35]],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "\n",
            "\n",
            "▶▶▶ 3815  : max cum reward :  1887  epsilon = 0.6184900000000421\n",
            "\n",
            "\n",
            "▶▶▶3816번째 에피소드 시작, env 초기화 완료.\n",
            "가져와야 할 아이템 : ['F', 'G', 'I', 'L', 'Q']\n",
            "\n",
            "현재 state         :  [9 4 0 1]\n",
            "step 데이터 : [10  4  0  1] -100 -100 True False\n",
            "put_data    : [9 4 0 1] 1 -100 [10  4  0  1] True\n",
            "input x tensor([[9., 4., 0., 1.]])\n",
            "x F.relu output tensor([[0.0000, 3.9237, 4.6151, 4.7875, 0.0000, 0.2507, 0.0000, 2.4267, 0.0000,\n",
            "         0.0000, 4.1978, 4.1762, 2.4767, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.1413, 3.9216, 0.0000, 0.0000, 2.8929, 5.8243, 2.5248, 3.7209, 4.2386,\n",
            "         5.6636, 0.0000, 2.9413, 0.0000, 3.3173, 1.6146, 4.5169, 4.0151, 2.4384,\n",
            "         4.8760, 1.5586, 5.0590, 0.0000, 0.0000, 2.9497, 0.0000, 0.0000, 3.5029,\n",
            "         1.8811, 0.0000, 2.6868, 0.0000, 0.0000, 3.1967, 0.0000, 3.6565, 4.7594,\n",
            "         0.0000, 0.0000, 3.1019, 0.0214, 2.8268, 0.0000, 5.9643, 0.0000, 1.8970,\n",
            "         2.1046, 2.8377, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 3.8353,\n",
            "         0.0000, 1.1405, 1.7965, 0.0000, 1.8861, 0.0000, 5.1741, 0.0000, 3.5758,\n",
            "         0.3999, 0.0000, 4.6976, 0.0000, 2.9704, 0.0000, 6.3943, 0.0000, 0.0000,\n",
            "         0.0000, 4.0191, 0.0000, 6.4565, 0.4706, 2.9453, 0.7226, 1.0934, 3.1971,\n",
            "         0.1449, 0.8116, 5.9372, 0.4560, 5.6647, 3.8680, 0.0000, 2.0528, 0.0000,\n",
            "         0.2076, 4.7467, 0.0000, 1.5468, 0.0000, 3.5468, 2.5609, 4.0590, 0.0000,\n",
            "         0.0000, 0.0000, 3.2703, 0.0000, 1.3859, 0.0000, 2.7313, 1.1338, 0.0000,\n",
            "         0.0000, 0.0000, 5.6618, 5.9368, 0.0000, 1.6009, 2.8696, 0.0000, 0.0000,\n",
            "         0.0000, 3.4181, 2.0182, 3.7739, 0.9471, 0.0000, 0.0000, 2.9654, 0.0000,\n",
            "         1.5187, 2.7904, 0.0000, 6.3595, 2.6256, 1.6488, 0.0000, 5.1478, 0.6726,\n",
            "         5.5093, 0.0000, 0.0000, 0.0000, 4.1197, 1.5942, 7.3711, 0.0000, 3.0487,\n",
            "         0.0000, 3.5529, 1.7076, 0.0000, 2.4797, 0.0000, 6.0246, 0.0000, 1.9215,\n",
            "         0.0000, 4.1244, 0.0000, 0.0000, 4.4797, 6.3199, 0.0000, 5.5861, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.1712, 0.0000, 3.3210,\n",
            "         0.0000, 0.0000, 2.5504, 0.0000, 0.0000, 0.9836, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 4.0877, 2.5450, 3.9283, 0.0000, 3.0025, 6.4583, 1.0322, 1.0873,\n",
            "         2.3829, 0.0000, 0.3614, 0.0000, 0.0000, 1.8650, 0.4616, 0.0000, 1.8765,\n",
            "         0.0000, 2.3278, 0.0000, 1.8850, 3.2433, 0.0000, 0.1141, 0.0000, 0.0000,\n",
            "         4.6390, 4.7462, 3.9709, 4.4871, 2.5170, 6.0832, 3.0400, 5.0868, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 4.2192, 0.0000, 6.2352, 1.7043, 0.0000, 3.0380,\n",
            "         1.4694, 0.5360, 3.4162, 0.0000, 2.2003, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 4.9435, 0.0000, 6.9565]], grad_fn=<ReluBackward0>)\n",
            "x fc_pi output tensor([[ 50.6140, -31.2710,   0.6270, -28.7580]], grad_fn=<AddmmBackward0>)\n",
            "x F.softmax(x, dim=softmax_dim) tensor([[ 50.6140, -31.2710,   0.6270, -28.7580]], grad_fn=<AddmmBackward0>)\n",
            "prob tensor([[1.0000e+00, 2.7404e-36, 1.9540e-22, 3.3821e-35]],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "\n",
            "\n",
            "▶▶▶ 3816  : max cum reward :  1887  epsilon = 0.6183900000000421\n",
            "\n",
            "\n",
            "▶▶▶3817번째 에피소드 시작, env 초기화 완료.\n",
            "가져와야 할 아이템 : ['F', 'L', 'M', 'O', 'Q']\n",
            "\n",
            "현재 state         :  [9 4 0 1]\n",
            "tensor([9, 4, 0, 1])\n",
            "tensor([9., 4., 0., 1.])\n",
            "end input\n",
            "input x tensor([9., 4., 0., 1.])\n",
            "x F.relu output tensor([0.0000, 3.9244, 4.6156, 4.7884, 0.0000, 0.2523, 0.0000, 2.4272, 0.0000,\n",
            "        0.0000, 4.1983, 4.1766, 2.4772, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.1430, 3.9220, 0.0000, 0.0000, 2.8935, 5.8249, 2.5252, 3.7215, 4.2398,\n",
            "        5.6642, 0.0000, 2.9418, 0.0000, 3.3179, 1.6150, 4.5173, 4.0155, 2.4390,\n",
            "        4.8769, 1.5590, 5.0596, 0.0000, 0.0000, 2.9504, 0.0000, 0.0000, 3.5033,\n",
            "        1.8815, 0.0000, 2.6873, 0.0000, 0.0000, 3.1970, 0.0000, 3.6569, 4.7599,\n",
            "        0.0000, 0.0000, 3.1023, 0.0230, 2.8274, 0.0000, 5.9650, 0.0000, 1.8974,\n",
            "        2.1050, 2.8385, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 3.8358,\n",
            "        0.0000, 1.1410, 1.7969, 0.0000, 1.8868, 0.0000, 5.1746, 0.0000, 3.5762,\n",
            "        0.4005, 0.0000, 4.6980, 0.0000, 2.9709, 0.0000, 6.3946, 0.0000, 0.0000,\n",
            "        0.0000, 4.0198, 0.0000, 6.4569, 0.4723, 2.9459, 0.7229, 1.0943, 3.1975,\n",
            "        0.1445, 0.8125, 5.9377, 0.4568, 5.6655, 3.8685, 0.0000, 2.0532, 0.0000,\n",
            "        0.2080, 4.7470, 0.0000, 1.5471, 0.0000, 3.5472, 2.5613, 4.0594, 0.0000,\n",
            "        0.0000, 0.0000, 3.2707, 0.0000, 1.3864, 0.0000, 2.7317, 1.1343, 0.0000,\n",
            "        0.0000, 0.0000, 5.6624, 5.9375, 0.0000, 1.6013, 2.8702, 0.0000, 0.0000,\n",
            "        0.0000, 3.4186, 2.0192, 3.7746, 0.9479, 0.0000, 0.0000, 2.9661, 0.0000,\n",
            "        1.5191, 2.7910, 0.0000, 6.3600, 2.6261, 1.6497, 0.0000, 5.1483, 0.6736,\n",
            "        5.5099, 0.0000, 0.0000, 0.0000, 4.1204, 1.5946, 7.3717, 0.0000, 3.0496,\n",
            "        0.0000, 3.5535, 1.7082, 0.0000, 2.4802, 0.0000, 6.0251, 0.0000, 1.9224,\n",
            "        0.0000, 4.1248, 0.0000, 0.0000, 4.4803, 6.3202, 0.0000, 5.5866, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.1719, 0.0000, 3.3217,\n",
            "        0.0000, 0.0000, 2.5515, 0.0000, 0.0000, 0.9859, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 4.0883, 2.5454, 3.9288, 0.0000, 3.0033, 6.4588, 1.0328, 1.0889,\n",
            "        2.3835, 0.0000, 0.3620, 0.0000, 0.0000, 1.8650, 0.4620, 0.0000, 1.8771,\n",
            "        0.0000, 2.3283, 0.0000, 1.8856, 3.2437, 0.0000, 0.1143, 0.0000, 0.0000,\n",
            "        4.6394, 4.7467, 3.9715, 4.4876, 2.5183, 6.0837, 3.0405, 5.0876, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 4.2195, 0.0000, 6.2358, 1.7049, 0.0000, 3.0388,\n",
            "        1.4701, 0.5374, 3.4169, 0.0000, 2.2009, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 4.9441, 0.0000, 6.9570], grad_fn=<ReluBackward0>)\n",
            "x fc_pi output tensor([ 50.6352, -31.2892,   0.6285, -28.7716], grad_fn=<AddBackward0>)\n",
            "x F.softmax(x, dim=softmax_dim) tensor([ 50.6352, -31.2892,   0.6285, -28.7716], grad_fn=<AddBackward0>)\n",
            "prob tensor([1.0000e+00, 2.6346e-36, 1.9159e-22, 3.2664e-35],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "step 데이터 : [8 4 0 1] -1 -1 False False\n",
            "put_data    : [9 4 0 1] 0 -1 [8 4 0 1] False\n",
            "tensor([8, 4, 0, 1])\n",
            "tensor([8., 4., 0., 1.])\n",
            "end input\n",
            "input x tensor([8., 4., 0., 1.])\n",
            "x F.relu output tensor([0.0000, 3.5641, 4.2745, 4.1600, 0.0000, 0.0373, 0.0000, 2.2990, 0.0000,\n",
            "        0.0000, 3.6409, 3.8287, 2.3728, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.1427, 3.6848, 0.0000, 0.0000, 2.6306, 5.1935, 2.3234, 3.4046, 3.6897,\n",
            "        5.1231, 0.0000, 2.5956, 0.0000, 3.0479, 1.5314, 4.2341, 3.8434, 2.3533,\n",
            "        4.2901, 1.2759, 4.6069, 0.0000, 0.0000, 2.5554, 0.0000, 0.0000, 3.2358,\n",
            "        1.8173, 0.0000, 2.3467, 0.0000, 0.0000, 3.0747, 0.0000, 3.3233, 4.3048,\n",
            "        0.0000, 0.0000, 2.8307, 0.0000, 2.6547, 0.0000, 5.5876, 0.0000, 1.5527,\n",
            "        1.9856, 2.4610, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 3.4692,\n",
            "        0.0000, 0.7843, 1.7001, 0.0000, 1.8823, 0.0000, 4.6894, 0.0000, 3.3840,\n",
            "        0.4721, 0.0000, 4.1675, 0.0000, 2.5787, 0.0000, 5.9056, 0.0000, 0.0000,\n",
            "        0.0000, 3.5832, 0.0000, 6.0242, 0.2729, 2.5053, 0.8038, 0.8747, 2.8207,\n",
            "        0.0471, 0.9418, 5.4055, 0.4393, 5.2311, 3.6751, 0.0000, 1.9396, 0.0000,\n",
            "        0.3164, 4.5178, 0.0000, 1.3203, 0.0000, 3.3329, 2.5576, 3.8925, 0.0000,\n",
            "        0.0000, 0.0000, 3.2089, 0.0000, 1.4244, 0.0000, 2.5994, 1.0855, 0.0000,\n",
            "        0.0000, 0.0000, 5.3059, 5.5159, 0.1026, 1.4909, 2.6478, 0.0000, 0.0000,\n",
            "        0.0000, 3.0354, 1.6870, 3.4841, 0.7414, 0.0000, 0.0000, 2.8746, 0.1348,\n",
            "        1.5180, 2.4244, 0.0000, 5.8623, 2.4641, 1.3515, 0.0000, 4.8210, 0.8183,\n",
            "        4.9482, 0.0000, 0.0000, 0.0000, 3.7782, 1.6007, 6.7939, 0.0000, 2.6332,\n",
            "        0.0000, 3.1981, 1.8181, 0.0000, 2.4022, 0.0000, 5.6256, 0.0000, 1.7898,\n",
            "        0.0000, 3.9077, 0.0000, 0.0000, 4.1764, 5.8592, 0.0000, 5.0647, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0467, 0.0000, 3.0969,\n",
            "        0.0000, 0.0000, 2.0991, 0.0000, 0.0000, 0.8184, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 3.6903, 2.2022, 3.6424, 0.0000, 2.7818, 6.0139, 1.0210, 1.0154,\n",
            "        2.1358, 0.0000, 0.3733, 0.0000, 0.0000, 1.8761, 0.5648, 0.0000, 1.7842,\n",
            "        0.0000, 2.2591, 0.0000, 1.9003, 3.1180, 0.0000, 0.1189, 0.0000, 0.0000,\n",
            "        4.0832, 4.3135, 3.6753, 3.9227, 2.1385, 5.6419, 2.6404, 4.6965, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 3.9421, 0.0000, 5.7003, 1.5388, 0.0000, 2.7155,\n",
            "        1.2574, 0.3651, 3.2757, 0.0000, 1.7813, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 4.7281, 0.0000, 6.4719], grad_fn=<ReluBackward0>)\n",
            "x fc_pi output tensor([ 46.4246, -28.7040,   0.7276, -26.4074], grad_fn=<AddBackward0>)\n",
            "x F.softmax(x, dim=softmax_dim) tensor([ 46.4246, -28.7040,   0.7276, -26.4074], grad_fn=<AddBackward0>)\n",
            "prob tensor([1.0000e+00, 2.3555e-33, 1.4258e-20, 2.3415e-32],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "step 데이터 : [7 4 0 1] -1 -2 False False\n",
            "put_data    : [8 4 0 1] 0 -1 [7 4 0 1] False\n",
            "step 데이터 : [6 4 0 1] -100 -102 True False\n",
            "put_data    : [7 4 0 1] 0 -100 [6 4 0 1] True\n",
            "input x tensor([[9., 4., 0., 1.],\n",
            "        [8., 4., 0., 1.],\n",
            "        [7., 4., 0., 1.]])\n",
            "x F.relu output tensor([[0.0000, 3.9244, 4.6156, 4.7884, 0.0000, 0.2523, 0.0000, 2.4272, 0.0000,\n",
            "         0.0000, 4.1983, 4.1766, 2.4772, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.1430, 3.9220, 0.0000, 0.0000, 2.8935, 5.8249, 2.5252, 3.7215, 4.2398,\n",
            "         5.6642, 0.0000, 2.9418, 0.0000, 3.3179, 1.6150, 4.5173, 4.0155, 2.4390,\n",
            "         4.8769, 1.5590, 5.0596, 0.0000, 0.0000, 2.9504, 0.0000, 0.0000, 3.5033,\n",
            "         1.8815, 0.0000, 2.6873, 0.0000, 0.0000, 3.1970, 0.0000, 3.6569, 4.7599,\n",
            "         0.0000, 0.0000, 3.1023, 0.0230, 2.8274, 0.0000, 5.9650, 0.0000, 1.8974,\n",
            "         2.1050, 2.8385, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 3.8358,\n",
            "         0.0000, 1.1410, 1.7969, 0.0000, 1.8868, 0.0000, 5.1746, 0.0000, 3.5762,\n",
            "         0.4005, 0.0000, 4.6980, 0.0000, 2.9709, 0.0000, 6.3946, 0.0000, 0.0000,\n",
            "         0.0000, 4.0198, 0.0000, 6.4569, 0.4723, 2.9459, 0.7229, 1.0943, 3.1975,\n",
            "         0.1445, 0.8125, 5.9377, 0.4568, 5.6655, 3.8685, 0.0000, 2.0532, 0.0000,\n",
            "         0.2080, 4.7470, 0.0000, 1.5471, 0.0000, 3.5472, 2.5613, 4.0594, 0.0000,\n",
            "         0.0000, 0.0000, 3.2707, 0.0000, 1.3864, 0.0000, 2.7317, 1.1343, 0.0000,\n",
            "         0.0000, 0.0000, 5.6624, 5.9375, 0.0000, 1.6013, 2.8702, 0.0000, 0.0000,\n",
            "         0.0000, 3.4186, 2.0192, 3.7746, 0.9479, 0.0000, 0.0000, 2.9661, 0.0000,\n",
            "         1.5191, 2.7910, 0.0000, 6.3600, 2.6261, 1.6497, 0.0000, 5.1483, 0.6736,\n",
            "         5.5099, 0.0000, 0.0000, 0.0000, 4.1204, 1.5946, 7.3717, 0.0000, 3.0496,\n",
            "         0.0000, 3.5535, 1.7082, 0.0000, 2.4802, 0.0000, 6.0251, 0.0000, 1.9224,\n",
            "         0.0000, 4.1248, 0.0000, 0.0000, 4.4803, 6.3202, 0.0000, 5.5866, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.1719, 0.0000, 3.3217,\n",
            "         0.0000, 0.0000, 2.5515, 0.0000, 0.0000, 0.9859, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 4.0883, 2.5454, 3.9288, 0.0000, 3.0033, 6.4588, 1.0328, 1.0889,\n",
            "         2.3835, 0.0000, 0.3620, 0.0000, 0.0000, 1.8651, 0.4620, 0.0000, 1.8771,\n",
            "         0.0000, 2.3283, 0.0000, 1.8856, 3.2437, 0.0000, 0.1143, 0.0000, 0.0000,\n",
            "         4.6394, 4.7467, 3.9715, 4.4876, 2.5183, 6.0837, 3.0405, 5.0876, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 4.2195, 0.0000, 6.2358, 1.7049, 0.0000, 3.0388,\n",
            "         1.4701, 0.5374, 3.4169, 0.0000, 2.2009, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 4.9441, 0.0000, 6.9570],\n",
            "        [0.0000, 3.5641, 4.2745, 4.1600, 0.0000, 0.0373, 0.0000, 2.2990, 0.0000,\n",
            "         0.0000, 3.6409, 3.8287, 2.3728, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.1427, 3.6848, 0.0000, 0.0000, 2.6306, 5.1935, 2.3234, 3.4046, 3.6897,\n",
            "         5.1231, 0.0000, 2.5956, 0.0000, 3.0479, 1.5314, 4.2341, 3.8434, 2.3533,\n",
            "         4.2901, 1.2759, 4.6069, 0.0000, 0.0000, 2.5554, 0.0000, 0.0000, 3.2358,\n",
            "         1.8173, 0.0000, 2.3467, 0.0000, 0.0000, 3.0747, 0.0000, 3.3233, 4.3048,\n",
            "         0.0000, 0.0000, 2.8307, 0.0000, 2.6547, 0.0000, 5.5876, 0.0000, 1.5527,\n",
            "         1.9856, 2.4610, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 3.4692,\n",
            "         0.0000, 0.7843, 1.7001, 0.0000, 1.8823, 0.0000, 4.6894, 0.0000, 3.3840,\n",
            "         0.4721, 0.0000, 4.1675, 0.0000, 2.5787, 0.0000, 5.9056, 0.0000, 0.0000,\n",
            "         0.0000, 3.5832, 0.0000, 6.0242, 0.2729, 2.5053, 0.8038, 0.8747, 2.8207,\n",
            "         0.0471, 0.9418, 5.4055, 0.4393, 5.2311, 3.6751, 0.0000, 1.9396, 0.0000,\n",
            "         0.3164, 4.5178, 0.0000, 1.3203, 0.0000, 3.3329, 2.5576, 3.8925, 0.0000,\n",
            "         0.0000, 0.0000, 3.2089, 0.0000, 1.4244, 0.0000, 2.5994, 1.0855, 0.0000,\n",
            "         0.0000, 0.0000, 5.3059, 5.5159, 0.1026, 1.4909, 2.6478, 0.0000, 0.0000,\n",
            "         0.0000, 3.0354, 1.6870, 3.4841, 0.7414, 0.0000, 0.0000, 2.8746, 0.1348,\n",
            "         1.5180, 2.4244, 0.0000, 5.8623, 2.4641, 1.3515, 0.0000, 4.8210, 0.8183,\n",
            "         4.9482, 0.0000, 0.0000, 0.0000, 3.7782, 1.6007, 6.7939, 0.0000, 2.6332,\n",
            "         0.0000, 3.1981, 1.8181, 0.0000, 2.4022, 0.0000, 5.6256, 0.0000, 1.7898,\n",
            "         0.0000, 3.9077, 0.0000, 0.0000, 4.1764, 5.8592, 0.0000, 5.0647, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0467, 0.0000, 3.0969,\n",
            "         0.0000, 0.0000, 2.0991, 0.0000, 0.0000, 0.8184, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 3.6903, 2.2022, 3.6424, 0.0000, 2.7818, 6.0139, 1.0210, 1.0154,\n",
            "         2.1358, 0.0000, 0.3733, 0.0000, 0.0000, 1.8761, 0.5648, 0.0000, 1.7842,\n",
            "         0.0000, 2.2591, 0.0000, 1.9003, 3.1180, 0.0000, 0.1189, 0.0000, 0.0000,\n",
            "         4.0832, 4.3135, 3.6753, 3.9227, 2.1385, 5.6419, 2.6404, 4.6965, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 3.9421, 0.0000, 5.7003, 1.5388, 0.0000, 2.7155,\n",
            "         1.2574, 0.3651, 3.2757, 0.0000, 1.7813, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 4.7281, 0.0000, 6.4719],\n",
            "        [0.0000, 3.2039, 3.9335, 3.5315, 0.0000, 0.0000, 0.0000, 2.1709, 0.0000,\n",
            "         0.0000, 3.0835, 3.4808, 2.2684, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.1423, 3.4476, 0.0000, 0.0000, 2.3676, 4.5621, 2.1217, 3.0878, 3.1396,\n",
            "         4.5819, 0.0000, 2.2493, 0.0000, 2.7779, 1.4479, 3.9510, 3.6713, 2.2676,\n",
            "         3.7033, 0.9928, 4.1542, 0.0000, 0.0000, 2.1603, 0.0000, 0.0000, 2.9684,\n",
            "         1.7532, 0.0000, 2.0062, 0.0000, 0.0000, 2.9524, 0.0000, 2.9897, 3.8497,\n",
            "         0.0000, 0.0000, 2.5590, 0.0000, 2.4820, 0.0000, 5.2103, 0.0000, 1.2079,\n",
            "         1.8663, 2.0835, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 3.1025,\n",
            "         0.0000, 0.4276, 1.6033, 0.0000, 1.8778, 0.0000, 4.2041, 0.0000, 3.1918,\n",
            "         0.5438, 0.0000, 3.6369, 0.0000, 2.1865, 0.0000, 5.4167, 0.0000, 0.0000,\n",
            "         0.0000, 3.1465, 0.0000, 5.5915, 0.0736, 2.0648, 0.8847, 0.6551, 2.4439,\n",
            "         0.0000, 1.0711, 4.8732, 0.4217, 4.7967, 3.4816, 0.0000, 1.8259, 0.0000,\n",
            "         0.4247, 4.2886, 0.0000, 1.0935, 0.0000, 3.1187, 2.5539, 3.7256, 0.0000,\n",
            "         0.0000, 0.0000, 3.1472, 0.0000, 1.4625, 0.0000, 2.4670, 1.0368, 0.0000,\n",
            "         0.0000, 0.0000, 4.9495, 5.0943, 0.2053, 1.3805, 2.4254, 0.0000, 0.0000,\n",
            "         0.0000, 2.6522, 1.3548, 3.1936, 0.5350, 0.0000, 0.0000, 2.7832, 0.3555,\n",
            "         1.5169, 2.0579, 0.0000, 5.3646, 2.3022, 1.0533, 0.0000, 4.4936, 0.9631,\n",
            "         4.3865, 0.0000, 0.0000, 0.0000, 3.4360, 1.6068, 6.2161, 0.0000, 2.2168,\n",
            "         0.0000, 2.8427, 1.9281, 0.0000, 2.3242, 0.0582, 5.2262, 0.0000, 1.6571,\n",
            "         0.0000, 3.6907, 0.0000, 0.0000, 3.8725, 5.3982, 0.0000, 4.5428, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.9216, 0.0000, 2.8721,\n",
            "         0.0000, 0.0000, 1.6466, 0.0000, 0.0000, 0.6510, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 3.2923, 1.8591, 3.3560, 0.0000, 2.5602, 5.5690, 1.0092, 0.9419,\n",
            "         1.8881, 0.0000, 0.3847, 0.0000, 0.0000, 1.8871, 0.6676, 0.0000, 1.6913,\n",
            "         0.0000, 2.1898, 0.0000, 1.9151, 2.9924, 0.0000, 0.1234, 0.0000, 0.0000,\n",
            "         3.5271, 3.8803, 3.3791, 3.3578, 1.7586, 5.2002, 2.2403, 4.3053, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 3.6648, 0.0000, 5.1647, 1.3726, 0.0000, 2.3922,\n",
            "         1.0448, 0.1929, 3.1344, 0.0000, 1.3618, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 4.5120, 0.0000, 5.9868]], grad_fn=<ReluBackward0>)\n",
            "x fc_pi output tensor([[ 50.6352, -31.2892,   0.6285, -28.7716],\n",
            "        [ 46.4246, -28.7040,   0.7276, -26.4074],\n",
            "        [ 42.2193, -26.1289,   0.8277, -24.0373]], grad_fn=<AddmmBackward0>)\n",
            "x F.softmax(x, dim=softmax_dim) tensor([[ 50.6352, -31.2892,   0.6285, -28.7716],\n",
            "        [ 46.4246, -28.7040,   0.7276, -26.4074],\n",
            "        [ 42.2193, -26.1289,   0.8277, -24.0373]], grad_fn=<AddmmBackward0>)\n",
            "prob tensor([[1.0000e+00, 2.6345e-36, 1.9159e-22, 3.2663e-35],\n",
            "        [1.0000e+00, 2.3555e-33, 1.4258e-20, 2.3415e-32],\n",
            "        [1.0000e+00, 2.0737e-30, 1.0565e-18, 1.6793e-29]],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "\n",
            "\n",
            "▶▶▶ 3817  : max cum reward :  1887  epsilon = 0.6182900000000421\n",
            "\n",
            "\n",
            "▶▶▶3818번째 에피소드 시작, env 초기화 완료.\n",
            "가져와야 할 아이템 : ['D', 'G', 'I']\n",
            "\n",
            "현재 state         :  [9 4 2 0]\n",
            "step 데이터 : [10  4  2  0] -100 -100 True False\n",
            "put_data    : [9 4 2 0] 1 -100 [10  4  2  0] True\n",
            "input x tensor([[9., 4., 2., 0.]])\n",
            "x F.relu output tensor([[0.0000, 3.4751, 4.0195, 4.2101, 0.0000, 0.3380, 0.0000, 1.6712, 0.0000,\n",
            "         0.0000, 4.0522, 3.3571, 2.7632, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 4.0226, 0.0000, 0.0000, 3.6392, 5.8247, 2.9359, 4.8145, 3.3226,\n",
            "         5.2496, 0.0000, 3.7276, 0.0000, 3.2977, 1.3592, 3.1383, 4.2040, 2.6139,\n",
            "         4.1292, 2.7023, 4.9971, 0.0000, 0.0909, 3.7068, 0.0000, 0.0000, 4.3861,\n",
            "         1.5991, 0.0000, 3.7785, 0.0000, 0.0000, 2.0863, 0.0000, 4.8278, 4.5381,\n",
            "         0.0000, 0.0000, 3.3074, 0.3052, 3.8389, 0.0000, 5.6040, 0.0000, 2.9516,\n",
            "         2.5208, 2.5491, 0.0436, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 3.1303,\n",
            "         0.0000, 0.8022, 1.6385, 0.0000, 2.0784, 0.0000, 4.5742, 0.0000, 4.4792,\n",
            "         1.1820, 0.0000, 5.2851, 0.0000, 3.9807, 0.0000, 6.5115, 0.0000, 0.0000,\n",
            "         0.0000, 3.3070, 0.0000, 5.6805, 0.0000, 3.7825, 0.0000, 1.1935, 3.2815,\n",
            "         0.0673, 0.0000, 5.7521, 0.4614, 5.6595, 3.6856, 0.0000, 1.3486, 0.0000,\n",
            "         0.9854, 4.7665, 0.0000, 0.5130, 0.0000, 3.0870, 3.2844, 4.5197, 0.0000,\n",
            "         0.0000, 0.0000, 2.9830, 0.0000, 2.2349, 0.0000, 4.0567, 2.1684, 0.0000,\n",
            "         0.0000, 0.0000, 5.3062, 5.4895, 0.0000, 2.1470, 3.0312, 0.0000, 0.0000,\n",
            "         0.0000, 3.5403, 2.1923, 3.9475, 0.9178, 0.0000, 0.0000, 3.0636, 0.0000,\n",
            "         1.4952, 2.9712, 0.0000, 6.9011, 3.0523, 1.8341, 0.0000, 6.3701, 0.3950,\n",
            "         5.3624, 0.0000, 0.0000, 0.0000, 4.7030, 1.7256, 6.1708, 0.0000, 2.9475,\n",
            "         0.0000, 3.6210, 2.4181, 0.0000, 2.7230, 0.0000, 5.6701, 0.0000, 1.1619,\n",
            "         0.0000, 4.3892, 0.0000, 0.0000, 4.0645, 6.7230, 0.0000, 5.9957, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.5522, 0.0000, 3.2157,\n",
            "         0.0000, 0.0000, 2.1289, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 3.4142, 2.9414, 3.8892, 0.0000, 3.2379, 5.8719, 2.5030, 0.0000,\n",
            "         3.1735, 0.0000, 1.2259, 0.0000, 0.0000, 0.5669, 0.9441, 0.0000, 2.2563,\n",
            "         0.0000, 2.9250, 0.0000, 1.3210, 2.0965, 0.0000, 1.1358, 0.0000, 0.0000,\n",
            "         5.0001, 5.8536, 3.4601, 5.0270, 2.7007, 5.3086, 4.0912, 5.5624, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 5.1783, 0.0000, 7.6455, 2.2277, 0.0000, 2.3479,\n",
            "         1.8297, 0.0000, 4.1803, 0.0000, 3.1551, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 5.9988, 0.0000, 6.7730]], grad_fn=<ReluBackward0>)\n",
            "x fc_pi output tensor([[ 52.1654, -32.6673,   2.0647, -32.0958]], grad_fn=<AddmmBackward0>)\n",
            "x F.softmax(x, dim=softmax_dim) tensor([[ 52.1654, -32.6673,   2.0647, -32.0958]], grad_fn=<AddmmBackward0>)\n",
            "prob tensor([[1.0000e+00, 1.4376e-37, 1.7440e-22, 2.5458e-37]],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "\n",
            "\n",
            "▶▶▶ 3818  : max cum reward :  1887  epsilon = 0.6181900000000421\n",
            "\n",
            "\n",
            "▶▶▶3819번째 에피소드 시작, env 초기화 완료.\n",
            "가져와야 할 아이템 : ['A', 'B', 'C', 'L', 'P']\n",
            "\n",
            "현재 state         :  [9 4 5 0]\n",
            "step 데이터 : [10  4  5  0] -100 -100 True False\n",
            "put_data    : [9 4 5 0] 1 -100 [10  4  5  0] True\n",
            "input x tensor([[9., 4., 5., 0.]])\n",
            "x F.relu output tensor([[0.0000, 2.5208, 3.1112, 3.8362, 0.3772, 0.0000, 0.0000, 0.8736, 0.0000,\n",
            "         0.0000, 4.1832, 2.3683, 2.9096, 0.0000, 0.9143, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 4.5314, 0.0000, 0.0000, 4.2685, 6.0836, 4.2659, 5.9454, 2.1993,\n",
            "         4.9321, 0.0000, 5.4155, 0.0000, 2.5836, 1.6208, 1.8139, 3.9027, 3.1682,\n",
            "         2.8959, 4.3776, 5.3348, 0.0000, 1.0718, 4.3630, 0.0000, 0.0000, 5.0802,\n",
            "         1.6680, 0.0000, 4.8400, 0.0000, 0.0000, 0.9307, 0.0000, 6.2908, 3.5053,\n",
            "         0.0000, 0.0000, 4.2413, 0.1112, 4.8796, 0.0000, 5.7354, 1.3822, 4.3583,\n",
            "         2.9022, 2.1117, 1.2304, 0.0000, 0.7830, 0.0000, 0.0000, 0.0000, 2.4704,\n",
            "         0.0000, 0.0313, 1.6124, 0.0000, 1.7957, 0.0000, 3.8600, 0.2547, 5.7005,\n",
            "         2.5919, 0.0000, 5.6449, 0.0000, 5.3021, 0.7152, 6.8456, 0.0000, 0.0000,\n",
            "         0.0000, 2.7232, 0.0000, 5.2702, 0.0000, 5.0631, 0.0000, 0.8079, 3.7775,\n",
            "         0.0000, 0.0000, 5.0055, 0.0000, 6.0234, 3.4370, 0.0000, 0.4904, 0.0000,\n",
            "         2.5183, 5.3400, 0.0000, 0.0000, 0.0000, 2.2799, 4.5981, 5.7633, 0.0000,\n",
            "         0.0000, 0.0000, 2.8591, 0.0000, 3.4681, 0.0000, 5.6174, 3.6457, 0.0000,\n",
            "         0.0000, 0.0000, 5.2508, 4.6828, 0.0000, 2.4632, 2.9440, 0.0000, 0.0000,\n",
            "         0.0000, 3.3829, 2.1310, 3.6676, 1.5249, 0.0000, 0.0000, 3.9172, 0.0000,\n",
            "         1.2125, 2.7487, 0.0000, 7.3162, 3.9414, 1.5322, 0.0000, 8.0863, 0.0000,\n",
            "         5.3475, 0.0000, 0.0000, 0.0000, 5.0352, 2.0750, 5.0413, 0.0000, 2.5553,\n",
            "         0.0000, 4.4962, 3.2362, 0.0382, 3.8170, 0.0000, 4.7515, 0.0000, 0.0862,\n",
            "         0.0000, 4.9889, 0.0000, 0.0000, 3.8959, 7.1451, 0.0000, 6.7307, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 2.4561, 0.0000, 2.6819,\n",
            "         0.0000, 0.0000, 1.1367, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 2.5816, 4.0929, 3.2723, 0.0000, 3.2432, 5.6278, 4.0798, 0.0000,\n",
            "         4.7447, 0.0000, 2.7611, 0.0000, 0.0000, 0.0000, 1.3180, 0.0000, 3.0869,\n",
            "         0.0000, 3.4683, 0.0000, 0.4140, 0.7973, 0.0000, 2.4058, 0.0000, 0.0000,\n",
            "         5.7515, 7.5347, 3.2511, 5.3665, 2.4689, 4.2866, 5.1936, 5.7484, 0.0000,\n",
            "         1.1650, 1.4430, 0.0000, 5.9998, 0.0000, 9.3158, 2.3434, 0.0000, 1.5965,\n",
            "         2.3842, 0.0000, 5.8996, 0.0000, 4.3323, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 7.8530, 0.0000, 7.1149]], grad_fn=<ReluBackward0>)\n",
            "x fc_pi output tensor([[ 54.5044, -34.8724,   4.3644, -37.1509]], grad_fn=<AddmmBackward0>)\n",
            "x F.softmax(x, dim=softmax_dim) tensor([[ 54.5044, -34.8724,   4.3644, -37.1509]], grad_fn=<AddmmBackward0>)\n",
            "prob tensor([[1.0000e+00, 1.5282e-39, 1.6767e-22, 1.5654e-40]],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "\n",
            "\n",
            "▶▶▶ 3819  : max cum reward :  1887  epsilon = 0.6180900000000421\n",
            "\n",
            "\n",
            "▶▶▶3820번째 에피소드 시작, env 초기화 완료.\n",
            "가져와야 할 아이템 : ['B', 'I', 'J', 'M', 'O']\n",
            "\n",
            "현재 state         :  [9 4 4 0]\n",
            "step 데이터 : [9 5 4 0] -100 -100 True False\n",
            "put_data    : [9 4 4 0] 3 -100 [9 5 4 0] True\n",
            "input x tensor([[9., 4., 4., 0.]])\n",
            "x F.relu output tensor([[0.0000e+00, 2.8417e+00, 3.4159e+00, 3.9634e+00, 8.3343e-03, 0.0000e+00,\n",
            "         0.0000e+00, 1.1414e+00, 0.0000e+00, 0.0000e+00, 4.1416e+00, 2.6998e+00,\n",
            "         2.8626e+00, 0.0000e+00, 4.2293e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "         0.0000e+00, 4.3641e+00, 0.0000e+00, 0.0000e+00, 4.0604e+00, 5.9993e+00,\n",
            "         3.8240e+00, 5.5707e+00, 2.5771e+00, 5.0402e+00, 0.0000e+00, 4.8541e+00,\n",
            "         0.0000e+00, 2.8236e+00, 1.5359e+00, 2.2571e+00, 4.0050e+00, 2.9857e+00,\n",
            "         3.3095e+00, 3.8208e+00, 5.2242e+00, 0.0000e+00, 7.4453e-01, 4.1466e+00,\n",
            "         0.0000e+00, 0.0000e+00, 4.8500e+00, 1.6469e+00, 0.0000e+00, 4.4880e+00,\n",
            "         0.0000e+00, 0.0000e+00, 1.3178e+00, 0.0000e+00, 5.8050e+00, 3.8512e+00,\n",
            "         0.0000e+00, 0.0000e+00, 3.9316e+00, 1.7918e-01, 4.5348e+00, 0.0000e+00,\n",
            "         5.6943e+00, 8.5470e-01, 3.8907e+00, 2.7767e+00, 2.2598e+00, 8.3587e-01,\n",
            "         0.0000e+00, 3.4429e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.6926e+00,\n",
            "         0.0000e+00, 2.9022e-01, 1.6233e+00, 0.0000e+00, 1.8926e+00, 0.0000e+00,\n",
            "         4.1006e+00, 7.7110e-02, 5.2947e+00, 2.1229e+00, 0.0000e+00, 5.5272e+00,\n",
            "         0.0000e+00, 4.8626e+00, 4.4365e-01, 6.7356e+00, 0.0000e+00, 0.0000e+00,\n",
            "         0.0000e+00, 2.9201e+00, 0.0000e+00, 5.4088e+00, 0.0000e+00, 4.6388e+00,\n",
            "         0.0000e+00, 9.3868e-01, 3.6138e+00, 0.0000e+00, 0.0000e+00, 5.2563e+00,\n",
            "         1.5038e-01, 5.9045e+00, 3.5219e+00, 0.0000e+00, 7.7837e-01, 0.0000e+00,\n",
            "         2.0089e+00, 5.1501e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.5507e+00,\n",
            "         4.1620e+00, 5.3507e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.9025e+00,\n",
            "         0.0000e+00, 3.0592e+00, 0.0000e+00, 5.0984e+00, 3.1551e+00, 0.0000e+00,\n",
            "         0.0000e+00, 0.0000e+00, 5.2715e+00, 4.9541e+00, 0.0000e+00, 2.3598e+00,\n",
            "         2.9751e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.4375e+00, 2.1540e+00,\n",
            "         3.7633e+00, 1.3255e+00, 0.0000e+00, 0.0000e+00, 3.6350e+00, 0.0000e+00,\n",
            "         1.3084e+00, 2.8253e+00, 0.0000e+00, 7.1799e+00, 3.6470e+00, 1.6350e+00,\n",
            "         0.0000e+00, 7.5158e+00, 0.0000e+00, 5.3549e+00, 0.0000e+00, 0.0000e+00,\n",
            "         0.0000e+00, 4.9269e+00, 1.9605e+00, 5.4198e+00, 0.0000e+00, 2.6882e+00,\n",
            "         0.0000e+00, 4.2066e+00, 2.9658e+00, 0.0000e+00, 3.4547e+00, 0.0000e+00,\n",
            "         5.0596e+00, 0.0000e+00, 4.4845e-01, 0.0000e+00, 4.7914e+00, 0.0000e+00,\n",
            "         0.0000e+00, 3.9545e+00, 7.0063e+00, 0.0000e+00, 6.4878e+00, 0.0000e+00,\n",
            "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "         2.1566e+00, 0.0000e+00, 2.8626e+00, 0.0000e+00, 0.0000e+00, 1.4707e+00,\n",
            "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "         0.0000e+00, 2.8612e+00, 3.7105e+00, 3.4798e+00, 0.0000e+00, 3.2441e+00,\n",
            "         5.7113e+00, 3.5552e+00, 0.0000e+00, 4.2234e+00, 0.0000e+00, 2.2515e+00,\n",
            "         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.1950e+00, 0.0000e+00, 2.8117e+00,\n",
            "         0.0000e+00, 3.2894e+00, 0.0000e+00, 7.1843e-01, 1.2320e+00, 0.0000e+00,\n",
            "         1.9829e+00, 0.0000e+00, 0.0000e+00, 5.5029e+00, 6.9767e+00, 3.3229e+00,\n",
            "         5.2558e+00, 2.5491e+00, 4.6287e+00, 4.8282e+00, 5.6890e+00, 0.0000e+00,\n",
            "         7.1886e-01, 9.5113e-01, 0.0000e+00, 5.7276e+00, 0.0000e+00, 8.7611e+00,\n",
            "         2.3068e+00, 0.0000e+00, 1.8489e+00, 2.2014e+00, 0.0000e+00, 5.3288e+00,\n",
            "         0.0000e+00, 3.9422e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "         0.0000e+00, 7.2374e+00, 0.0000e+00, 7.0031e+00]],\n",
            "       grad_fn=<ReluBackward0>)\n",
            "x fc_pi output tensor([[ 53.8048, -34.2078,   3.5748, -35.4630]], grad_fn=<AddmmBackward0>)\n",
            "x F.softmax(x, dim=softmax_dim) tensor([[ 53.8048, -34.2078,   3.5748, -35.4630]], grad_fn=<AddmmBackward0>)\n",
            "prob tensor([[1.0000e+00, 5.9792e-39, 1.5324e-22, 1.7041e-39]],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "\n",
            "\n",
            "▶▶▶ 3820  : max cum reward :  1887  epsilon = 0.6179900000000421\n",
            "\n",
            "\n",
            "▶▶▶3821번째 에피소드 시작, env 초기화 완료.\n",
            "가져와야 할 아이템 : ['B', 'C', 'E', 'G', 'J', 'M']\n",
            "\n",
            "현재 state         :  [9 4 4 0]\n",
            "tensor([9, 4, 4, 0])\n",
            "tensor([9., 4., 4., 0.])\n",
            "end input\n",
            "input x tensor([9., 4., 4., 0.])\n",
            "x F.relu output tensor([0.0000e+00, 2.8439e+00, 3.4176e+00, 3.9655e+00, 8.1076e-03, 0.0000e+00,\n",
            "        0.0000e+00, 1.1429e+00, 0.0000e+00, 0.0000e+00, 4.1432e+00, 2.7014e+00,\n",
            "        2.8640e+00, 0.0000e+00, 4.2289e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 4.3660e+00, 0.0000e+00, 0.0000e+00, 4.0618e+00, 6.0009e+00,\n",
            "        3.8253e+00, 5.5725e+00, 2.5798e+00, 5.0420e+00, 0.0000e+00, 4.8551e+00,\n",
            "        0.0000e+00, 2.8250e+00, 1.5377e+00, 2.2585e+00, 4.0066e+00, 2.9875e+00,\n",
            "        3.3114e+00, 3.8222e+00, 5.2258e+00, 0.0000e+00, 7.4430e-01, 4.1486e+00,\n",
            "        0.0000e+00, 0.0000e+00, 4.8511e+00, 1.6485e+00, 0.0000e+00, 4.4895e+00,\n",
            "        0.0000e+00, 0.0000e+00, 1.3194e+00, 0.0000e+00, 5.8066e+00, 3.8524e+00,\n",
            "        0.0000e+00, 0.0000e+00, 3.9329e+00, 1.8180e-01, 4.5366e+00, 0.0000e+00,\n",
            "        5.6964e+00, 8.5507e-01, 3.8920e+00, 2.7781e+00, 2.2617e+00, 8.3694e-01,\n",
            "        0.0000e+00, 3.4454e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.6945e+00,\n",
            "        0.0000e+00, 2.9169e-01, 1.6251e+00, 0.0000e+00, 1.8948e+00, 0.0000e+00,\n",
            "        4.1026e+00, 7.7635e-02, 5.2959e+00, 2.1237e+00, 0.0000e+00, 5.5289e+00,\n",
            "        0.0000e+00, 4.8636e+00, 4.4375e-01, 6.7368e+00, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 2.9219e+00, 0.0000e+00, 5.4104e+00, 0.0000e+00, 4.6408e+00,\n",
            "        0.0000e+00, 9.4044e-01, 3.6153e+00, 0.0000e+00, 0.0000e+00, 5.2579e+00,\n",
            "        1.5190e-01, 5.9065e+00, 3.5236e+00, 0.0000e+00, 7.7994e-01, 0.0000e+00,\n",
            "        2.0102e+00, 5.1512e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.5521e+00,\n",
            "        4.1635e+00, 5.3523e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.9041e+00,\n",
            "        0.0000e+00, 3.0610e+00, 0.0000e+00, 5.0996e+00, 3.1567e+00, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 5.2732e+00, 4.9561e+00, 0.0000e+00, 2.3613e+00,\n",
            "        2.9767e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.4392e+00, 2.1561e+00,\n",
            "        3.7652e+00, 1.3278e+00, 0.0000e+00, 0.0000e+00, 3.6370e+00, 0.0000e+00,\n",
            "        1.3098e+00, 2.8272e+00, 0.0000e+00, 7.1816e+00, 3.6487e+00, 1.6368e+00,\n",
            "        0.0000e+00, 7.5171e+00, 0.0000e+00, 5.3568e+00, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 4.9288e+00, 1.9620e+00, 5.4214e+00, 0.0000e+00, 2.6900e+00,\n",
            "        0.0000e+00, 4.2084e+00, 2.9676e+00, 0.0000e+00, 3.4566e+00, 0.0000e+00,\n",
            "        5.0612e+00, 0.0000e+00, 4.5141e-01, 0.0000e+00, 4.7933e+00, 0.0000e+00,\n",
            "        0.0000e+00, 3.9563e+00, 7.0078e+00, 0.0000e+00, 6.4894e+00, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        2.1581e+00, 0.0000e+00, 2.8648e+00, 0.0000e+00, 0.0000e+00, 1.4732e+00,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 2.8629e+00, 3.7118e+00, 3.4814e+00, 0.0000e+00, 3.2463e+00,\n",
            "        5.7131e+00, 3.5562e+00, 0.0000e+00, 4.2254e+00, 0.0000e+00, 2.2533e+00,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 1.1964e+00, 0.0000e+00, 2.8131e+00,\n",
            "        0.0000e+00, 3.2913e+00, 0.0000e+00, 7.2011e-01, 1.2334e+00, 0.0000e+00,\n",
            "        1.9834e+00, 0.0000e+00, 0.0000e+00, 5.5045e+00, 6.9786e+00, 3.3247e+00,\n",
            "        5.2577e+00, 2.5514e+00, 4.6299e+00, 4.8299e+00, 5.6910e+00, 0.0000e+00,\n",
            "        7.1914e-01, 9.5142e-01, 0.0000e+00, 5.7291e+00, 0.0000e+00, 8.7629e+00,\n",
            "        2.3085e+00, 0.0000e+00, 1.8505e+00, 2.2031e+00, 0.0000e+00, 5.3306e+00,\n",
            "        0.0000e+00, 3.9440e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 7.2394e+00, 0.0000e+00, 7.0049e+00],\n",
            "       grad_fn=<ReluBackward0>)\n",
            "x fc_pi output tensor([ 53.8666, -34.2784,   3.5766, -35.4905], grad_fn=<AddBackward0>)\n",
            "x F.softmax(x, dim=softmax_dim) tensor([ 53.8666, -34.2784,   3.5766, -35.4905], grad_fn=<AddBackward0>)\n",
            "prob tensor([1.0000e+00, 5.2373e-39, 1.4432e-22, 1.5585e-39],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "step 데이터 : [8 4 4 0] -1 -1 False False\n",
            "put_data    : [9 4 4 0] 0 -1 [8 4 4 0] False\n",
            "tensor([8, 4, 4, 0])\n",
            "tensor([8., 4., 4., 0.])\n",
            "end input\n",
            "input x tensor([8., 4., 4., 0.])\n",
            "x F.relu output tensor([0.0000, 2.4831, 3.0761, 3.3365, 0.3224, 0.0000, 0.0000, 1.0144, 0.0000,\n",
            "        0.0000, 3.5854, 2.3531, 2.7593, 0.0000, 0.6639, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 4.1283, 0.0000, 0.0000, 3.7986, 5.3691, 3.6233, 5.2552, 2.0292,\n",
            "        4.5004, 0.0000, 4.5086, 0.0000, 2.5547, 1.4537, 1.9750, 3.8341, 2.9013,\n",
            "        2.7242, 3.5387, 4.7728, 0.0000, 0.9095, 3.7530, 0.0000, 0.0000, 4.5833,\n",
            "        1.5840, 0.0000, 4.1486, 0.0000, 0.0000, 1.1967, 0.0000, 5.4726, 3.3970,\n",
            "        0.0000, 0.0000, 3.6609, 0.1308, 4.3635, 0.0000, 5.3185, 1.1568, 3.5469,\n",
            "        2.6584, 1.8838, 0.8601, 0.0000, 0.5555, 0.0000, 0.0000, 0.0000, 2.3275,\n",
            "        0.0000, 0.0000, 1.5278, 0.0000, 1.8898, 0.0000, 3.6169, 0.0605, 5.1034,\n",
            "        2.1951, 0.0000, 4.9980, 0.0000, 4.4712, 0.6134, 6.2476, 0.0000, 0.0000,\n",
            "        0.0000, 2.4848, 0.0000, 4.9773, 0.0000, 4.1998, 0.0000, 0.7205, 3.2381,\n",
            "        0.0000, 0.0000, 4.7253, 0.1338, 5.4716, 3.3298, 0.0000, 0.6659, 0.0000,\n",
            "        2.1183, 4.9217, 0.0000, 0.0000, 0.0000, 2.3375, 4.1594, 5.1850, 0.0000,\n",
            "        0.0000, 0.0000, 2.8419, 0.0000, 3.0986, 0.0000, 4.9669, 3.1076, 0.0000,\n",
            "        0.0000, 0.0000, 4.9163, 4.5341, 0.0000, 2.2505, 2.7539, 0.0000, 0.0000,\n",
            "        0.0000, 3.0556, 1.8235, 3.4743, 1.1208, 0.0000, 0.0000, 3.5451, 0.0000,\n",
            "        1.3083, 2.4602, 0.0000, 6.6835, 3.4863, 1.3382, 0.0000, 7.1894, 0.0000,\n",
            "        4.7947, 0.0000, 0.0000, 0.0000, 4.5861, 1.9678, 4.8433, 0.0000, 2.2732,\n",
            "        0.0000, 3.8525, 3.0771, 0.0000, 3.3781, 0.0000, 4.6614, 0.0000, 0.3181,\n",
            "        0.0000, 4.5757, 0.0000, 0.0000, 3.6520, 6.5464, 0.0000, 5.9672, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 2.0326, 0.0000, 2.6395,\n",
            "        0.0000, 0.0000, 1.0202, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 2.4645, 3.3683, 3.1946, 0.0000, 3.0242, 5.2677, 3.5442, 0.0000,\n",
            "        3.9772, 0.0000, 2.2642, 0.0000, 0.0000, 0.0000, 1.2989, 0.0000, 2.7199,\n",
            "        0.0000, 3.2216, 0.0000, 0.7344, 1.1074, 0.0000, 1.9879, 0.0000, 0.0000,\n",
            "        4.9479, 6.5449, 3.0281, 4.6924, 2.1711, 4.1878, 4.4294, 5.2994, 0.0000,\n",
            "        0.7995, 1.1123, 0.0000, 5.4513, 0.0000, 8.2269, 2.1420, 0.0000, 1.5269,\n",
            "        1.9901, 0.0000, 5.1889, 0.0000, 3.5241, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 7.0228, 0.0000, 6.5194], grad_fn=<ReluBackward0>)\n",
            "x fc_pi output tensor([ 49.6509, -31.7232,   3.7204, -33.2268], grad_fn=<AddBackward0>)\n",
            "x F.softmax(x, dim=softmax_dim) tensor([ 49.6509, -31.7232,   3.7204, -33.2268], grad_fn=<AddBackward0>)\n",
            "prob tensor([1.0000e+00, 4.5671e-36, 1.1288e-20, 1.0154e-36],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "step 데이터 : [7 4 4 0] -1 -2 False False\n",
            "put_data    : [8 4 4 0] 0 -1 [7 4 4 0] False\n",
            "step 데이터 : [7 3 4 0] -1 -3 False False\n",
            "put_data    : [7 4 4 0] 2 -1 [7 3 4 0] False\n",
            "step 데이터 : [7 2 4 0] -1 -4 False False\n",
            "put_data    : [7 3 4 0] 2 -1 [7 2 4 0] False\n",
            "tensor([7, 2, 4, 0])\n",
            "tensor([7., 2., 4., 0.])\n",
            "end input\n",
            "input x tensor([7., 2., 4., 0.])\n",
            "x F.relu output tensor([0.0000, 1.5065, 1.8009, 3.3715, 0.0000, 0.3971, 0.0000, 0.4941, 0.0000,\n",
            "        0.0000, 3.5547, 1.4002, 1.6189, 0.0000, 0.6909, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 2.9843, 0.0000, 0.0000, 3.3058, 4.7395, 3.1236, 4.6184, 2.1933,\n",
            "        3.6642, 0.0000, 4.6143, 0.0000, 1.4360, 1.2261, 1.1826, 2.5264, 2.3499,\n",
            "        2.2253, 3.6056, 3.9118, 0.0000, 0.5026, 3.5796, 0.0000, 0.0000, 3.3368,\n",
            "        1.2118, 0.0000, 3.6201, 0.0000, 0.0000, 0.3731, 0.0000, 4.5960, 2.2698,\n",
            "        0.0000, 0.0000, 3.2408, 0.2234, 3.2978, 0.0000, 3.9833, 0.9794, 3.6613,\n",
            "        2.0483, 1.7882, 1.2954, 0.0000, 0.3321, 0.0000, 0.0000, 0.0000, 1.6677,\n",
            "        0.0000, 0.5920, 1.1380, 0.0000, 0.7042, 0.0000, 2.7181, 0.2707, 4.1081,\n",
            "        1.8288, 0.0000, 4.3143, 0.0000, 4.1860, 0.2673, 4.7931, 0.0000, 0.0000,\n",
            "        0.0000, 2.0081, 0.0000, 3.5846, 0.0000, 4.0934, 0.0000, 1.0317, 3.2076,\n",
            "        0.0000, 0.0000, 3.4155, 0.0000, 4.4847, 2.0646, 0.0000, 0.0351, 0.0000,\n",
            "        1.6063, 3.7377, 0.0000, 0.0000, 0.0000, 1.4421, 3.1591, 4.0967, 0.0000,\n",
            "        0.0000, 0.0000, 1.8247, 0.0000, 2.5408, 0.0000, 4.1931, 2.9716, 0.0000,\n",
            "        0.0000, 0.0000, 3.7589, 2.9895, 0.0000, 1.5506, 2.1639, 0.0000, 0.0000,\n",
            "        0.0000, 2.7530, 1.7635, 2.2832, 1.8139, 0.0000, 0.0000, 2.6716, 0.0000,\n",
            "        0.7244, 2.3621, 0.0000, 5.2511, 2.7281, 1.2854, 0.0000, 5.9431, 0.0000,\n",
            "        4.2500, 0.0000, 0.0000, 0.0000, 3.3910, 1.1899, 3.3235, 0.0000, 2.1771,\n",
            "        0.0000, 3.5361, 2.0502, 0.1245, 2.4964, 0.0000, 3.1437, 0.0000, 0.0000,\n",
            "        0.0000, 3.3030, 0.0000, 0.0000, 2.4526, 5.2161, 0.0000, 5.0801, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.6039, 0.0000, 0.0000, 1.8312, 0.0000, 1.7982,\n",
            "        0.0000, 0.0000, 1.3358, 0.0000, 0.0000, 0.0000, 0.3202, 0.0000, 0.0000,\n",
            "        0.0000, 2.0531, 3.3126, 1.9613, 0.0000, 2.0518, 3.8707, 2.8667, 0.0000,\n",
            "        4.0697, 0.0000, 2.3216, 0.0000, 0.0000, 0.0000, 0.7885, 0.0000, 2.1513,\n",
            "        0.0000, 2.3806, 0.0000, 0.0000, 0.3353, 0.0000, 2.0634, 0.0000, 0.0000,\n",
            "        4.6861, 5.5065, 2.2027, 4.3942, 2.1225, 2.7083, 4.1166, 3.8861, 0.0000,\n",
            "        1.2364, 0.9547, 0.0000, 4.3988, 0.0000, 7.0562, 1.7016, 0.0000, 1.3978,\n",
            "        2.0358, 0.0000, 4.1500, 0.0000, 3.6614, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 5.6922, 0.0000, 4.9892], grad_fn=<ReluBackward0>)\n",
            "x fc_pi output tensor([ 39.7325, -25.5427,   3.1085, -27.3455], grad_fn=<AddBackward0>)\n",
            "x F.softmax(x, dim=softmax_dim) tensor([ 39.7325, -25.5427,   3.1085, -27.3455], grad_fn=<AddBackward0>)\n",
            "prob tensor([1.0000e+00, 4.4805e-29, 1.2428e-16, 7.3857e-30],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "step 데이터 : [6 2 4 0] -100 -104 True False\n",
            "put_data    : [7 2 4 0] 0 -100 [6 2 4 0] True\n",
            "input x tensor([[9., 4., 4., 0.],\n",
            "        [8., 4., 4., 0.],\n",
            "        [7., 4., 4., 0.],\n",
            "        [7., 3., 4., 0.],\n",
            "        [7., 2., 4., 0.]])\n",
            "x F.relu output tensor([[0.0000, 2.8439, 3.4176,  ..., 7.2394, 0.0000, 7.0049],\n",
            "        [0.0000, 2.4831, 3.0761,  ..., 7.0228, 0.0000, 6.5194],\n",
            "        [0.0000, 2.1224, 2.7347,  ..., 6.8063, 0.0000, 6.0338],\n",
            "        [0.0000, 1.8145, 2.2678,  ..., 6.2493, 0.0000, 5.5115],\n",
            "        [0.0000, 1.5065, 1.8009,  ..., 5.6922, 0.0000, 4.9892]],\n",
            "       grad_fn=<ReluBackward0>)\n",
            "x fc_pi output tensor([[ 53.8666, -34.2784,   3.5766, -35.4905],\n",
            "        [ 49.6509, -31.7232,   3.7204, -33.2268],\n",
            "        [ 45.4598, -29.1914,   3.8586, -30.9554],\n",
            "        [ 42.5605, -27.3295,   3.4846, -29.1463],\n",
            "        [ 39.7325, -25.5427,   3.1085, -27.3455]], grad_fn=<AddmmBackward0>)\n",
            "x F.softmax(x, dim=softmax_dim) tensor([[ 53.8666, -34.2784,   3.5766, -35.4905],\n",
            "        [ 49.6509, -31.7232,   3.7204, -33.2268],\n",
            "        [ 45.4598, -29.1914,   3.8586, -30.9554],\n",
            "        [ 42.5605, -27.3295,   3.4846, -29.1463],\n",
            "        [ 39.7325, -25.5427,   3.1085, -27.3455]], grad_fn=<AddmmBackward0>)\n",
            "prob tensor([[1.0000e+00, 5.2373e-39, 1.4432e-22, 1.5585e-39],\n",
            "        [1.0000e+00, 4.5671e-36, 1.1288e-20, 1.0154e-36],\n",
            "        [1.0000e+00, 3.7964e-33, 8.5672e-19, 6.5057e-34],\n",
            "        [1.0000e+00, 4.4378e-31, 1.0704e-17, 7.2133e-32],\n",
            "        [1.0000e+00, 4.4805e-29, 1.2428e-16, 7.3857e-30]],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "\n",
            "\n",
            "▶▶▶ 3821  : max cum reward :  1887  epsilon = 0.6178900000000421\n",
            "\n",
            "\n",
            "▶▶▶3822번째 에피소드 시작, env 초기화 완료.\n",
            "가져와야 할 아이템 : ['F', 'G', 'I', 'K', 'O', 'Q']\n",
            "\n",
            "현재 state         :  [9 4 0 1]\n",
            "step 데이터 : [8 4 0 1] -1 -1 False False\n",
            "put_data    : [9 4 0 1] 0 -1 [8 4 0 1] False\n",
            "step 데이터 : [9 4 0 1] -1 -2 False False\n",
            "put_data    : [8 4 0 1] 1 -1 [9 4 0 1] False\n",
            "tensor([9, 4, 0, 1])\n",
            "tensor([9., 4., 0., 1.])\n",
            "end input\n",
            "input x tensor([9., 4., 0., 1.])\n",
            "x F.relu output tensor([0.0000, 3.9324, 4.6215, 4.7960, 0.0000, 0.2624, 0.0000, 2.4325, 0.0000,\n",
            "        0.0000, 4.2042, 4.1821, 2.4825, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.1482, 3.9290, 0.0000, 0.0000, 2.8986, 5.8307, 2.5297, 3.7281, 4.2497,\n",
            "        5.6710, 0.0000, 2.9455, 0.0000, 3.3234, 1.6217, 4.5221, 4.0212, 2.4456,\n",
            "        4.8840, 1.5640, 5.0656, 0.0000, 0.0000, 2.9577, 0.0000, 0.0000, 3.5070,\n",
            "        1.8874, 0.0000, 2.6928, 0.0000, 0.0000, 3.2026, 0.0000, 3.6625, 4.7645,\n",
            "        0.0000, 0.0000, 3.1069, 0.0344, 2.8339, 0.0000, 5.9728, 0.0000, 1.9017,\n",
            "        2.1100, 2.8453, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 3.8426,\n",
            "        0.0000, 1.1464, 1.8033, 0.0000, 1.8951, 0.0000, 5.1820, 0.0000, 3.5804,\n",
            "        0.4036, 0.0000, 4.7045, 0.0000, 2.9740, 0.0000, 6.3989, 0.0000, 0.0000,\n",
            "        0.0000, 4.0265, 0.0000, 6.4626, 0.4788, 2.9534, 0.7234, 1.1011, 3.2026,\n",
            "        0.1436, 0.8165, 5.9436, 0.4644, 5.6726, 3.8746, 0.0000, 2.0588, 0.0000,\n",
            "        0.2128, 4.7510, 0.0000, 1.5492, 0.0000, 3.5522, 2.5668, 4.0651, 0.0000,\n",
            "        0.0000, 0.0000, 3.2769, 0.0000, 1.3929, 0.0000, 2.7358, 1.1399, 0.0000,\n",
            "        0.0000, 0.0000, 5.6689, 5.9447, 0.0000, 1.6073, 2.8762, 0.0000, 0.0000,\n",
            "        0.0000, 3.4248, 2.0270, 3.7817, 0.9566, 0.0000, 0.0000, 2.9731, 0.0000,\n",
            "        1.5242, 2.7981, 0.0000, 6.3661, 2.6321, 1.6565, 0.0000, 5.1530, 0.6797,\n",
            "        5.5169, 0.0000, 0.0000, 0.0000, 4.1275, 1.6003, 7.3776, 0.0000, 3.0562,\n",
            "        0.0000, 3.5600, 1.7151, 0.0000, 2.4872, 0.0000, 6.0308, 0.0000, 1.9326,\n",
            "        0.0000, 4.1318, 0.0000, 0.0000, 4.4870, 6.3258, 0.0000, 5.5927, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.1774, 0.0000, 3.3297,\n",
            "        0.0000, 0.0000, 2.5607, 0.0000, 0.0000, 0.9942, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 4.0944, 2.5498, 3.9344, 0.0000, 3.0113, 6.4652, 1.0363, 1.0942,\n",
            "        2.3907, 0.0000, 0.3684, 0.0000, 0.0000, 1.8642, 0.4676, 0.0000, 1.8821,\n",
            "        0.0000, 2.3351, 0.0000, 1.8915, 3.2485, 0.0000, 0.1160, 0.0000, 0.0000,\n",
            "        4.6450, 4.7536, 3.9779, 4.4949, 2.5272, 6.0878, 3.0467, 5.0952, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 4.2246, 0.0000, 6.2422, 1.7114, 0.0000, 3.0446,\n",
            "        1.4761, 0.5429, 3.4237, 0.0000, 2.2077, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 4.9515, 0.0000, 6.9636], grad_fn=<ReluBackward0>)\n",
            "x fc_pi output tensor([ 50.8706, -31.5628,   0.6428, -28.8673], grad_fn=<AddBackward0>)\n",
            "x F.softmax(x, dim=softmax_dim) tensor([ 50.8706, -31.5628,   0.6428, -28.8673], grad_fn=<AddBackward0>)\n",
            "prob tensor([1.0000e+00, 1.5835e-36, 1.5358e-22, 2.3456e-35],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "step 데이터 : [8 4 0 1] -1 -3 False False\n",
            "put_data    : [9 4 0 1] 0 -1 [8 4 0 1] False\n",
            "tensor([8, 4, 0, 1])\n",
            "tensor([8., 4., 0., 1.])\n",
            "end input\n",
            "input x tensor([8., 4., 0., 1.])\n",
            "x F.relu output tensor([0.0000, 3.5715, 4.2799, 4.1670, 0.0000, 0.0466, 0.0000, 2.3039, 0.0000,\n",
            "        0.0000, 3.6464, 3.8337, 2.3777, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.1474, 3.6912, 0.0000, 0.0000, 2.6352, 5.1989, 2.3276, 3.4107, 3.6989,\n",
            "        5.1293, 0.0000, 2.5989, 0.0000, 3.0530, 1.5376, 4.2386, 3.8486, 2.3593,\n",
            "        4.2967, 1.2805, 4.6124, 0.0000, 0.0000, 2.5620, 0.0000, 0.0000, 3.2392,\n",
            "        1.8228, 0.0000, 2.3518, 0.0000, 0.0000, 3.0798, 0.0000, 3.3284, 4.3090,\n",
            "        0.0000, 0.0000, 2.8349, 0.0000, 2.6607, 0.0000, 5.5948, 0.0000, 1.5565,\n",
            "        1.9902, 2.4673, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 3.4754,\n",
            "        0.0000, 0.7893, 1.7059, 0.0000, 1.8899, 0.0000, 4.6961, 0.0000, 3.3878,\n",
            "        0.4750, 0.0000, 4.1734, 0.0000, 2.5815, 0.0000, 5.9095, 0.0000, 0.0000,\n",
            "        0.0000, 3.5893, 0.0000, 6.0293, 0.2790, 2.5122, 0.8043, 0.8810, 2.8254,\n",
            "        0.0462, 0.9454, 5.4109, 0.4463, 5.2376, 3.6807, 0.0000, 1.9446, 0.0000,\n",
            "        0.3207, 4.5214, 0.0000, 1.3223, 0.0000, 3.3376, 2.5626, 3.8977, 0.0000,\n",
            "        0.0000, 0.0000, 3.2146, 0.0000, 1.4304, 0.0000, 2.6031, 1.0907, 0.0000,\n",
            "        0.0000, 0.0000, 5.3119, 5.5226, 0.1025, 1.4964, 2.6533, 0.0000, 0.0000,\n",
            "        0.0000, 3.0411, 1.6942, 3.4907, 0.7495, 0.0000, 0.0000, 2.8811, 0.1332,\n",
            "        1.5227, 2.4310, 0.0000, 5.8679, 2.4696, 1.3579, 0.0000, 4.8253, 0.8240,\n",
            "        4.9546, 0.0000, 0.0000, 0.0000, 3.7847, 1.6059, 6.7993, 0.0000, 2.6393,\n",
            "        0.0000, 3.2040, 1.8245, 0.0000, 2.4086, 0.0000, 5.6309, 0.0000, 1.7991,\n",
            "        0.0000, 3.9141, 0.0000, 0.0000, 4.1826, 5.8643, 0.0000, 5.0703, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0518, 0.0000, 3.1043,\n",
            "        0.0000, 0.0000, 2.1076, 0.0000, 0.0000, 0.8262, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 3.6960, 2.2063, 3.6475, 0.0000, 2.7891, 6.0198, 1.0243, 1.0203,\n",
            "        2.1424, 0.0000, 0.3792, 0.0000, 0.0000, 1.8753, 0.5699, 0.0000, 1.7888,\n",
            "        0.0000, 2.2653, 0.0000, 1.9057, 3.1224, 0.0000, 0.1204, 0.0000, 0.0000,\n",
            "        4.0884, 4.3198, 3.6812, 3.9294, 2.1467, 5.6457, 2.6461, 4.7034, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 3.9467, 0.0000, 5.7062, 1.5447, 0.0000, 2.7209,\n",
            "        1.2630, 0.3702, 3.2819, 0.0000, 1.7876, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 4.7348, 0.0000, 6.4779], grad_fn=<ReluBackward0>)\n",
            "x fc_pi output tensor([ 46.6389, -28.9525,   0.7413, -26.4939], grad_fn=<AddBackward0>)\n",
            "x F.softmax(x, dim=softmax_dim) tensor([ 46.6389, -28.9525,   0.7413, -26.4939], grad_fn=<AddBackward0>)\n",
            "prob tensor([1.0000e+00, 1.4828e-33, 1.1666e-20, 1.7330e-32],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "step 데이터 : [7 4 0 1] -1 -4 False False\n",
            "put_data    : [8 4 0 1] 0 -1 [7 4 0 1] False\n",
            "tensor([7, 4, 0, 1])\n",
            "tensor([7., 4., 0., 1.])\n",
            "end input\n",
            "input x tensor([7., 4., 0., 1.])\n",
            "x F.relu output tensor([0.0000, 3.2106, 3.9384, 3.5379, 0.0000, 0.0000, 0.0000, 2.1753, 0.0000,\n",
            "        0.0000, 3.0885, 3.4854, 2.2729, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.1467, 3.4534, 0.0000, 0.0000, 2.3719, 4.5670, 2.1254, 3.0934, 3.1481,\n",
            "        4.5876, 0.0000, 2.2523, 0.0000, 2.7826, 1.4535, 3.9550, 3.6760, 2.2731,\n",
            "        3.7094, 0.9969, 4.1592, 0.0000, 0.0000, 2.1664, 0.0000, 0.0000, 2.9714,\n",
            "        1.7581, 0.0000, 2.0108, 0.0000, 0.0000, 2.9570, 0.0000, 2.9943, 3.8535,\n",
            "        0.0000, 0.0000, 2.5629, 0.0000, 2.4874, 0.0000, 5.2168, 0.0000, 1.2114,\n",
            "        1.8704, 2.0894, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 3.1082,\n",
            "        0.0000, 0.4322, 1.6086, 0.0000, 1.8847, 0.0000, 4.2103, 0.0000, 3.1953,\n",
            "        0.5464, 0.0000, 3.6423, 0.0000, 2.1891, 0.0000, 5.4202, 0.0000, 0.0000,\n",
            "        0.0000, 3.1521, 0.0000, 5.5961, 0.0793, 2.0710, 0.8853, 0.6610, 2.4482,\n",
            "        0.0000, 1.0742, 4.8781, 0.4281, 4.8027, 3.4868, 0.0000, 1.8305, 0.0000,\n",
            "        0.4287, 4.2919, 0.0000, 1.0954, 0.0000, 3.1229, 2.5584, 3.7303, 0.0000,\n",
            "        0.0000, 0.0000, 3.1523, 0.0000, 1.4679, 0.0000, 2.4704, 1.0415, 0.0000,\n",
            "        0.0000, 0.0000, 4.9549, 5.1004, 0.2052, 1.3855, 2.4304, 0.0000, 0.0000,\n",
            "        0.0000, 2.6574, 1.3615, 3.1996, 0.5425, 0.0000, 0.0000, 2.7891, 0.3538,\n",
            "        1.5211, 2.0639, 0.0000, 5.3697, 2.3072, 1.0592, 0.0000, 4.4975, 0.9683,\n",
            "        4.3924, 0.0000, 0.0000, 0.0000, 3.4419, 1.6115, 6.2211, 0.0000, 2.2224,\n",
            "        0.0000, 2.8480, 1.9338, 0.0000, 2.3300, 0.0597, 5.2310, 0.0000, 1.6656,\n",
            "        0.0000, 3.6965, 0.0000, 0.0000, 3.8782, 5.4028, 0.0000, 4.5479, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.9262, 0.0000, 2.8788,\n",
            "        0.0000, 0.0000, 1.6546, 0.0000, 0.0000, 0.6581, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 3.2975, 1.8628, 3.3607, 0.0000, 2.5669, 5.5743, 1.0122, 0.9464,\n",
            "        1.8941, 0.0000, 0.3901, 0.0000, 0.0000, 1.8864, 0.6722, 0.0000, 1.6955,\n",
            "        0.0000, 2.1955, 0.0000, 1.9200, 2.9963, 0.0000, 0.1248, 0.0000, 0.0000,\n",
            "        3.5317, 3.8860, 3.3845, 3.3639, 1.7663, 5.2036, 2.2455, 4.3117, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 3.6689, 0.0000, 5.1701, 1.3781, 0.0000, 2.3972,\n",
            "        1.0499, 0.1976, 3.1401, 0.0000, 1.3676, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 4.5181, 0.0000, 5.9923], grad_fn=<ReluBackward0>)\n",
            "x fc_pi output tensor([ 42.4129, -26.3531,   0.8401, -24.1158], grad_fn=<AddBackward0>)\n",
            "x F.softmax(x, dim=softmax_dim) tensor([ 42.4129, -26.3531,   0.8401, -24.1158], grad_fn=<AddBackward0>)\n",
            "prob tensor([1.0000e+00, 1.3656e-30, 8.8139e-19, 1.2792e-29],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "step 데이터 : [6 4 0 1] -100 -104 True False\n",
            "put_data    : [7 4 0 1] 0 -100 [6 4 0 1] True\n",
            "input x tensor([[9., 4., 0., 1.],\n",
            "        [8., 4., 0., 1.],\n",
            "        [9., 4., 0., 1.],\n",
            "        [8., 4., 0., 1.],\n",
            "        [7., 4., 0., 1.]])\n",
            "x F.relu output tensor([[0.0000, 3.9324, 4.6215,  ..., 4.9515, 0.0000, 6.9636],\n",
            "        [0.0000, 3.5715, 4.2799,  ..., 4.7348, 0.0000, 6.4779],\n",
            "        [0.0000, 3.9324, 4.6215,  ..., 4.9515, 0.0000, 6.9636],\n",
            "        [0.0000, 3.5715, 4.2799,  ..., 4.7348, 0.0000, 6.4779],\n",
            "        [0.0000, 3.2106, 3.9384,  ..., 4.5181, 0.0000, 5.9923]],\n",
            "       grad_fn=<ReluBackward0>)\n",
            "x fc_pi output tensor([[ 50.8706, -31.5628,   0.6428, -28.8673],\n",
            "        [ 46.6389, -28.9525,   0.7413, -26.4939],\n",
            "        [ 50.8706, -31.5628,   0.6428, -28.8673],\n",
            "        [ 46.6389, -28.9525,   0.7413, -26.4939],\n",
            "        [ 42.4129, -26.3531,   0.8401, -24.1158]], grad_fn=<AddmmBackward0>)\n",
            "x F.softmax(x, dim=softmax_dim) tensor([[ 50.8706, -31.5628,   0.6428, -28.8673],\n",
            "        [ 46.6389, -28.9525,   0.7413, -26.4939],\n",
            "        [ 50.8706, -31.5628,   0.6428, -28.8673],\n",
            "        [ 46.6389, -28.9525,   0.7413, -26.4939],\n",
            "        [ 42.4129, -26.3531,   0.8401, -24.1158]], grad_fn=<AddmmBackward0>)\n",
            "prob tensor([[1.0000e+00, 1.5835e-36, 1.5357e-22, 2.3456e-35],\n",
            "        [1.0000e+00, 1.4828e-33, 1.1666e-20, 1.7331e-32],\n",
            "        [1.0000e+00, 1.5835e-36, 1.5357e-22, 2.3456e-35],\n",
            "        [1.0000e+00, 1.4828e-33, 1.1666e-20, 1.7331e-32],\n",
            "        [1.0000e+00, 1.3656e-30, 8.8139e-19, 1.2792e-29]],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "\n",
            "\n",
            "▶▶▶ 3822  : max cum reward :  1887  epsilon = 0.6177900000000421\n",
            "\n",
            "\n",
            "▶▶▶3823번째 에피소드 시작, env 초기화 완료.\n",
            "가져와야 할 아이템 : ['C', 'E', 'J', 'L', 'O', 'Q']\n",
            "\n",
            "현재 state         :  [9 4 3 0]\n",
            "step 데이터 : [10  4  3  0] -100 -100 True False\n",
            "put_data    : [9 4 3 0] 1 -100 [10  4  3  0] True\n",
            "input x tensor([[9., 4., 3., 0.]])\n",
            "x F.relu output tensor([[0.0000, 3.1659, 3.7232, 4.0937, 0.0000, 0.1649, 0.0000, 1.4113, 0.0000,\n",
            "         0.0000, 4.1023, 3.0336, 2.8178, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 4.1997, 0.0000, 0.0000, 3.8547, 5.9174, 3.3841, 5.1988, 2.9589,\n",
            "         5.1511, 0.0000, 4.2945, 0.0000, 3.0658, 1.4537, 2.7021, 4.1097, 2.8060,\n",
            "         3.7258, 3.2662, 5.1162, 0.0000, 0.4174, 3.9334, 0.0000, 0.0000, 4.6214,\n",
            "         1.6286, 0.0000, 4.1382, 0.0000, 0.0000, 1.7070, 0.0000, 5.3216, 4.1989,\n",
            "         0.0000, 0.0000, 3.6238, 0.2508, 4.1929, 0.0000, 5.6565, 0.3282, 3.4251,\n",
            "         2.6533, 2.4106, 0.4429, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 2.9177,\n",
            "         0.0000, 0.5512, 1.6367, 0.0000, 1.9931, 0.0000, 4.3442, 0.0000, 4.8908,\n",
            "         1.6557, 0.0000, 5.4120, 0.0000, 4.4247, 0.1725, 6.6274, 0.0000, 0.0000,\n",
            "         0.0000, 3.1199, 0.0000, 5.5498, 0.0000, 4.2177, 0.0000, 1.0720, 3.4523,\n",
            "         0.0000, 0.0000, 5.5096, 0.3113, 5.7888, 3.6094, 0.0000, 1.0684, 0.0000,\n",
            "         1.5016, 4.9622, 0.0000, 0.1636, 0.0000, 2.8234, 3.7282, 4.9404, 0.0000,\n",
            "         0.0000, 0.0000, 2.9484, 0.0000, 2.6531, 0.0000, 4.5815, 2.6669, 0.0000,\n",
            "         0.0000, 0.0000, 5.2949, 5.2287, 0.0000, 2.2587, 3.0087, 0.0000, 0.0000,\n",
            "         0.0000, 3.4946, 2.1801, 3.8621, 1.1295, 0.0000, 0.0000, 3.3560, 0.0000,\n",
            "         1.4063, 2.9047, 0.0000, 7.0463, 3.3552, 1.7404, 0.0000, 6.9474, 0.1158,\n",
            "         5.3652, 0.0000, 0.0000, 0.0000, 4.8215, 1.8483, 5.8007, 0.0000, 2.8237,\n",
            "         0.0000, 3.9198, 2.6983, 0.0000, 3.0954, 0.0000, 5.3702, 0.0000, 0.8149,\n",
            "         0.0000, 4.5967, 0.0000, 0.0000, 4.0158, 6.8697, 0.0000, 6.2473, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.8599, 0.0000, 3.0469,\n",
            "         0.0000, 0.0000, 1.8082, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 3.1432, 3.3300, 3.6897, 0.0000, 3.2487, 5.7975, 3.0327, 0.0000,\n",
            "         3.7053, 0.0000, 1.7448, 0.0000, 0.0000, 0.0540, 1.0744, 0.0000, 2.5388,\n",
            "         0.0000, 3.1135, 0.0000, 1.0254, 1.6686, 0.0000, 1.5612, 0.0000, 0.0000,\n",
            "         5.2567, 6.4217, 3.3975, 5.1483, 2.6328, 4.9726, 4.4655, 5.6329, 0.0000,\n",
            "         0.2731, 0.4598, 0.0000, 5.4576, 0.0000, 8.2094, 2.2729, 0.0000, 2.1036,\n",
            "         2.0213, 0.0000, 4.7610, 0.0000, 3.5550, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 6.6250, 0.0000, 6.8942]], grad_fn=<ReluBackward0>)\n",
            "x fc_pi output tensor([[ 53.1958, -33.6719,   2.8235, -33.8385]], grad_fn=<AddmmBackward0>)\n",
            "x F.softmax(x, dim=softmax_dim) tensor([[ 53.1958, -33.6719,   2.8235, -33.8385]], grad_fn=<AddmmBackward0>)\n",
            "prob tensor([[1.0000e+00, 1.8785e-38, 1.3292e-22, 1.5903e-38]],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "\n",
            "\n",
            "▶▶▶ 3823  : max cum reward :  1887  epsilon = 0.6176900000000421\n",
            "\n",
            "\n",
            "▶▶▶3824번째 에피소드 시작, env 초기화 완료.\n",
            "가져와야 할 아이템 : ['B', 'E', 'K', 'L', 'P', 'Q']\n",
            "\n",
            "현재 state         :  [9 4 4 0]\n",
            "step 데이터 : [10  4  4  0] -100 -100 True False\n",
            "put_data    : [9 4 4 0] 1 -100 [10  4  4  0] True\n",
            "input x tensor([[9., 4., 4., 0.]])\n",
            "x F.relu output tensor([[0.0000e+00, 2.8478e+00, 3.4203e+00, 3.9694e+00, 8.5014e-03, 0.0000e+00,\n",
            "         0.0000e+00, 1.1453e+00, 0.0000e+00, 0.0000e+00, 4.1460e+00, 2.7038e+00,\n",
            "         2.8667e+00, 0.0000e+00, 4.2346e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "         0.0000e+00, 4.3691e+00, 0.0000e+00, 0.0000e+00, 4.0648e+00, 6.0037e+00,\n",
            "         3.8273e+00, 5.5757e+00, 2.5848e+00, 5.0453e+00, 0.0000e+00, 4.8577e+00,\n",
            "         0.0000e+00, 2.8278e+00, 1.5407e+00, 2.2603e+00, 4.0091e+00, 2.9907e+00,\n",
            "         3.3149e+00, 3.8248e+00, 5.2289e+00, 0.0000e+00, 7.4491e-01, 4.1523e+00,\n",
            "         0.0000e+00, 0.0000e+00, 4.8528e+00, 1.6516e+00, 0.0000e+00, 4.4919e+00,\n",
            "         0.0000e+00, 0.0000e+00, 1.3215e+00, 0.0000e+00, 5.8092e+00, 3.8548e+00,\n",
            "         0.0000e+00, 0.0000e+00, 3.9350e+00, 1.8614e-01, 4.5399e+00, 0.0000e+00,\n",
            "         5.7003e+00, 8.5592e-01, 3.8941e+00, 2.7804e+00, 2.2649e+00, 8.3820e-01,\n",
            "         0.0000e+00, 3.4476e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.6978e+00,\n",
            "         0.0000e+00, 2.9428e-01, 1.6278e+00, 0.0000e+00, 1.8989e+00, 0.0000e+00,\n",
            "         4.1061e+00, 7.9153e-02, 5.2979e+00, 2.1263e+00, 0.0000e+00, 5.5318e+00,\n",
            "         0.0000e+00, 4.8656e+00, 4.4497e-01, 6.7387e+00, 0.0000e+00, 0.0000e+00,\n",
            "         0.0000e+00, 2.9255e+00, 0.0000e+00, 5.4129e+00, 0.0000e+00, 4.6446e+00,\n",
            "         0.0000e+00, 9.4348e-01, 3.6177e+00, 0.0000e+00, 0.0000e+00, 5.2608e+00,\n",
            "         1.5322e-01, 5.9103e+00, 3.5265e+00, 0.0000e+00, 7.8215e-01, 0.0000e+00,\n",
            "         2.0126e+00, 5.1536e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.5542e+00,\n",
            "         4.1661e+00, 5.3548e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.9070e+00,\n",
            "         0.0000e+00, 3.0642e+00, 0.0000e+00, 5.1020e+00, 3.1593e+00, 0.0000e+00,\n",
            "         0.0000e+00, 0.0000e+00, 5.2764e+00, 4.9599e+00, 0.0000e+00, 2.3640e+00,\n",
            "         2.9797e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.4421e+00, 2.1599e+00,\n",
            "         3.7689e+00, 1.3319e+00, 0.0000e+00, 0.0000e+00, 3.6406e+00, 0.0000e+00,\n",
            "         1.3120e+00, 2.8305e+00, 0.0000e+00, 7.1846e+00, 3.6515e+00, 1.6401e+00,\n",
            "         0.0000e+00, 7.5197e+00, 0.0000e+00, 5.3601e+00, 0.0000e+00, 0.0000e+00,\n",
            "         0.0000e+00, 4.9323e+00, 1.9647e+00, 5.4242e+00, 0.0000e+00, 2.6933e+00,\n",
            "         0.0000e+00, 4.2116e+00, 2.9710e+00, 0.0000e+00, 3.4600e+00, 0.0000e+00,\n",
            "         5.0641e+00, 0.0000e+00, 4.5648e-01, 0.0000e+00, 4.7965e+00, 0.0000e+00,\n",
            "         0.0000e+00, 3.9594e+00, 7.0102e+00, 0.0000e+00, 6.4922e+00, 0.0000e+00,\n",
            "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "         2.1617e+00, 0.0000e+00, 2.8691e+00, 0.0000e+00, 0.0000e+00, 1.4777e+00,\n",
            "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "         0.0000e+00, 2.8656e+00, 3.7139e+00, 3.4840e+00, 0.0000e+00, 3.2507e+00,\n",
            "         5.7160e+00, 3.5589e+00, 0.0000e+00, 4.2291e+00, 0.0000e+00, 2.2566e+00,\n",
            "         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.1992e+00, 0.0000e+00, 2.8159e+00,\n",
            "         0.0000e+00, 3.2945e+00, 0.0000e+00, 7.2330e-01, 1.2354e+00, 0.0000e+00,\n",
            "         1.9849e+00, 0.0000e+00, 0.0000e+00, 5.5071e+00, 6.9821e+00, 3.3278e+00,\n",
            "         5.2614e+00, 2.5558e+00, 4.6322e+00, 4.8331e+00, 5.6952e+00, 0.0000e+00,\n",
            "         7.1889e-01, 9.5082e-01, 0.0000e+00, 5.7313e+00, 0.0000e+00, 8.7664e+00,\n",
            "         2.3115e+00, 0.0000e+00, 1.8533e+00, 2.2064e+00, 0.0000e+00, 5.3343e+00,\n",
            "         0.0000e+00, 3.9474e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "         0.0000e+00, 7.2432e+00, 0.0000e+00, 7.0082e+00]],\n",
            "       grad_fn=<ReluBackward0>)\n",
            "x fc_pi output tensor([[ 53.9730, -34.4111,   3.5995, -35.5489]], grad_fn=<AddmmBackward0>)\n",
            "x F.softmax(x, dim=softmax_dim) tensor([[ 53.9730, -34.4111,   3.5995, -35.5489]], grad_fn=<AddmmBackward0>)\n",
            "prob tensor([[1.0000e+00, 4.1233e-39, 1.3275e-22, 1.3217e-39]],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "\n",
            "\n",
            "▶▶▶ 3824  : max cum reward :  1887  epsilon = 0.6175900000000422\n",
            "\n",
            "\n",
            "▶▶▶3825번째 에피소드 시작, env 초기화 완료.\n",
            "가져와야 할 아이템 : ['H', 'J', 'M', 'P']\n",
            "\n",
            "현재 state         :  [9 4 0 3]\n",
            "step 데이터 : [10  4  0  3] -100 -100 True False\n",
            "put_data    : [9 4 0 3] 1 -100 [10  4  0  3] True\n",
            "input x tensor([[9., 4., 0., 3.]])\n",
            "x F.relu output tensor([[0.0000e+00, 3.5602e+00, 4.6034e+00, 5.4562e+00, 0.0000e+00, 0.0000e+00,\n",
            "         0.0000e+00, 2.8816e+00, 0.0000e+00, 0.0000e+00, 4.6720e+00, 4.5031e+00,\n",
            "         2.1069e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "         9.9172e-01, 4.4069e+00, 0.0000e+00, 0.0000e+00, 2.2481e+00, 6.1773e+00,\n",
            "         3.4823e+00, 3.0510e+00, 4.5884e+00, 6.0781e+00, 0.0000e+00, 3.6263e+00,\n",
            "         0.0000e+00, 2.4125e+00, 2.4827e+00, 5.5145e+00, 3.2431e+00, 2.8360e+00,\n",
            "         4.7366e+00, 1.5122e+00, 5.6423e+00, 0.0000e+00, 0.0000e+00, 2.3219e+00,\n",
            "         0.0000e+00, 0.0000e+00, 2.6677e+00, 2.5454e+00, 0.0000e+00, 1.9266e+00,\n",
            "         0.0000e+00, 0.0000e+00, 3.8835e+00, 0.0000e+00, 3.2721e+00, 3.8321e+00,\n",
            "         0.0000e+00, 0.0000e+00, 3.9426e+00, 0.0000e+00, 2.2003e+00, 0.0000e+00,\n",
            "         6.8713e+00, 0.0000e+00, 1.6698e+00, 1.7879e+00, 2.8423e+00, 0.0000e+00,\n",
            "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.3748e+00,\n",
            "         0.0000e+00, 7.9657e-01, 2.0858e+00, 0.0000e+00, 1.1370e+00, 0.0000e+00,\n",
            "         5.4318e+00, 0.0000e+00, 3.4039e+00, 7.2250e-01, 1.7318e-01, 4.0108e+00,\n",
            "         0.0000e+00, 2.7176e+00, 0.0000e+00, 6.6111e+00, 0.0000e+00, 0.0000e+00,\n",
            "         0.0000e+00, 4.6754e+00, 0.0000e+00, 7.4690e+00, 1.1933e+00, 2.9887e+00,\n",
            "         1.4721e+00, 3.9042e-01, 3.6970e+00, 0.0000e+00, 1.4618e+00, 5.3204e+00,\n",
            "         0.0000e+00, 6.1716e+00, 3.9102e+00, 0.0000e+00, 2.3244e+00, 0.0000e+00,\n",
            "         7.0269e-01, 5.4781e+00, 0.0000e+00, 2.2118e+00, 0.0000e+00, 3.3972e+00,\n",
            "         2.8734e+00, 4.8032e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.6879e+00,\n",
            "         3.8820e-01, 1.3413e+00, 0.0000e+00, 2.1683e+00, 1.0427e+00, 0.0000e+00,\n",
            "         0.0000e+00, 0.0000e+00, 6.3086e+00, 5.7668e+00, 1.8386e-01, 9.3894e-01,\n",
            "         2.4393e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.9728e+00, 1.6009e+00,\n",
            "         3.0645e+00, 1.8273e+00, 0.0000e+00, 0.0000e+00, 3.9177e+00, 0.0000e+00,\n",
            "         1.1963e+00, 2.1421e+00, 0.0000e+00, 5.8383e+00, 2.9663e+00, 8.8784e-01,\n",
            "         0.0000e+00, 4.9991e+00, 9.6981e-02, 5.7929e+00, 0.0000e+00, 0.0000e+00,\n",
            "         0.0000e+00, 3.4068e+00, 1.8050e+00, 8.2745e+00, 0.0000e+00, 2.7395e+00,\n",
            "         0.0000e+00, 4.5935e+00, 1.3873e+00, 0.0000e+00, 3.4614e+00, 0.0000e+00,\n",
            "         5.5172e+00, 0.0000e+00, 2.0209e+00, 0.0000e+00, 4.4035e+00, 4.7664e-01,\n",
            "         0.0000e+00, 5.0946e+00, 6.0836e+00, 0.0000e+00, 5.7555e+00, 0.0000e+00,\n",
            "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "         1.6242e+00, 0.0000e+00, 2.8314e+00, 0.0000e+00, 0.0000e+00, 2.0849e+00,\n",
            "         4.7337e-02, 0.0000e+00, 1.1952e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "         0.0000e+00, 4.3332e+00, 3.2940e+00, 3.1920e+00, 0.0000e+00, 2.5512e+00,\n",
            "         7.3147e+00, 2.0097e-01, 1.9281e+00, 2.9071e+00, 0.0000e+00, 6.8883e-01,\n",
            "         0.0000e+00, 0.0000e+00, 2.4108e+00, 4.4009e-03, 0.0000e+00, 2.2326e+00,\n",
            "         0.0000e+00, 1.8673e+00, 0.0000e+00, 1.8126e+00, 3.8109e+00, 0.0000e+00,\n",
            "         0.0000e+00, 1.9615e-01, 0.0000e+00, 4.9263e+00, 4.7824e+00, 4.7230e+00,\n",
            "         3.8701e+00, 1.8562e+00, 6.2765e+00, 2.4164e+00, 4.3957e+00, 0.0000e+00,\n",
            "         0.0000e+00, 0.0000e+00, 0.0000e+00, 3.4029e+00, 0.0000e+00, 5.6516e+00,\n",
            "         8.2248e-01, 0.0000e+00, 3.4259e+00, 1.4979e+00, 1.2428e+00, 4.1912e+00,\n",
            "         0.0000e+00, 1.8702e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "         0.0000e+00, 5.3160e+00, 0.0000e+00, 7.7889e+00]],\n",
            "       grad_fn=<ReluBackward0>)\n",
            "x fc_pi output tensor([[ 50.7911, -31.3181,   0.4512, -28.2415]], grad_fn=<AddmmBackward0>)\n",
            "x F.softmax(x, dim=softmax_dim) tensor([[ 50.7911, -31.3181,   0.4512, -28.2415]], grad_fn=<AddmmBackward0>)\n",
            "prob tensor([[1.0000e+00, 2.1901e-36, 1.3730e-22, 4.7490e-35]],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "\n",
            "\n",
            "▶▶▶ 3825  : max cum reward :  1887  epsilon = 0.6174900000000422\n",
            "\n",
            "\n",
            "▶▶▶3826번째 에피소드 시작, env 초기화 완료.\n",
            "가져와야 할 아이템 : ['A', 'E', 'F', 'G', 'J', 'K', 'L']\n",
            "\n",
            "현재 state         :  [9 4 5 0]\n",
            "tensor([9, 4, 5, 0])\n",
            "tensor([9., 4., 5., 0.])\n",
            "end input\n",
            "input x tensor([9., 4., 5., 0.])\n",
            "x F.relu output tensor([0.0000, 2.5264, 3.1151, 3.8432, 0.3786, 0.0000, 0.0000, 0.8768, 0.0000,\n",
            "        0.0000, 4.1874, 2.3714, 2.9137, 0.0000, 0.9157, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 4.5353, 0.0000, 0.0000, 4.2735, 6.0877, 4.2688, 5.9499, 2.2077,\n",
            "        4.9368, 0.0000, 5.4202, 0.0000, 2.5876, 1.6243, 1.8161, 3.9060, 3.1728,\n",
            "        2.9021, 4.3817, 5.3395, 0.0000, 1.0739, 4.3687, 0.0000, 0.0000, 5.0830,\n",
            "        1.6725, 0.0000, 4.8432, 0.0000, 0.0000, 0.9332, 0.0000, 6.2944, 3.5090,\n",
            "        0.0000, 0.0000, 4.2445, 0.1195, 4.8844, 0.0000, 5.7410, 1.3830, 4.3616,\n",
            "        2.9056, 2.1172, 1.2314, 0.0000, 0.7820, 0.0000, 0.0000, 0.0000, 2.4751,\n",
            "        0.0000, 0.0353, 1.6158, 0.0000, 1.8014, 0.0000, 3.8647, 0.2592, 5.7036,\n",
            "        2.5968, 0.0000, 5.6486, 0.0000, 5.3059, 0.7199, 6.8483, 0.0000, 0.0000,\n",
            "        0.0000, 2.7288, 0.0000, 5.2737, 0.0000, 5.0682, 0.0000, 0.8131, 3.7813,\n",
            "        0.0000, 0.0000, 5.0096, 0.0000, 6.0293, 3.4411, 0.0000, 0.4933, 0.0000,\n",
            "        2.5220, 5.3439, 0.0000, 0.0000, 0.0000, 2.2828, 4.6021, 5.7667, 0.0000,\n",
            "        0.0000, 0.0000, 2.8630, 0.0000, 3.4726, 0.0000, 5.6215, 3.6495, 0.0000,\n",
            "        0.0000, 0.0000, 5.2554, 4.6887, 0.0000, 2.4667, 2.9485, 0.0000, 0.0000,\n",
            "        0.0000, 3.3871, 2.1379, 3.6732, 1.5314, 0.0000, 0.0000, 3.9226, 0.0000,\n",
            "        1.2157, 2.7537, 0.0000, 7.3204, 3.9455, 1.5381, 0.0000, 8.0907, 0.0000,\n",
            "        5.3519, 0.0000, 0.0000, 0.0000, 5.0403, 2.0788, 5.0454, 0.0000, 2.5614,\n",
            "        0.0000, 4.5011, 3.2408, 0.0400, 3.8218, 0.0000, 4.7558, 0.0000, 0.0938,\n",
            "        0.0000, 4.9930, 0.0000, 0.0000, 3.9002, 7.1483, 0.0000, 6.7345, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 2.4622, 0.0000, 2.6880,\n",
            "        0.0000, 0.0000, 1.1445, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 2.5855, 4.0962, 3.2762, 0.0000, 3.2498, 5.6319, 4.0847, 0.0000,\n",
            "        4.7502, 0.0000, 2.7659, 0.0000, 0.0000, 0.0000, 1.3221, 0.0000, 3.0917,\n",
            "        0.0000, 3.4725, 0.0000, 0.4189, 0.7999, 0.0000, 2.4087, 0.0000, 0.0000,\n",
            "        5.7552, 7.5395, 3.2555, 5.3712, 2.4768, 4.2905, 5.1982, 5.7548, 0.0000,\n",
            "        1.1633, 1.4390, 0.0000, 6.0029, 0.0000, 9.3212, 2.3478, 0.0000, 1.6015,\n",
            "        2.3896, 0.0000, 5.9054, 0.0000, 4.3369, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 7.8586, 0.0000, 7.1197], grad_fn=<ReluBackward0>)\n",
            "x fc_pi output tensor([ 54.6617, -35.0465,   4.4017, -37.2614], grad_fn=<AddBackward0>)\n",
            "x F.softmax(x, dim=softmax_dim) tensor([ 54.6617, -35.0465,   4.4017, -37.2614], grad_fn=<AddBackward0>)\n",
            "prob tensor([1.0000e+00, 1.0970e-39, 1.4873e-22, 1.1977e-40],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "step 데이터 : [8 4 5 0] -1 -1 False False\n",
            "put_data    : [9 4 5 0] 0 -1 [8 4 5 0] False\n",
            "step 데이터 : [8 3 5 0] -1 -2 False False\n",
            "put_data    : [8 4 5 0] 2 -1 [8 3 5 0] False\n",
            "tensor([8, 3, 5, 0])\n",
            "tensor([8., 3., 5., 0.])\n",
            "end input\n",
            "input x tensor([8., 3., 5., 0.])\n",
            "x F.relu output tensor([0.0000e+00, 1.8575e+00, 2.3067e+00, 3.5458e+00, 2.3287e-01, 6.0079e-03,\n",
            "        0.0000e+00, 5.5233e-01, 0.0000e+00, 0.0000e+00, 3.8930e+00, 1.7208e+00,\n",
            "        2.2910e+00, 0.0000e+00, 1.0494e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 3.8444e+00, 0.0000e+00, 0.0000e+00, 3.8952e+00, 5.4569e+00,\n",
            "        3.9179e+00, 5.4728e+00, 2.0141e+00, 4.2478e+00, 0.0000e+00, 5.2996e+00,\n",
            "        0.0000e+00, 1.8929e+00, 1.4684e+00, 1.2782e+00, 3.1658e+00, 2.8539e+00,\n",
            "        2.3587e+00, 4.2732e+00, 4.6823e+00, 0.0000e+00, 9.5270e-01, 4.0840e+00,\n",
            "        0.0000e+00, 0.0000e+00, 4.3258e+00, 1.4540e+00, 0.0000e+00, 4.4085e+00,\n",
            "        0.0000e+00, 0.0000e+00, 4.6008e-01, 0.0000e+00, 5.6891e+00, 2.7175e+00,\n",
            "        0.0000e+00, 0.0000e+00, 3.8984e+00, 1.3988e-01, 4.2649e+00, 0.0000e+00,\n",
            "        4.8843e+00, 1.4452e+00, 4.2462e+00, 2.5407e+00, 1.8802e+00, 1.4608e+00,\n",
            "        0.0000e+00, 7.7597e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.9616e+00,\n",
            "        0.0000e+00, 1.8534e-01, 1.3722e+00, 0.0000e+00, 1.2059e+00, 0.0000e+00,\n",
            "        3.1724e+00, 3.5525e-01, 5.1096e+00, 2.4490e+00, 0.0000e+00, 5.0412e+00,\n",
            "        0.0000e+00, 4.9669e+00, 6.3119e-01, 5.8764e+00, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 2.2717e+00, 0.0000e+00, 4.3607e+00, 0.0000e+00, 4.7943e+00,\n",
            "        0.0000e+00, 8.5848e-01, 3.5774e+00, 0.0000e+00, 0.0000e+00, 4.0883e+00,\n",
            "        0.0000e+00, 5.3182e+00, 2.7115e+00, 0.0000e+00, 1.2083e-01, 0.0000e+00,\n",
            "        2.3199e+00, 4.6370e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.7278e+00,\n",
            "        4.0998e+00, 5.1389e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.3232e+00,\n",
            "        0.0000e+00, 3.2123e+00, 0.0000e+00, 5.1681e+00, 3.5568e+00, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 4.4981e+00, 3.7051e+00, 0.0000e+00, 2.0613e+00,\n",
            "        2.5419e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.0439e+00, 1.9412e+00,\n",
            "        2.9319e+00, 1.7743e+00, 0.0000e+00, 0.0000e+00, 3.4397e+00, 0.0000e+00,\n",
            "        9.2297e-01, 2.5210e+00, 0.0000e+00, 6.3551e+00, 3.4852e+00, 1.3621e+00,\n",
            "        0.0000e+00, 7.3035e+00, 0.0000e+00, 4.7985e+00, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 4.2713e+00, 1.6926e+00, 3.9963e+00, 0.0000e+00, 2.3046e+00,\n",
            "        0.0000e+00, 4.1649e+00, 2.7820e+00, 3.1599e-01, 3.3416e+00, 0.0000e+00,\n",
            "        3.7969e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.2478e+00, 0.0000e+00,\n",
            "        0.0000e+00, 3.1482e+00, 6.2524e+00, 0.0000e+00, 6.0298e+00, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 4.3015e-01, 0.0000e+00, 0.0000e+00,\n",
            "        2.2984e+00, 0.0000e+00, 2.1544e+00, 0.0000e+00, 0.0000e+00, 1.0755e+00,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 2.8910e-01, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 2.1806e+00, 3.8965e+00, 2.5160e+00, 0.0000e+00, 2.6522e+00,\n",
            "        4.7106e+00, 3.7396e+00, 0.0000e+00, 4.6722e+00, 0.0000e+00, 2.7999e+00,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 1.1180e+00, 0.0000e+00, 2.7605e+00,\n",
            "        0.0000e+00, 3.0171e+00, 1.5342e-01, 0.0000e+00, 3.5086e-01, 0.0000e+00,\n",
            "        2.4485e+00, 0.0000e+00, 0.0000e+00, 5.3459e+00, 6.8034e+00, 2.6944e+00,\n",
            "        4.9393e+00, 2.2619e+00, 3.3295e+00, 4.8414e+00, 4.8521e+00, 0.0000e+00,\n",
            "        1.4222e+00, 1.4412e+00, 0.0000e+00, 5.3377e+00, 0.0000e+00, 8.4676e+00,\n",
            "        2.0442e+00, 0.0000e+00, 1.3749e+00, 2.3057e+00, 0.0000e+00, 5.3148e+00,\n",
            "        0.0000e+00, 4.1954e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 7.0849e+00, 0.0000e+00, 6.1116e+00],\n",
            "       grad_fn=<ReluBackward0>)\n",
            "x fc_pi output tensor([ 47.5953, -30.6721,   4.1570, -33.2114], grad_fn=<AddBackward0>)\n",
            "x F.softmax(x, dim=softmax_dim) tensor([ 47.5953, -30.6721,   4.1570, -33.2114], grad_fn=<AddBackward0>)\n",
            "prob tensor([1.0000e+00, 1.0207e-34, 1.3646e-19, 8.0561e-36],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "step 데이터 : [7 3 5 0] -1 -3 False False\n",
            "put_data    : [8 3 5 0] 0 -1 [7 3 5 0] False\n",
            "step 데이터 : [7 2 5 0] -1 -4 False False\n",
            "put_data    : [7 3 5 0] 2 -1 [7 2 5 0] False\n",
            "tensor([7, 2, 5, 0])\n",
            "tensor([7., 2., 5., 0.])\n",
            "end input\n",
            "input x tensor([7., 2., 5., 0.])\n",
            "x F.relu output tensor([0.0000e+00, 1.1887e+00, 1.4982e+00, 3.2485e+00, 8.7142e-02, 2.1560e-01,\n",
            "        0.0000e+00, 2.2782e-01, 0.0000e+00, 0.0000e+00, 3.5986e+00, 1.0701e+00,\n",
            "        1.6683e+00, 0.0000e+00, 1.1832e+00, 0.0000e+00, 0.0000e+00, 2.7492e-02,\n",
            "        0.0000e+00, 3.1535e+00, 0.0000e+00, 0.0000e+00, 3.5169e+00, 4.8261e+00,\n",
            "        3.5669e+00, 4.9956e+00, 1.8204e+00, 3.5587e+00, 0.0000e+00, 5.1789e+00,\n",
            "        0.0000e+00, 1.1982e+00, 1.3126e+00, 7.4031e-01, 2.4257e+00, 2.5349e+00,\n",
            "        1.8154e+00, 4.1648e+00, 4.0251e+00, 0.0000e+00, 8.3152e-01, 3.7993e+00,\n",
            "        0.0000e+00, 0.0000e+00, 3.5686e+00, 1.2355e+00, 0.0000e+00, 3.9737e+00,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.0837e+00, 1.9260e+00,\n",
            "        0.0000e+00, 0.0000e+00, 3.5523e+00, 1.6028e-01, 3.6454e+00, 0.0000e+00,\n",
            "        4.0275e+00, 1.5074e+00, 4.1307e+00, 2.1757e+00, 1.6433e+00, 1.6902e+00,\n",
            "        0.0000e+00, 7.6996e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.4481e+00,\n",
            "        0.0000e+00, 3.3534e-01, 1.1287e+00, 0.0000e+00, 6.1046e-01, 0.0000e+00,\n",
            "        2.4800e+00, 4.5133e-01, 4.5156e+00, 2.3011e+00, 0.0000e+00, 4.4338e+00,\n",
            "        0.0000e+00, 4.6278e+00, 5.4245e-01, 4.9045e+00, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 1.8145e+00, 0.0000e+00, 3.4478e+00, 0.0000e+00, 4.5205e+00,\n",
            "        0.0000e+00, 9.0389e-01, 3.3734e+00, 0.0000e+00, 0.0000e+00, 3.1669e+00,\n",
            "        0.0000e+00, 4.6070e+00, 1.9819e+00, 0.0000e+00, 0.0000e+00, 6.5018e-02,\n",
            "        2.1178e+00, 3.9300e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.1728e+00,\n",
            "        3.5975e+00, 4.5111e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.7834e+00,\n",
            "        0.0000e+00, 2.9521e+00, 0.0000e+00, 4.7147e+00, 3.4642e+00, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 3.7408e+00, 2.7215e+00, 0.0000e+00, 1.6559e+00,\n",
            "        2.1354e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.7006e+00, 1.7445e+00,\n",
            "        2.1906e+00, 2.0171e+00, 1.8994e-03, 0.0000e+00, 2.9569e+00, 0.0000e+00,\n",
            "        6.3024e-01, 2.2883e+00, 0.0000e+00, 5.3898e+00, 3.0248e+00, 1.1861e+00,\n",
            "        0.0000e+00, 6.5162e+00, 0.0000e+00, 4.2450e+00, 1.9351e-01, 0.0000e+00,\n",
            "        0.0000e+00, 3.5022e+00, 1.3064e+00, 2.9472e+00, 0.0000e+00, 2.0478e+00,\n",
            "        0.0000e+00, 3.8286e+00, 2.3232e+00, 5.9201e-01, 2.8614e+00, 0.0000e+00,\n",
            "        2.8380e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.5025e+00, 0.0000e+00,\n",
            "        0.0000e+00, 2.3963e+00, 5.3565e+00, 1.9707e-01, 5.3250e+00, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 8.6508e-01, 0.0000e+00, 0.0000e+00,\n",
            "        2.1346e+00, 0.0000e+00, 1.6208e+00, 0.0000e+00, 0.0000e+00, 1.0064e+00,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 7.0509e-01, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 1.7756e+00, 3.6968e+00, 1.7559e+00, 0.0000e+00, 2.0547e+00,\n",
            "        3.7893e+00, 3.3945e+00, 0.0000e+00, 4.5942e+00, 0.0000e+00, 2.8339e+00,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 9.1393e-01, 0.0000e+00, 2.4294e+00,\n",
            "        0.0000e+00, 2.5617e+00, 3.4887e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        2.4883e+00, 0.0000e+00, 0.0000e+00, 4.9366e+00, 6.0672e+00, 2.1333e+00,\n",
            "        4.5074e+00, 2.0470e+00, 2.3685e+00, 4.4847e+00, 3.9493e+00, 0.0000e+00,\n",
            "        1.6811e+00, 1.4434e+00, 0.0000e+00, 4.6726e+00, 0.0000e+00, 7.6140e+00,\n",
            "        1.7406e+00, 0.0000e+00, 1.1483e+00, 2.2218e+00, 0.0000e+00, 4.7242e+00,\n",
            "        0.0000e+00, 4.0540e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 6.3111e+00, 0.0000e+00, 5.1036e+00],\n",
            "       grad_fn=<ReluBackward0>)\n",
            "x fc_pi output tensor([ 40.6082, -26.3147,   3.8962, -29.1731], grad_fn=<AddBackward0>)\n",
            "x F.softmax(x, dim=softmax_dim) tensor([ 40.6082, -26.3147,   3.8962, -29.1731], grad_fn=<AddBackward0>)\n",
            "prob tensor([1.0000e+00, 8.6243e-30, 1.1381e-16, 4.9469e-31],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "step 데이터 : [6 2 5 0] -100 -104 True False\n",
            "put_data    : [7 2 5 0] 0 -100 [6 2 5 0] True\n",
            "input x tensor([[9., 4., 5., 0.],\n",
            "        [8., 4., 5., 0.],\n",
            "        [8., 3., 5., 0.],\n",
            "        [7., 3., 5., 0.],\n",
            "        [7., 2., 5., 0.]])\n",
            "x F.relu output tensor([[0.0000, 2.5264, 3.1151,  ..., 7.8586, 0.0000, 7.1197],\n",
            "        [0.0000, 2.1654, 2.7735,  ..., 7.6419, 0.0000, 6.6339],\n",
            "        [0.0000, 1.8575, 2.3067,  ..., 7.0849, 0.0000, 6.1116],\n",
            "        [0.0000, 1.4966, 1.9651,  ..., 6.8681, 0.0000, 5.6259],\n",
            "        [0.0000, 1.1887, 1.4982,  ..., 6.3111, 0.0000, 5.1036]],\n",
            "       grad_fn=<ReluBackward0>)\n",
            "x fc_pi output tensor([[ 54.6617, -35.0465,   4.4017, -37.2614],\n",
            "        [ 50.4516, -32.4912,   4.5268, -35.0034],\n",
            "        [ 47.5953, -30.6721,   4.1570, -33.2114],\n",
            "        [ 43.3908, -28.1245,   4.2931, -30.9631],\n",
            "        [ 40.6082, -26.3147,   3.8962, -29.1731]], grad_fn=<AddmmBackward0>)\n",
            "x F.softmax(x, dim=softmax_dim) tensor([[ 54.6617, -35.0465,   4.4017, -37.2614],\n",
            "        [ 50.4516, -32.4912,   4.5268, -35.0034],\n",
            "        [ 47.5953, -30.6721,   4.1570, -33.2114],\n",
            "        [ 43.3908, -28.1245,   4.2931, -30.9631],\n",
            "        [ 40.6082, -26.3147,   3.8962, -29.1731]], grad_fn=<AddmmBackward0>)\n",
            "prob tensor([[1.0000e+00, 1.0971e-39, 1.4873e-22, 1.1977e-40],\n",
            "        [1.0000e+00, 9.5148e-37, 1.1353e-20, 7.7156e-38],\n",
            "        [1.0000e+00, 1.0207e-34, 1.3646e-19, 8.0562e-36],\n",
            "        [1.0000e+00, 8.7362e-32, 1.0473e-17, 5.1110e-33],\n",
            "        [1.0000e+00, 8.6243e-30, 1.1381e-16, 4.9469e-31]],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "\n",
            "\n",
            "▶▶▶ 3826  : max cum reward :  1887  epsilon = 0.6173900000000422\n",
            "\n",
            "\n",
            "▶▶▶3827번째 에피소드 시작, env 초기화 완료.\n",
            "가져와야 할 아이템 : ['A', 'C', 'D', 'K', 'L', 'P']\n",
            "\n",
            "현재 state         :  [9 4 5 0]\n",
            "step 데이터 : [8 4 5 0] -1 -1 False False\n",
            "put_data    : [9 4 5 0] 0 -1 [8 4 5 0] False\n",
            "step 데이터 : [8 3 5 0] -1 -2 False False\n",
            "put_data    : [8 4 5 0] 2 -1 [8 3 5 0] False\n",
            "step 데이터 : [8 2 5 0] -1 -3 False False\n",
            "put_data    : [8 3 5 0] 2 -1 [8 2 5 0] False\n",
            "tensor([8, 2, 5, 0])\n",
            "tensor([8., 2., 5., 0.])\n",
            "end input\n",
            "input x tensor([8., 2., 5., 0.])\n",
            "x F.relu output tensor([0.0000, 1.5480, 1.8386, 3.8768, 0.0000, 0.4314, 0.0000, 0.3551, 0.0000,\n",
            "        0.0000, 4.1554, 1.4171, 1.7723, 0.0000, 0.9427, 0.0000, 0.0000, 0.0634,\n",
            "        0.0000, 3.3899, 0.0000, 0.0000, 3.7798, 5.4569, 3.7682, 5.3117, 2.3699,\n",
            "        4.0992, 0.0000, 5.5254, 0.0000, 1.4676, 1.3951, 1.0225, 2.5970, 2.6200,\n",
            "        2.4018, 4.4477, 4.4774, 0.0000, 0.6673, 4.1939, 0.0000, 0.0000, 3.8357,\n",
            "        1.2993, 0.0000, 4.3135, 0.0000, 0.0000, 0.1082, 0.0000, 5.4168, 2.3807,\n",
            "        0.0000, 0.0000, 3.8235, 0.2107, 3.8176, 0.0000, 4.4041, 1.2056, 4.4752,\n",
            "        2.2946, 2.0203, 1.6662, 0.0000, 0.5584, 0.0000, 0.0000, 0.0000, 1.8140,\n",
            "        0.0000, 0.6915, 1.2245, 0.0000, 0.6142, 0.0000, 2.9643, 0.4695, 4.7075,\n",
            "        2.2301, 0.0000, 4.9635, 0.0000, 5.0201, 0.3744, 5.3930, 0.0000, 0.0000,\n",
            "        0.0000, 2.2508, 0.0000, 3.8799, 0.0000, 4.9602, 0.0000, 1.1230, 3.7498,\n",
            "        0.0000, 0.0000, 3.6986, 0.0000, 5.0409, 2.1747, 0.0000, 0.0000, 0.0000,\n",
            "        2.0092, 4.1593, 0.0000, 0.0000, 0.0000, 1.3863, 3.6008, 4.6772, 0.0000,\n",
            "        0.0000, 0.0000, 1.8444, 0.0000, 2.9135, 0.0000, 4.8471, 3.5124, 0.0000,\n",
            "        0.0000, 0.0000, 4.0966, 3.1426, 0.0000, 1.7656, 2.3573, 0.0000, 0.0000,\n",
            "        0.0000, 3.0832, 2.0765, 2.4806, 2.2229, 0.0000, 0.0000, 3.0477, 0.0000,\n",
            "        0.6308, 2.6541, 0.0000, 5.8868, 3.1862, 1.4841, 0.0000, 6.8435, 0.0000,\n",
            "        4.8058, 0.1887, 0.0000, 0.0000, 3.8438, 1.2997, 3.5243, 0.0000, 2.4641,\n",
            "        0.0000, 4.1835, 2.2125, 0.3954, 2.9387, 0.0000, 3.2370, 0.0000, 0.0000,\n",
            "        0.0000, 3.7187, 0.0000, 0.0000, 2.6993, 5.8168, 0.0000, 5.8461, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.9098, 0.0000, 0.0000, 2.2600, 0.0000, 1.8449,\n",
            "        0.0000, 0.0000, 1.4583, 0.0000, 0.0000, 0.0000, 0.5640, 0.0000, 0.0000,\n",
            "        0.0000, 2.1728, 4.0396, 2.0417, 0.0000, 2.2758, 4.2335, 3.4068, 0.0000,\n",
            "        4.8413, 0.0000, 2.8220, 0.0000, 0.0000, 0.0000, 0.8109, 0.0000, 2.5222,\n",
            "        0.0000, 2.6302, 0.1906, 0.0000, 0.0267, 0.0000, 2.4843, 0.0000, 0.0000,\n",
            "        5.4922, 6.4997, 2.4289, 5.0715, 2.4266, 2.8101, 4.8842, 4.3400, 0.0000,\n",
            "        1.5999, 1.2810, 0.0000, 4.9494, 0.0000, 8.1493, 1.9062, 0.0000, 1.4713,\n",
            "        2.4341, 0.0000, 4.8651, 0.0000, 4.4728, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 6.5266, 0.0000, 5.5881], grad_fn=<ReluBackward0>)\n",
            "x fc_pi output tensor([ 44.7569, -28.8381,   3.7729, -31.4180], grad_fn=<AddBackward0>)\n",
            "x F.softmax(x, dim=softmax_dim) tensor([ 44.7569, -28.8381,   3.7729, -31.4180], grad_fn=<AddBackward0>)\n",
            "prob tensor([1.0000e+00, 1.0917e-32, 1.5882e-18, 8.2734e-34],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "step 데이터 : [7 2 5 0] -1 -4 False False\n",
            "put_data    : [8 2 5 0] 0 -1 [7 2 5 0] False\n",
            "step 데이터 : [6 2 5 0] -100 -104 True False\n",
            "put_data    : [7 2 5 0] 0 -100 [6 2 5 0] True\n",
            "input x tensor([[9., 4., 5., 0.],\n",
            "        [8., 4., 5., 0.],\n",
            "        [8., 3., 5., 0.],\n",
            "        [8., 2., 5., 0.],\n",
            "        [7., 2., 5., 0.]])\n",
            "x F.relu output tensor([[0.0000, 2.5244, 3.1136,  ..., 7.8571, 0.0000, 7.1182],\n",
            "        [0.0000, 2.1636, 2.7721,  ..., 7.6405, 0.0000, 6.6326],\n",
            "        [0.0000, 1.8558, 2.3054,  ..., 7.0835, 0.0000, 6.1104],\n",
            "        [0.0000, 1.5480, 1.8386,  ..., 6.5266, 0.0000, 5.5881],\n",
            "        [0.0000, 1.1872, 1.4971,  ..., 6.3099, 0.0000, 5.1025]],\n",
            "       grad_fn=<ReluBackward0>)\n",
            "x fc_pi output tensor([[ 54.6101, -34.9808,   4.4117, -37.2578],\n",
            "        [ 50.4036, -32.4296,   4.5360, -34.9998],\n",
            "        [ 47.5505, -30.6144,   4.1657, -33.2084],\n",
            "        [ 44.7568, -28.8381,   3.7729, -31.4180],\n",
            "        [ 40.5702, -26.2649,   3.9036, -29.1706]], grad_fn=<AddmmBackward0>)\n",
            "x F.softmax(x, dim=softmax_dim) tensor([[ 54.6101, -34.9808,   4.4117, -37.2578],\n",
            "        [ 50.4036, -32.4296,   4.5360, -34.9998],\n",
            "        [ 47.5505, -30.6144,   4.1657, -33.2084],\n",
            "        [ 44.7568, -28.8381,   3.7729, -31.4180],\n",
            "        [ 40.5702, -26.2649,   3.9036, -29.1706]], grad_fn=<AddmmBackward0>)\n",
            "prob tensor([[1.0000e+00, 1.2335e-39, 1.5816e-22, 1.2656e-40],\n",
            "        [1.0000e+00, 1.0616e-36, 1.2022e-20, 8.1237e-38],\n",
            "        [1.0000e+00, 1.1308e-34, 1.4395e-19, 8.4503e-36],\n",
            "        [1.0000e+00, 1.0917e-32, 1.5882e-18, 8.2734e-34],\n",
            "        [1.0000e+00, 9.4168e-30, 1.1910e-16, 5.1517e-31]],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "\n",
            "\n",
            "▶▶▶ 3827  : max cum reward :  1887  epsilon = 0.6172900000000422\n",
            "\n",
            "\n",
            "▶▶▶3828번째 에피소드 시작, env 초기화 완료.\n",
            "가져와야 할 아이템 : ['F', 'I', 'K', 'L', 'M', 'O', 'Q']\n",
            "\n",
            "현재 state         :  [9 4 0 1]\n",
            "step 데이터 : [10  4  0  1] -100 -100 True False\n",
            "put_data    : [9 4 0 1] 1 -100 [10  4  0  1] True\n",
            "input x tensor([[9., 4., 0., 1.]])\n",
            "x F.relu output tensor([[0.0000e+00, 3.9292e+00, 4.6189e+00, 4.7951e+00, 0.0000e+00, 2.6407e-01,\n",
            "         0.0000e+00, 2.4297e+00, 0.0000e+00, 0.0000e+00, 4.2019e+00, 4.1789e+00,\n",
            "         2.4809e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "         1.5102e-01, 3.9251e+00, 0.0000e+00, 0.0000e+00, 2.8983e+00, 5.8284e+00,\n",
            "         2.5276e+00, 3.7255e+00, 4.2476e+00, 5.6683e+00, 0.0000e+00, 2.9467e+00,\n",
            "         0.0000e+00, 3.3214e+00, 1.6177e+00, 4.5186e+00, 4.0181e+00, 2.4430e+00,\n",
            "         4.8826e+00, 1.5629e+00, 5.0640e+00, 0.0000e+00, 0.0000e+00, 2.9558e+00,\n",
            "         0.0000e+00, 0.0000e+00, 3.5058e+00, 1.8856e+00, 0.0000e+00, 2.6898e+00,\n",
            "         0.0000e+00, 0.0000e+00, 3.1986e+00, 0.0000e+00, 3.6600e+00, 4.7632e+00,\n",
            "         0.0000e+00, 0.0000e+00, 3.1050e+00, 3.5205e-02, 2.8318e+00, 0.0000e+00,\n",
            "         5.9701e+00, 0.0000e+00, 1.9004e+00, 2.1080e+00, 2.8435e+00, 0.0000e+00,\n",
            "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.8398e+00,\n",
            "         0.0000e+00, 1.1444e+00, 1.7994e+00, 0.0000e+00, 1.8920e+00, 0.0000e+00,\n",
            "         5.1786e+00, 0.0000e+00, 3.5790e+00, 4.0599e-01, 0.0000e+00, 4.7008e+00,\n",
            "         0.0000e+00, 2.9746e+00, 0.0000e+00, 6.3968e+00, 0.0000e+00, 0.0000e+00,\n",
            "         0.0000e+00, 4.0251e+00, 0.0000e+00, 6.4598e+00, 4.7828e-01, 2.9504e+00,\n",
            "         7.2560e-01, 1.0989e+00, 3.2008e+00, 1.4561e-01, 8.1411e-01, 5.9413e+00,\n",
            "         4.6099e-01, 5.6709e+00, 3.8720e+00, 0.0000e+00, 2.0553e+00, 0.0000e+00,\n",
            "         2.1137e-01, 4.7510e+00, 0.0000e+00, 1.5486e+00, 0.0000e+00, 3.5492e+00,\n",
            "         2.5649e+00, 4.0620e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.2740e+00,\n",
            "         0.0000e+00, 1.3904e+00, 0.0000e+00, 2.7358e+00, 1.1375e+00, 0.0000e+00,\n",
            "         0.0000e+00, 0.0000e+00, 5.6664e+00, 5.9430e+00, 1.8581e-03, 1.6042e+00,\n",
            "         2.8742e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.4222e+00, 2.0258e+00,\n",
            "         3.7797e+00, 9.5371e-01, 0.0000e+00, 0.0000e+00, 2.9710e+00, 0.0000e+00,\n",
            "         1.5218e+00, 2.7952e+00, 0.0000e+00, 6.3637e+00, 2.6297e+00, 1.6556e+00,\n",
            "         0.0000e+00, 5.1525e+00, 6.8078e-01, 5.5135e+00, 0.0000e+00, 0.0000e+00,\n",
            "         0.0000e+00, 4.1249e+00, 1.5978e+00, 7.3751e+00, 0.0000e+00, 3.0557e+00,\n",
            "         0.0000e+00, 3.5580e+00, 1.7123e+00, 0.0000e+00, 2.4845e+00, 0.0000e+00,\n",
            "         6.0289e+00, 0.0000e+00, 1.9293e+00, 0.0000e+00, 4.1282e+00, 0.0000e+00,\n",
            "         0.0000e+00, 4.4838e+00, 6.3228e+00, 0.0000e+00, 5.5896e+00, 0.0000e+00,\n",
            "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "         1.1782e+00, 0.0000e+00, 3.3272e+00, 0.0000e+00, 0.0000e+00, 2.5587e+00,\n",
            "         0.0000e+00, 0.0000e+00, 9.9535e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "         0.0000e+00, 4.0914e+00, 2.5483e+00, 3.9321e+00, 0.0000e+00, 3.0096e+00,\n",
            "         6.4622e+00, 1.0381e+00, 1.0962e+00, 2.3886e+00, 0.0000e+00, 3.6628e-01,\n",
            "         0.0000e+00, 0.0000e+00, 1.8653e+00, 4.6574e-01, 0.0000e+00, 1.8817e+00,\n",
            "         0.0000e+00, 2.3319e+00, 0.0000e+00, 1.8900e+00, 3.2455e+00, 0.0000e+00,\n",
            "         1.1772e-01, 0.0000e+00, 0.0000e+00, 4.6425e+00, 4.7510e+00, 3.9754e+00,\n",
            "         4.4918e+00, 2.5262e+00, 6.0874e+00, 3.0447e+00, 5.0937e+00, 0.0000e+00,\n",
            "         0.0000e+00, 0.0000e+00, 0.0000e+00, 4.2221e+00, 0.0000e+00, 6.2410e+00,\n",
            "         1.7089e+00, 0.0000e+00, 3.0435e+00, 1.4752e+00, 5.4232e-01, 3.4224e+00,\n",
            "         0.0000e+00, 2.2048e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "         0.0000e+00, 4.9494e+00, 0.0000e+00, 6.9613e+00]],\n",
            "       grad_fn=<ReluBackward0>)\n",
            "x fc_pi output tensor([[ 50.7788, -31.4412,   0.6849, -28.8949]], grad_fn=<AddmmBackward0>)\n",
            "x F.softmax(x, dim=softmax_dim) tensor([[ 50.7788, -31.4412,   0.6849, -28.8949]], grad_fn=<AddmmBackward0>)\n",
            "prob tensor([[1.0000e+00, 1.9603e-36, 1.7559e-22, 2.5013e-35]],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "\n",
            "\n",
            "▶▶▶ 3828  : max cum reward :  1887  epsilon = 0.6171900000000422\n",
            "\n",
            "\n",
            "▶▶▶3829번째 에피소드 시작, env 초기화 완료.\n",
            "가져와야 할 아이템 : ['G', 'I', 'J', 'K', 'L', 'O', 'Q']\n",
            "\n",
            "현재 state         :  [9 4 0 2]\n",
            "step 데이터 : [8 4 0 2] -1 -1 False False\n",
            "put_data    : [9 4 0 2] 0 -1 [8 4 0 2] False\n",
            "step 데이터 : [9 4 0 2] -1 -2 False False\n",
            "put_data    : [8 4 0 2] 1 -1 [9 4 0 2] False\n",
            "step 데이터 : [10  4  0  2] -100 -102 True False\n",
            "put_data    : [9 4 0 2] 1 -100 [10  4  0  2] True\n",
            "input x tensor([[9., 4., 0., 2.],\n",
            "        [8., 4., 0., 2.],\n",
            "        [9., 4., 0., 2.]])\n",
            "x F.relu output tensor([[0.0000, 3.7413, 4.6087, 5.1238, 0.0000, 0.0000, 0.0000, 2.6530, 0.0000,\n",
            "         0.0000, 4.4345, 4.3382, 2.2918, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.5715, 4.1628, 0.0000, 0.0000, 2.5720, 6.0005, 3.0029, 3.3856, 4.4151,\n",
            "         5.8704, 0.0000, 3.2863, 0.0000, 2.8647, 2.0468, 5.0136, 3.6279, 2.6369,\n",
            "         4.8076, 1.5360, 5.3509, 0.0000, 0.0000, 2.6362, 0.0000, 0.0000, 3.0853,\n",
            "         2.2135, 0.0000, 2.3054, 0.0000, 0.0000, 3.5379, 0.0000, 3.4637, 4.2958,\n",
            "         0.0000, 0.0000, 3.5218, 0.0000, 2.5135, 0.0000, 6.4178, 0.0000, 1.7836,\n",
            "         1.9460, 2.8406, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 4.1046,\n",
            "         0.0000, 0.9686, 1.9395, 0.0000, 1.5111, 0.0000, 5.3020, 0.0000, 3.4898,\n",
            "         0.5648, 0.0000, 4.3527, 0.0000, 2.8458, 0.0000, 6.5020, 0.0000, 0.0000,\n",
            "         0.0000, 4.3482, 0.0000, 6.9619, 0.8346, 2.9666, 1.0997, 0.7417, 3.4470,\n",
            "         0.0000, 1.1362, 5.6284, 0.1440, 5.9190, 3.8884, 0.0000, 2.1868, 0.0000,\n",
            "         0.4555, 5.1138, 0.0000, 1.8797, 0.0000, 3.4706, 2.7171, 4.4299, 0.0000,\n",
            "         0.0000, 0.0000, 3.4782, 0.0000, 1.3633, 0.0000, 2.4513, 1.0876, 0.0000,\n",
            "         0.0000, 0.0000, 5.9847, 5.8525, 0.0941, 1.2685, 2.6544, 0.0000, 0.0000,\n",
            "         0.0000, 3.1948, 1.8113, 3.4195, 1.3877, 0.0000, 0.0000, 3.4419, 0.0000,\n",
            "         1.3566, 2.4657, 0.0000, 6.0987, 2.7956, 1.2695, 0.0000, 5.0746, 0.3879,\n",
            "         5.6500, 0.0000, 0.0000, 0.0000, 3.7631, 1.6990, 7.8222, 0.0000, 2.8960,\n",
            "         0.0000, 4.0734, 1.5469, 0.0000, 2.9702, 0.0000, 5.7710, 0.0000, 1.9718,\n",
            "         0.0000, 4.2626, 0.1510, 0.0000, 4.7861, 6.2006, 0.0000, 5.6697, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.4005, 0.0000, 3.0765,\n",
            "         0.0000, 0.0000, 2.3190, 0.0000, 0.0000, 1.0943, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 4.2095, 2.9194, 3.5598, 0.0000, 2.7779, 6.8856, 0.6194, 1.5119,\n",
            "         2.6453, 0.0000, 0.5252, 0.0000, 0.0000, 2.1386, 0.2324, 0.0000, 2.0559,\n",
            "         0.0000, 2.0966, 0.0000, 1.8494, 3.5256, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         4.7820, 4.7641, 4.3466, 4.1779, 2.1887, 6.1808, 2.7283, 4.7424, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 3.8102, 0.0000, 5.9443, 1.2626, 0.0000, 3.2329,\n",
            "         1.4848, 0.8916, 3.8047, 0.0000, 2.0345, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 5.1301, 0.0000, 7.3726],\n",
            "        [0.0000, 3.3806, 4.2673, 4.4948, 0.0000, 0.0000, 0.0000, 2.5246, 0.0000,\n",
            "         0.0000, 3.8768, 3.9901, 2.1871, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.5705, 3.9252, 0.0000, 0.0000, 2.3086, 5.3687, 2.8008, 3.0683, 3.8644,\n",
            "         5.3288, 0.0000, 2.9396, 0.0000, 2.5944, 1.9629, 4.7303, 3.4555, 2.5508,\n",
            "         4.2204, 1.2525, 4.8978, 0.0000, 0.0000, 2.2406, 0.0000, 0.0000, 2.8176,\n",
            "         2.1489, 0.0000, 1.9646, 0.0000, 0.0000, 3.4153, 0.0000, 3.1297, 3.8404,\n",
            "         0.0000, 0.0000, 3.2499, 0.0000, 2.3404, 0.0000, 6.0399, 0.0000, 1.4386,\n",
            "         1.8263, 2.4628, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 3.7376,\n",
            "         0.0000, 0.6117, 1.8424, 0.0000, 1.5060, 0.0000, 4.8163, 0.0000, 3.2973,\n",
            "         0.6360, 0.0000, 3.8218, 0.0000, 2.4533, 0.0000, 6.0128, 0.0000, 0.0000,\n",
            "         0.0000, 3.9111, 0.0000, 6.5288, 0.6348, 2.5256, 1.1806, 0.5218, 3.0699,\n",
            "         0.0000, 1.2651, 5.0958, 0.1260, 5.4841, 3.6946, 0.0000, 2.0729, 0.0000,\n",
            "         0.5635, 4.8842, 0.0000, 1.6528, 0.0000, 3.2561, 2.7130, 4.2627, 0.0000,\n",
            "         0.0000, 0.0000, 3.4161, 0.0524, 1.4009, 0.0000, 2.3186, 1.0385, 0.0000,\n",
            "         0.0000, 0.0000, 5.6279, 5.4304, 0.1967, 1.1577, 2.4316, 0.0000, 0.0000,\n",
            "         0.0000, 2.8112, 1.4786, 3.1285, 1.1809, 0.0000, 0.0000, 3.3500, 0.0000,\n",
            "         1.3552, 2.0988, 0.0000, 5.6006, 2.6332, 0.9709, 0.0000, 4.7469, 0.5320,\n",
            "         5.0880, 0.0000, 0.0000, 0.0000, 3.4204, 1.7047, 7.2441, 0.0000, 2.4791,\n",
            "         0.0000, 3.7176, 1.6564, 0.0000, 2.8918, 0.0000, 5.3711, 0.0000, 1.8386,\n",
            "         0.0000, 4.0451, 0.2266, 0.0000, 4.4819, 5.7393, 0.0000, 5.1475, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.2748, 0.0000, 2.8512,\n",
            "         0.0000, 0.0000, 1.8661, 0.0000, 0.0000, 0.9261, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 3.8112, 2.5760, 3.2730, 0.0000, 2.5558, 6.4403, 0.6072, 1.4378,\n",
            "         2.3971, 0.0000, 0.5362, 0.0000, 0.0000, 2.1497, 0.3348, 0.0000, 1.9626,\n",
            "         0.0000, 2.0270, 0.0000, 1.8637, 3.3998, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         4.2255, 4.3304, 4.0500, 3.6125, 1.8083, 5.7387, 2.3278, 4.3507, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 3.5325, 0.0000, 5.4083, 1.0961, 0.0000, 2.9093,\n",
            "         1.2718, 0.7190, 3.6630, 0.0000, 1.6146, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 4.9136, 0.0000, 6.8870],\n",
            "        [0.0000, 3.7413, 4.6087, 5.1238, 0.0000, 0.0000, 0.0000, 2.6530, 0.0000,\n",
            "         0.0000, 4.4345, 4.3382, 2.2918, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.5715, 4.1628, 0.0000, 0.0000, 2.5720, 6.0005, 3.0029, 3.3856, 4.4151,\n",
            "         5.8704, 0.0000, 3.2863, 0.0000, 2.8647, 2.0468, 5.0136, 3.6279, 2.6369,\n",
            "         4.8076, 1.5360, 5.3509, 0.0000, 0.0000, 2.6362, 0.0000, 0.0000, 3.0853,\n",
            "         2.2135, 0.0000, 2.3054, 0.0000, 0.0000, 3.5379, 0.0000, 3.4637, 4.2958,\n",
            "         0.0000, 0.0000, 3.5218, 0.0000, 2.5135, 0.0000, 6.4178, 0.0000, 1.7836,\n",
            "         1.9460, 2.8406, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 4.1046,\n",
            "         0.0000, 0.9686, 1.9395, 0.0000, 1.5111, 0.0000, 5.3020, 0.0000, 3.4898,\n",
            "         0.5648, 0.0000, 4.3527, 0.0000, 2.8458, 0.0000, 6.5020, 0.0000, 0.0000,\n",
            "         0.0000, 4.3482, 0.0000, 6.9619, 0.8346, 2.9666, 1.0997, 0.7417, 3.4470,\n",
            "         0.0000, 1.1362, 5.6284, 0.1440, 5.9190, 3.8884, 0.0000, 2.1868, 0.0000,\n",
            "         0.4555, 5.1138, 0.0000, 1.8797, 0.0000, 3.4706, 2.7171, 4.4299, 0.0000,\n",
            "         0.0000, 0.0000, 3.4782, 0.0000, 1.3633, 0.0000, 2.4513, 1.0876, 0.0000,\n",
            "         0.0000, 0.0000, 5.9847, 5.8525, 0.0941, 1.2685, 2.6544, 0.0000, 0.0000,\n",
            "         0.0000, 3.1948, 1.8113, 3.4195, 1.3877, 0.0000, 0.0000, 3.4419, 0.0000,\n",
            "         1.3566, 2.4657, 0.0000, 6.0987, 2.7956, 1.2695, 0.0000, 5.0746, 0.3879,\n",
            "         5.6500, 0.0000, 0.0000, 0.0000, 3.7631, 1.6990, 7.8222, 0.0000, 2.8960,\n",
            "         0.0000, 4.0734, 1.5469, 0.0000, 2.9702, 0.0000, 5.7710, 0.0000, 1.9718,\n",
            "         0.0000, 4.2626, 0.1510, 0.0000, 4.7861, 6.2006, 0.0000, 5.6697, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.4005, 0.0000, 3.0765,\n",
            "         0.0000, 0.0000, 2.3190, 0.0000, 0.0000, 1.0943, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 4.2095, 2.9194, 3.5598, 0.0000, 2.7779, 6.8856, 0.6194, 1.5119,\n",
            "         2.6453, 0.0000, 0.5252, 0.0000, 0.0000, 2.1386, 0.2324, 0.0000, 2.0559,\n",
            "         0.0000, 2.0966, 0.0000, 1.8494, 3.5256, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         4.7820, 4.7641, 4.3466, 4.1779, 2.1887, 6.1808, 2.7283, 4.7424, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 3.8102, 0.0000, 5.9443, 1.2626, 0.0000, 3.2329,\n",
            "         1.4848, 0.8916, 3.8047, 0.0000, 2.0345, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 5.1301, 0.0000, 7.3726]], grad_fn=<ReluBackward0>)\n",
            "x fc_pi output tensor([[ 50.6746, -31.2574,   0.5887, -28.5705],\n",
            "        [ 46.4620, -28.6737,   0.6824, -26.1859],\n",
            "        [ 50.6746, -31.2574,   0.5887, -28.5705]], grad_fn=<AddmmBackward0>)\n",
            "x F.softmax(x, dim=softmax_dim) tensor([[ 50.6746, -31.2574,   0.5887, -28.5705],\n",
            "        [ 46.4620, -28.6737,   0.6824, -26.1859],\n",
            "        [ 50.6746, -31.2574,   0.5887, -28.5705]], grad_fn=<AddmmBackward0>)\n",
            "prob tensor([[1.0000e+00, 2.6144e-36, 1.7700e-22, 3.8397e-35],\n",
            "        [1.0000e+00, 2.3387e-33, 1.3127e-20, 2.8146e-32],\n",
            "        [1.0000e+00, 2.6144e-36, 1.7700e-22, 3.8397e-35]],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "\n",
            "\n",
            "▶▶▶ 3829  : max cum reward :  1887  epsilon = 0.6170900000000422\n",
            "\n",
            "\n",
            "▶▶▶3830번째 에피소드 시작, env 초기화 완료.\n",
            "가져와야 할 아이템 : ['A', 'D', 'H', 'I', 'J', 'L', 'M']\n",
            "\n",
            "현재 state         :  [9 4 5 0]\n",
            "tensor([9, 4, 5, 0])\n",
            "tensor([9., 4., 5., 0.])\n",
            "end input\n",
            "input x tensor([9., 4., 5., 0.])\n",
            "x F.relu output tensor([0.0000, 2.5212, 3.1114, 3.8408, 0.3819, 0.0000, 0.0000, 0.8720, 0.0000,\n",
            "        0.0000, 4.1839, 2.3669, 2.9109, 0.0000, 0.9180, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 4.5308, 0.0000, 0.0000, 4.2718, 6.0843, 4.2657, 5.9461, 2.2040,\n",
            "        4.9328, 0.0000, 5.4202, 0.0000, 2.5841, 1.6191, 1.8114, 3.9020, 3.1691,\n",
            "        2.8993, 4.3795, 5.3366, 0.0000, 1.0777, 4.3655, 0.0000, 0.0000, 5.0807,\n",
            "        1.6702, 0.0000, 4.8394, 0.0000, 0.0000, 0.9278, 0.0000, 6.2910, 3.5062,\n",
            "        0.0000, 0.0000, 4.2416, 0.1178, 4.8813, 0.0000, 5.7368, 1.3827, 4.3594,\n",
            "        2.9027, 2.1141, 1.2274, 0.0000, 0.7790, 0.0000, 0.0000, 0.0000, 2.4713,\n",
            "        0.0000, 0.0328, 1.6110, 0.0000, 1.7974, 0.0000, 3.8600, 0.2633, 5.7012,\n",
            "        2.5982, 0.0000, 5.6439, 0.0000, 5.3053, 0.7253, 6.8454, 0.0000, 0.0000,\n",
            "        0.0000, 2.7257, 0.0000, 5.2700, 0.0000, 5.0638, 0.0000, 0.8099, 3.7786,\n",
            "        0.0000, 0.0000, 5.0062, 0.0000, 6.0260, 3.4373, 0.0000, 0.4882, 0.0000,\n",
            "        2.5198, 5.3434, 0.0000, 0.0000, 0.0000, 2.2789, 4.5991, 5.7627, 0.0000,\n",
            "        0.0000, 0.0000, 2.8590, 0.0000, 3.4690, 0.0000, 5.6208, 3.6461, 0.0000,\n",
            "        0.0000, 0.0000, 5.2515, 4.6852, 0.0000, 2.4628, 2.9452, 0.0000, 0.0000,\n",
            "        0.0000, 3.3833, 2.1354, 3.6697, 1.5283, 0.0000, 0.0000, 3.9192, 0.0000,\n",
            "        1.2125, 2.7498, 0.0000, 7.3170, 3.9421, 1.5358, 0.0000, 8.0890, 0.0000,\n",
            "        5.3474, 0.0000, 0.0000, 0.0000, 5.0365, 2.0753, 5.0417, 0.0000, 2.5593,\n",
            "        0.0000, 4.4979, 3.2371, 0.0412, 3.8178, 0.0000, 4.7529, 0.0000, 0.0887,\n",
            "        0.0000, 4.9882, 0.0000, 0.0000, 3.8957, 7.1444, 0.0000, 6.7304, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 2.4618, 0.0000, 2.6839,\n",
            "        0.0000, 0.0000, 1.1409, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 2.5816, 4.0937, 3.2728, 0.0000, 3.2465, 5.6278, 4.0856, 0.0000,\n",
            "        4.7468, 0.0000, 2.7627, 0.0000, 0.0000, 0.0000, 1.3203, 0.0000, 3.0900,\n",
            "        0.0000, 3.4684, 0.0000, 0.4157, 0.7956, 0.0000, 2.4103, 0.0000, 0.0000,\n",
            "        5.7517, 7.5359, 3.2518, 5.3667, 2.4741, 4.2886, 5.1951, 5.7516, 0.0000,\n",
            "        1.1600, 1.4333, 0.0000, 5.9995, 0.0000, 9.3185, 2.3445, 0.0000, 1.5990,\n",
            "        2.3871, 0.0000, 5.9026, 0.0000, 4.3328, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 7.8552, 0.0000, 7.1161], grad_fn=<ReluBackward0>)\n",
            "x fc_pi output tensor([ 54.5313, -34.8993,   4.4509, -37.2602], grad_fn=<AddBackward0>)\n",
            "x F.softmax(x, dim=softmax_dim) tensor([ 54.5313, -34.8993,   4.4509, -37.2602], grad_fn=<AddBackward0>)\n",
            "prob tensor([1.0000e+00, 1.4480e-39, 1.7797e-22, 1.3661e-40],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "step 데이터 : [8 4 5 0] -1 -1 False False\n",
            "put_data    : [9 4 5 0] 0 -1 [8 4 5 0] False\n",
            "tensor([8, 4, 5, 0])\n",
            "tensor([8., 4., 5., 0.])\n",
            "end input\n",
            "input x tensor([8., 4., 5., 0.])\n",
            "x F.relu output tensor([0.0000, 2.1605, 2.7700, 3.2118, 0.6960, 0.0000, 0.0000, 0.7436, 0.0000,\n",
            "        0.0000, 3.6262, 2.0187, 2.8061, 0.0000, 1.1588, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 4.2932, 0.0000, 0.0000, 4.0084, 5.4526, 4.0637, 5.6288, 1.6534,\n",
            "        4.3912, 0.0000, 5.0735, 0.0000, 2.3138, 1.5352, 1.5280, 3.7295, 3.0829,\n",
            "        2.3121, 4.0960, 4.8834, 0.0000, 1.2426, 3.9699, 0.0000, 0.0000, 4.8130,\n",
            "        1.6056, 0.0000, 4.4986, 0.0000, 0.0000, 0.8052, 0.0000, 5.9570, 3.0507,\n",
            "        0.0000, 0.0000, 3.9696, 0.0666, 4.7081, 0.0000, 5.3589, 1.6844, 4.0143,\n",
            "        2.7831, 1.7363, 1.2507, 0.0000, 0.9901, 0.0000, 0.0000, 0.0000, 2.1043,\n",
            "        0.0000, 0.0000, 1.5139, 0.0000, 1.7924, 0.0000, 3.3743, 0.2457, 5.5087,\n",
            "        2.6694, 0.0000, 5.1131, 0.0000, 4.9128, 0.8944, 6.3562, 0.0000, 0.0000,\n",
            "        0.0000, 2.2885, 0.0000, 4.8369, 0.0000, 4.6228, 0.0000, 0.5900, 3.4014,\n",
            "        0.0000, 0.0000, 4.4736, 0.0000, 5.5910, 3.2435, 0.0000, 0.3742, 0.0000,\n",
            "        2.6278, 5.1138, 0.0000, 0.0000, 0.0000, 2.0644, 4.5950, 5.5955, 0.0000,\n",
            "        0.0000, 0.0000, 2.7969, 0.0000, 3.5066, 0.0000, 5.4880, 3.5970, 0.0000,\n",
            "        0.0000, 0.1480, 4.8947, 4.2631, 0.0000, 2.3521, 2.7224, 0.0000, 0.0000,\n",
            "        0.0000, 2.9997, 1.8027, 3.3787, 1.3214, 0.0000, 0.0000, 3.8273, 0.0000,\n",
            "        1.2111, 2.3829, 0.0000, 6.8189, 3.7797, 1.2372, 0.0000, 7.7612, 0.0000,\n",
            "        4.7853, 0.0000, 0.0000, 0.0000, 4.6938, 2.0810, 4.4636, 0.0000, 2.1424,\n",
            "        0.0000, 4.1420, 3.3466, 0.2379, 3.7394, 0.0000, 4.3530, 0.0000, 0.0000,\n",
            "        0.0000, 4.7708, 0.0000, 0.0000, 3.5915, 6.6831, 0.0000, 6.2082, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 2.3361, 0.0000, 2.4586,\n",
            "        0.0000, 0.0000, 0.6880, 0.0000, 0.0000, 0.0000, 0.0139, 0.0000, 0.0000,\n",
            "        0.0000, 2.1834, 3.7502, 2.9861, 0.0000, 3.0244, 5.1825, 4.0734, 0.0000,\n",
            "        4.4986, 0.0000, 2.7736, 0.0000, 0.0000, 0.0000, 1.4226, 0.0000, 2.9967,\n",
            "        0.0000, 3.3988, 0.1159, 0.4300, 0.6697, 0.0000, 2.4145, 0.0000, 0.0000,\n",
            "        5.1951, 7.1022, 2.9552, 4.8013, 2.0937, 3.8465, 4.7946, 5.3599, 0.0000,\n",
            "        1.2407, 1.5946, 0.0000, 5.7218, 0.0000, 8.7825, 2.1780, 0.0000, 1.2753,\n",
            "        2.1740, 0.0000, 5.7608, 0.0000, 3.9129, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 7.6386, 0.0000, 6.6305], grad_fn=<ReluBackward0>)\n",
            "x fc_pi output tensor([ 50.3291, -32.3518,   4.5725, -35.0014], grad_fn=<AddBackward0>)\n",
            "x F.softmax(x, dim=softmax_dim) tensor([ 50.3291, -32.3518,   4.5725, -35.0014], grad_fn=<AddBackward0>)\n",
            "prob tensor([1.0000e+00, 1.2364e-36, 1.3434e-20, 8.7391e-38],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "step 데이터 : [7 4 5 0] -1 -2 False False\n",
            "put_data    : [8 4 5 0] 0 -1 [7 4 5 0] False\n",
            "step 데이터 : [7 5 5 0] -1 -3 False False\n",
            "put_data    : [7 4 5 0] 3 -1 [7 5 5 0] False\n",
            "tensor([7, 5, 5, 0])\n",
            "tensor([7., 5., 5., 0.])\n",
            "end input\n",
            "input x tensor([7., 5., 5., 0.])\n",
            "x F.relu output tensor([0.0000, 2.1074, 2.8953, 2.2510, 1.4703, 0.0000, 0.0000, 0.8109, 0.0000,\n",
            "        0.0000, 2.8047, 1.9725, 3.2190, 0.0000, 1.5071, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 4.5084, 0.0000, 0.0000, 3.8597, 4.8195, 4.0102, 5.4711, 0.7453,\n",
            "        3.9966, 0.0000, 4.5008, 0.0000, 2.4676, 1.5227, 1.4987, 4.1244, 3.2292,\n",
            "        1.6807, 3.6372, 4.6341, 0.0000, 1.6940, 3.4632, 0.0000, 0.0000, 5.0345,\n",
            "        1.6945, 0.0000, 4.2513, 0.0000, 0.0000, 1.0327, 0.0000, 5.8940, 2.9311,\n",
            "        0.0000, 0.0000, 3.7716, 0.0000, 4.9810, 0.0000, 5.4594, 2.2255, 3.4394,\n",
            "        2.9083, 1.2172, 1.0673, 0.0000, 1.4180, 0.0000, 0.0000, 0.0000, 1.8833,\n",
            "        0.0000, 0.0000, 1.5627, 0.0000, 2.3773, 0.0000, 3.0949, 0.1150, 5.7174,\n",
            "        2.9597, 0.0000, 4.6582, 0.0000, 4.4668, 1.3218, 6.3492, 0.0000, 0.0000,\n",
            "        0.0000, 1.8710, 0.0000, 4.8833, 0.0000, 4.0142, 0.0000, 0.1045, 2.8508,\n",
            "        0.0000, 0.0000, 4.3293, 0.1031, 5.4320, 3.5851, 0.0000, 0.5183, 0.0000,\n",
            "        3.0456, 5.3613, 0.0000, 0.0000, 0.0000, 2.1900, 5.0888, 5.8885, 0.0000,\n",
            "        0.0000, 0.0000, 3.2119, 0.0000, 3.8416, 0.0000, 5.6757, 3.5911, 0.0000,\n",
            "        0.0000, 0.7137, 4.9378, 4.4021, 0.0000, 2.5355, 2.6830, 0.0000, 0.0000,\n",
            "        0.0000, 2.5753, 1.3338, 3.5376, 0.6645, 0.0000, 0.0000, 4.1259, 0.0000,\n",
            "        1.5006, 1.8813, 0.0000, 6.7877, 3.9150, 0.8158, 0.0000, 7.8928, 0.3553,\n",
            "        4.2141, 0.0000, 0.0000, 0.0000, 4.7772, 2.4783, 4.3561, 0.0000, 1.5652,\n",
            "        0.0000, 3.7662, 4.0240, 0.3555, 4.0622, 0.2110, 4.5119, 0.0000, 0.0000,\n",
            "        0.0000, 5.0805, 0.0000, 0.0000, 3.7345, 6.6560, 0.0000, 5.8681, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 2.2484, 0.0000, 2.5411,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 1.7914, 3.2628, 3.1724, 0.0000, 3.1773, 5.2127, 4.3941, 0.0000,\n",
            "        4.0798, 0.0000, 2.7610, 0.0000, 0.0000, 0.0000, 1.8312, 0.0000, 3.1410,\n",
            "        0.0000, 3.7144, 0.2369, 0.9387, 0.8665, 0.0000, 2.3834, 0.0000, 0.0000,\n",
            "        4.4910, 6.9706, 2.9228, 4.1019, 1.5476, 3.9231, 4.3500, 5.4789, 0.0000,\n",
            "        1.1426, 1.9144, 0.0000, 5.8313, 0.0000, 8.5636, 2.1481, 0.0000, 0.8544,\n",
            "        1.8315, 0.0000, 6.0676, 0.0000, 3.2140, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 7.9788, 0.0000, 6.6671], grad_fn=<ReluBackward0>)\n",
            "x fc_pi output tensor([ 49.0560, -31.7167,   5.0861, -34.5663], grad_fn=<AddBackward0>)\n",
            "x F.softmax(x, dim=softmax_dim) tensor([ 49.0560, -31.7167,   5.0861, -34.5663], grad_fn=<AddBackward0>)\n",
            "prob tensor([1.0000e+00, 8.3341e-36, 8.0192e-20, 4.8228e-37],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "step 데이터 : [6 5 5 0] -1 -4 False False\n",
            "put_data    : [7 5 5 0] 0 -1 [6 5 5 0] False\n",
            "step 데이터 : [6 6 5 0] -100 -104 True False\n",
            "put_data    : [6 5 5 0] 3 -100 [6 6 5 0] True\n",
            "input x tensor([[9., 4., 5., 0.],\n",
            "        [8., 4., 5., 0.],\n",
            "        [7., 4., 5., 0.],\n",
            "        [7., 5., 5., 0.],\n",
            "        [6., 5., 5., 0.]])\n",
            "x F.relu output tensor([[0.0000, 2.5212, 3.1114,  ..., 7.8552, 0.0000, 7.1161],\n",
            "        [0.0000, 2.1605, 2.7700,  ..., 7.6386, 0.0000, 6.6305],\n",
            "        [0.0000, 1.7998, 2.4286,  ..., 7.4220, 0.0000, 6.1450],\n",
            "        [0.0000, 2.1074, 2.8953,  ..., 7.9788, 0.0000, 6.6671],\n",
            "        [0.0000, 1.7467, 2.5538,  ..., 7.7622, 0.0000, 6.1815]],\n",
            "       grad_fn=<ReluBackward0>)\n",
            "x fc_pi output tensor([[ 54.5313, -34.8993,   4.4509, -37.2602],\n",
            "        [ 50.3291, -32.3518,   4.5725, -35.0014],\n",
            "        [ 46.1451, -29.8212,   4.6976, -32.7510],\n",
            "        [ 49.0560, -31.7167,   5.0861, -34.5663],\n",
            "        [ 44.9724, -29.2777,   5.2429, -32.3272]], grad_fn=<AddmmBackward0>)\n",
            "x F.softmax(x, dim=softmax_dim) tensor([[ 54.5313, -34.8993,   4.4509, -37.2602],\n",
            "        [ 50.3291, -32.3518,   4.5725, -35.0014],\n",
            "        [ 46.1451, -29.8212,   4.6976, -32.7510],\n",
            "        [ 49.0560, -31.7167,   5.0861, -34.5663],\n",
            "        [ 44.9724, -29.2777,   5.2429, -32.3272]], grad_fn=<AddmmBackward0>)\n",
            "prob tensor([[1.0000e+00, 1.4480e-39, 1.7797e-22, 1.3661e-40],\n",
            "        [1.0000e+00, 1.2364e-36, 1.3434e-20, 8.7390e-38],\n",
            "        [1.0000e+00, 1.0192e-33, 9.9899e-19, 5.4431e-35],\n",
            "        [1.0000e+00, 8.3341e-36, 8.0192e-20, 4.8228e-37],\n",
            "        [1.0000e+00, 5.6702e-33, 5.5681e-18, 2.6867e-34]],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "\n",
            "\n",
            "▶▶▶ 3830  : max cum reward :  1887  epsilon = 0.6169900000000422\n",
            "\n",
            "\n",
            "▶▶▶3831번째 에피소드 시작, env 초기화 완료.\n",
            "가져와야 할 아이템 : ['G', 'H', 'I', 'J', 'N', 'O', 'P']\n",
            "\n",
            "현재 state         :  [9 4 0 2]\n",
            "step 데이터 : [10  4  0  2] -100 -100 True False\n",
            "put_data    : [9 4 0 2] 1 -100 [10  4  0  2] True\n",
            "input x tensor([[9., 4., 0., 2.]])\n",
            "x F.relu output tensor([[0.0000, 3.7417, 4.6089, 5.1243, 0.0000, 0.0000, 0.0000, 2.6530, 0.0000,\n",
            "         0.0000, 4.4347, 4.3382, 2.2922, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.5748, 4.1628, 0.0000, 0.0000, 2.5727, 6.0007, 3.0029, 3.3859, 4.4156,\n",
            "         5.8707, 0.0000, 3.2872, 0.0000, 2.8650, 2.0468, 5.0133, 3.6279, 2.6372,\n",
            "         4.8079, 1.5365, 5.3514, 0.0000, 0.0000, 2.6369, 0.0000, 0.0000, 3.0855,\n",
            "         2.2140, 0.0000, 2.3054, 0.0000, 0.0000, 3.5375, 0.0000, 3.4639, 4.2961,\n",
            "         0.0000, 0.0000, 3.5220, 0.0000, 2.5140, 0.0000, 6.4183, 0.0000, 1.7839,\n",
            "         1.9462, 2.8408, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 4.1048,\n",
            "         0.0000, 0.9687, 1.9394, 0.0000, 1.5116, 0.0000, 5.3022, 0.0000, 3.4900,\n",
            "         0.5660, 0.0000, 4.3527, 0.0000, 2.8464, 0.0000, 6.5021, 0.0000, 0.0000,\n",
            "         0.0000, 4.3489, 0.0000, 6.9620, 0.8367, 2.9670, 1.1000, 0.7418, 3.4472,\n",
            "         0.0000, 1.1377, 5.6287, 0.1462, 5.9196, 3.8886, 0.0000, 2.1866, 0.0000,\n",
            "         0.4558, 5.1145, 0.0000, 1.8798, 0.0000, 3.4705, 2.7174, 4.4299, 0.0000,\n",
            "         0.0000, 0.0000, 3.4784, 0.0000, 1.3636, 0.0000, 2.4520, 1.0878, 0.0000,\n",
            "         0.0000, 0.0000, 5.9851, 5.8532, 0.0931, 1.2685, 2.6548, 0.0000, 0.0000,\n",
            "         0.0000, 3.1950, 1.8117, 3.4201, 1.3880, 0.0000, 0.0000, 3.4425, 0.0000,\n",
            "         1.3567, 2.4659, 0.0000, 6.0990, 2.7958, 1.2699, 0.0000, 5.0752, 0.3896,\n",
            "         5.6502, 0.0000, 0.0000, 0.0000, 3.7635, 1.6992, 7.8224, 0.0000, 2.8964,\n",
            "         0.0000, 4.0739, 1.5473, 0.0000, 2.9706, 0.0000, 5.7714, 0.0000, 1.9723,\n",
            "         0.0000, 4.2627, 0.1498, 0.0000, 4.7863, 6.2006, 0.0000, 5.6698, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.4017, 0.0000, 3.0772,\n",
            "         0.0000, 0.0000, 2.3194, 0.0000, 0.0000, 1.0978, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 4.2094, 2.9197, 3.5600, 0.0000, 2.7788, 6.8857, 0.6207, 1.5148,\n",
            "         2.6459, 0.0000, 0.5257, 0.0000, 0.0000, 2.1387, 0.2328, 0.0000, 2.0566,\n",
            "         0.0000, 2.0968, 0.0000, 1.8500, 3.5254, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         4.7822, 4.7646, 4.3470, 4.1784, 2.1893, 6.1813, 2.7287, 4.7433, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 3.8102, 0.0000, 5.9450, 1.2629, 0.0000, 3.2331,\n",
            "         1.4856, 0.8932, 3.8054, 0.0000, 2.0349, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 5.1308, 0.0000, 7.3730]], grad_fn=<ReluBackward0>)\n",
            "x fc_pi output tensor([[ 50.6837, -31.2711,   0.6083, -28.5903]], grad_fn=<AddmmBackward0>)\n",
            "x F.softmax(x, dim=softmax_dim) tensor([[ 50.6837, -31.2711,   0.6083, -28.5903]], grad_fn=<AddmmBackward0>)\n",
            "prob tensor([[1.0000e+00, 2.5556e-36, 1.7887e-22, 3.7303e-35]],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "\n",
            "\n",
            "▶▶▶ 3831  : max cum reward :  1887  epsilon = 0.6168900000000422\n",
            "\n",
            "\n",
            "▶▶▶3832번째 에피소드 시작, env 초기화 완료.\n",
            "가져와야 할 아이템 : ['A', 'C', 'D', 'I', 'J', 'L', 'M']\n",
            "\n",
            "현재 state         :  [9 4 5 0]\n",
            "tensor([9, 4, 5, 0])\n",
            "tensor([9., 4., 5., 0.])\n",
            "end input\n",
            "input x tensor([9., 4., 5., 0.])\n",
            "x F.relu output tensor([0.0000, 2.5224, 3.1124, 3.8422, 0.3829, 0.0000, 0.0000, 0.8724, 0.0000,\n",
            "        0.0000, 4.1848, 2.3674, 2.9119, 0.0000, 0.9187, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 4.5318, 0.0000, 0.0000, 4.2733, 6.0853, 4.2664, 5.9472, 2.2056,\n",
            "        4.9339, 0.0000, 5.4217, 0.0000, 2.5849, 1.6198, 1.8115, 3.9027, 3.1702,\n",
            "        2.9004, 4.3808, 5.3378, 0.0000, 1.0793, 4.3671, 0.0000, 0.0000, 5.0813,\n",
            "        1.6717, 0.0000, 4.8401, 0.0000, 0.0000, 0.9279, 0.0000, 6.2919, 3.5070,\n",
            "        0.0000, 0.0000, 4.2423, 0.1181, 4.8826, 0.0000, 5.7381, 1.3834, 4.3603,\n",
            "        2.9037, 2.1151, 1.2266, 0.0000, 0.7784, 0.0000, 0.0000, 0.0000, 2.4724,\n",
            "        0.0000, 0.0333, 1.6117, 0.0000, 1.7990, 0.0000, 3.8610, 0.2658, 5.7020,\n",
            "        2.6000, 0.0000, 5.6447, 0.0000, 5.3065, 0.7279, 6.8461, 0.0000, 0.0000,\n",
            "        0.0000, 2.7271, 0.0000, 5.2708, 0.0000, 5.0651, 0.0000, 0.8106, 3.7795,\n",
            "        0.0000, 0.0000, 5.0072, 0.0000, 6.0275, 3.4382, 0.0000, 0.4885, 0.0000,\n",
            "        2.5210, 5.3448, 0.0000, 0.0000, 0.0000, 2.2794, 4.6002, 5.7635, 0.0000,\n",
            "        0.0000, 0.0000, 2.8599, 0.0000, 3.4702, 0.0000, 5.6222, 3.6470, 0.0000,\n",
            "        0.0000, 0.0000, 5.2525, 4.6867, 0.0000, 2.4636, 2.9464, 0.0000, 0.0000,\n",
            "        0.0000, 3.3843, 2.1366, 3.6711, 1.5296, 0.0000, 0.0000, 3.9207, 0.0000,\n",
            "        1.2133, 2.7509, 0.0000, 7.3182, 3.9431, 1.5370, 0.0000, 8.0903, 0.0000,\n",
            "        5.3483, 0.0000, 0.0000, 0.0000, 5.0378, 2.0762, 5.0426, 0.0000, 2.5605,\n",
            "        0.0000, 4.4992, 3.2383, 0.0423, 3.8190, 0.0000, 4.7541, 0.0000, 0.0897,\n",
            "        0.0000, 4.9891, 0.0000, 0.0000, 3.8966, 7.1451, 0.0000, 6.7312, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 2.4639, 0.0000, 2.6853,\n",
            "        0.0000, 0.0000, 1.1420, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 2.5823, 4.0945, 3.2738, 0.0000, 3.2483, 5.6286, 4.0874, 0.0000,\n",
            "        4.7483, 0.0000, 2.7640, 0.0000, 0.0000, 0.0000, 1.3217, 0.0000, 3.0915,\n",
            "        0.0000, 3.4695, 0.0000, 0.4169, 0.7959, 0.0000, 2.4116, 0.0000, 0.0000,\n",
            "        5.7526, 7.5372, 3.2530, 5.3679, 2.4756, 4.2896, 5.1964, 5.7533, 0.0000,\n",
            "        1.1595, 1.4318, 0.0000, 6.0003, 0.0000, 9.3200, 2.3457, 0.0000, 1.5998,\n",
            "        2.3885, 0.0000, 5.9042, 0.0000, 4.3340, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 7.8567, 0.0000, 7.1173], grad_fn=<ReluBackward0>)\n",
            "x fc_pi output tensor([ 54.5686, -34.9421,   4.4726, -37.2986], grad_fn=<AddBackward0>)\n",
            "x F.softmax(x, dim=softmax_dim) tensor([ 54.5686, -34.9421,   4.4726, -37.2986], grad_fn=<AddBackward0>)\n",
            "prob tensor([1.0000e+00, 1.3365e-39, 1.7521e-22, 1.2664e-40],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "step 데이터 : [8 4 5 0] -1 -1 False False\n",
            "put_data    : [9 4 5 0] 0 -1 [8 4 5 0] False\n",
            "step 데이터 : [8 5 5 0] -1 -2 False False\n",
            "put_data    : [8 4 5 0] 3 -1 [8 5 5 0] False\n",
            "tensor([8, 5, 5, 0])\n",
            "tensor([8., 5., 5., 0.])\n",
            "end input\n",
            "input x tensor([8., 5., 5., 0.])\n",
            "x F.relu output tensor([0.0000, 2.4693, 3.2376, 2.8813, 1.1572, 0.0000, 0.0000, 0.9396, 0.0000,\n",
            "        0.0000, 3.3633, 2.3212, 3.3248, 0.0000, 1.2670, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 4.7469, 0.0000, 0.0000, 4.1245, 5.4522, 4.2129, 5.7894, 1.2976,\n",
            "        4.5393, 0.0000, 4.8490, 0.0000, 2.7387, 1.6072, 1.7822, 4.2975, 3.3165,\n",
            "        2.2691, 3.9220, 5.0884, 0.0000, 1.5307, 3.8603, 0.0000, 0.0000, 5.3029,\n",
            "        1.7606, 0.0000, 4.5927, 0.0000, 0.0000, 1.1553, 0.0000, 6.2289, 3.3873,\n",
            "        0.0000, 0.0000, 4.0443, 0.0000, 5.1554, 0.0000, 5.8386, 1.9245, 3.7854,\n",
            "        3.0289, 1.5960, 1.0432, 0.0000, 1.2062, 0.0000, 0.0000, 0.0000, 2.2515,\n",
            "        0.0000, 0.0000, 1.6605, 0.0000, 2.3839, 0.0000, 3.5815, 0.1351, 5.9107,\n",
            "        2.8903, 0.0000, 5.1898, 0.0000, 4.8605, 1.1553, 6.8391, 0.0000, 0.0000,\n",
            "        0.0000, 2.3096, 0.0000, 5.3172, 0.0000, 4.4564, 0.0000, 0.3250, 3.2288,\n",
            "        0.0000, 0.0000, 4.8629, 0.1226, 5.8684, 3.7798, 0.0000, 0.6326, 0.0000,\n",
            "        2.9388, 5.5924, 0.0000, 0.0000, 0.0000, 2.4050, 5.0939, 6.0564, 0.0000,\n",
            "        0.0000, 0.0000, 3.2750, 0.0000, 3.8052, 0.0000, 5.8099, 3.6411, 0.0000,\n",
            "        0.0000, 0.3969, 5.2957, 4.8257, 0.0000, 2.6471, 2.9069, 0.0000, 0.0000,\n",
            "        0.0000, 2.9599, 1.6677, 3.8300, 0.8726, 0.0000, 0.0000, 4.2193, 0.0000,\n",
            "        1.5028, 2.2493, 0.0000, 7.2869, 4.0784, 1.1155, 0.0000, 8.2218, 0.2132,\n",
            "        4.7771, 0.0000, 0.0000, 0.0000, 5.1211, 2.4734, 4.9350, 0.0000, 1.9833,\n",
            "        0.0000, 4.1234, 3.9157, 0.1598, 4.1419, 0.0000, 4.9129, 0.0000, 0.1225,\n",
            "        0.0000, 5.2989, 0.0000, 0.0000, 4.0396, 7.1180, 0.0000, 6.3911, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 2.3761, 0.0000, 2.7679,\n",
            "        0.0000, 0.0000, 0.3048, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 2.1903, 3.6070, 3.4601, 0.0000, 3.4012, 5.6589, 4.4081, 0.0000,\n",
            "        4.3295, 0.0000, 2.7514, 0.0000, 0.0000, 0.0000, 1.7302, 0.0000, 3.2357,\n",
            "        0.0000, 3.7851, 0.0795, 0.9256, 0.9927, 0.0000, 2.3805, 0.0000, 0.0000,\n",
            "        5.0484, 7.4056, 3.2205, 4.6685, 1.9295, 4.3661, 4.7518, 5.8723, 0.0000,\n",
            "        1.0614, 1.7515, 0.0000, 6.1097, 0.0000, 9.1012, 2.3158, 0.0000, 1.1789,\n",
            "        2.0460, 0.0000, 6.2109, 0.0000, 3.6350, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 8.1969, 0.0000, 7.1538], grad_fn=<ReluBackward0>)\n",
            "x fc_pi output tensor([ 53.2655, -34.2594,   4.9809, -36.8483], grad_fn=<AddBackward0>)\n",
            "x F.softmax(x, dim=softmax_dim) tensor([ 53.2655, -34.2594,   4.9809, -36.8483], grad_fn=<AddBackward0>)\n",
            "prob tensor([1.0000e+00, 9.7367e-39, 1.0722e-21, 7.3130e-40],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "step 데이터 : [7 5 5 0] -1 -3 False False\n",
            "put_data    : [8 5 5 0] 0 -1 [7 5 5 0] False\n",
            "tensor([7, 5, 5, 0])\n",
            "tensor([7., 5., 5., 0.])\n",
            "end input\n",
            "input x tensor([7., 5., 5., 0.])\n",
            "x F.relu output tensor([0.0000, 2.1084, 2.8961, 2.2523, 1.4712, 0.0000, 0.0000, 0.8111, 0.0000,\n",
            "        0.0000, 2.8055, 1.9730, 3.2200, 0.0000, 1.5078, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 4.5092, 0.0000, 0.0000, 3.8610, 4.8204, 4.0108, 5.4721, 0.7468,\n",
            "        3.9976, 0.0000, 4.5022, 0.0000, 2.4683, 1.5232, 1.4988, 4.1250, 3.2302,\n",
            "        1.6818, 3.6384, 4.6352, 0.0000, 1.6955, 3.4646, 0.0000, 0.0000, 5.0351,\n",
            "        1.6958, 0.0000, 4.2519, 0.0000, 0.0000, 1.0327, 0.0000, 5.8948, 2.9318,\n",
            "        0.0000, 0.0000, 3.7723, 0.0000, 4.9822, 0.0000, 5.4606, 2.2261, 3.4402,\n",
            "        2.9091, 1.2181, 1.0665, 0.0000, 1.4173, 0.0000, 0.0000, 0.0000, 1.8843,\n",
            "        0.0000, 0.0000, 1.5633, 0.0000, 2.3787, 0.0000, 3.0958, 0.1174, 5.7182,\n",
            "        2.9613, 0.0000, 4.6588, 0.0000, 4.4679, 1.3243, 6.3498, 0.0000, 0.0000,\n",
            "        0.0000, 1.8723, 0.0000, 4.8840, 0.0000, 4.0153, 0.0000, 0.1050, 2.8516,\n",
            "        0.0000, 0.0000, 4.3302, 0.1043, 5.4334, 3.5859, 0.0000, 0.5186, 0.0000,\n",
            "        3.0467, 5.3626, 0.0000, 0.0000, 0.0000, 2.1905, 5.0897, 5.8892, 0.0000,\n",
            "        0.0000, 0.0000, 3.2127, 0.0000, 3.8427, 0.0000, 5.6770, 3.5920, 0.0000,\n",
            "        0.0000, 0.7145, 4.9387, 4.4035, 0.0000, 2.5362, 2.6840, 0.0000, 0.0000,\n",
            "        0.0000, 2.5762, 1.3349, 3.5389, 0.6657, 0.0000, 0.0000, 4.1272, 0.0000,\n",
            "        1.5013, 1.8823, 0.0000, 6.7887, 3.9159, 0.8168, 0.0000, 7.8940, 0.3571,\n",
            "        4.2149, 0.0000, 0.0000, 0.0000, 4.7783, 2.4791, 4.3568, 0.0000, 1.5663,\n",
            "        0.0000, 3.7674, 4.0251, 0.3565, 4.0633, 0.2109, 4.5130, 0.0000, 0.0000,\n",
            "        0.0000, 5.0813, 0.0000, 0.0000, 3.7353, 6.6566, 0.0000, 5.8688, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 2.2502, 0.0000, 2.5424,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 1.7920, 3.2635, 3.1732, 0.0000, 3.1789, 5.2135, 4.3957, 0.0000,\n",
            "        4.0811, 0.0000, 2.7622, 0.0000, 0.0000, 0.0000, 1.8325, 0.0000, 3.1423,\n",
            "        0.0000, 3.7154, 0.2377, 0.9398, 0.8668, 0.0000, 2.3846, 0.0000, 0.0000,\n",
            "        4.4918, 6.9718, 2.9238, 4.1030, 1.5490, 3.9240, 4.3512, 5.4804, 0.0000,\n",
            "        1.1420, 1.9129, 0.0000, 5.8319, 0.0000, 8.5650, 2.1492, 0.0000, 0.8552,\n",
            "        1.8328, 0.0000, 6.0690, 0.0000, 3.2150, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 7.9802, 0.0000, 6.6681], grad_fn=<ReluBackward0>)\n",
            "x fc_pi output tensor([ 49.0882, -31.7527,   5.1064, -34.6016], grad_fn=<AddBackward0>)\n",
            "x F.softmax(x, dim=softmax_dim) tensor([ 49.0882, -31.7527,   5.1064, -34.6016], grad_fn=<AddBackward0>)\n",
            "prob tensor([1.0000e+00, 7.7848e-36, 7.9242e-20, 4.5082e-37],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "step 데이터 : [6 5 5 0] -1 -4 False False\n",
            "put_data    : [7 5 5 0] 0 -1 [6 5 5 0] False\n",
            "tensor([6, 5, 5, 0])\n",
            "tensor([6., 5., 5., 0.])\n",
            "end input\n",
            "input x tensor([6., 5., 5., 0.])\n",
            "x F.relu output tensor([0.0000, 1.7476, 2.5546, 1.6232, 1.7852, 0.0000, 0.0000, 0.6827, 0.0000,\n",
            "        0.0000, 2.2477, 1.6247, 3.1151, 0.0000, 1.7486, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 4.2715, 0.0000, 0.0000, 3.5975, 4.1886, 3.8087, 5.1547, 0.1960,\n",
            "        3.4559, 0.0000, 4.1554, 0.0000, 2.1979, 1.4392, 1.2154, 3.9526, 3.1440,\n",
            "        1.0945, 3.3548, 4.1820, 0.0000, 1.8603, 3.0689, 0.0000, 0.0000, 4.7673,\n",
            "        1.6311, 0.0000, 3.9110, 0.0000, 0.0000, 0.9101, 0.0000, 5.5608, 2.4763,\n",
            "        0.0000, 0.0000, 3.5003, 0.0000, 4.8089, 0.0000, 5.0826, 2.5277, 3.0951,\n",
            "        2.7894, 0.8402, 1.0898, 0.0000, 1.6284, 0.0000, 0.0000, 0.0000, 1.5172,\n",
            "        0.0000, 0.0000, 1.4661, 0.0000, 2.3735, 0.0000, 2.6100, 0.0997, 5.5256,\n",
            "        3.0324, 0.0000, 4.1278, 0.4355, 4.0753, 1.4932, 5.8605, 0.0000, 0.0000,\n",
            "        0.0000, 1.4350, 0.0000, 4.4509, 0.0000, 3.5741, 0.0000, 0.0000, 2.4744,\n",
            "        0.0000, 0.0000, 3.7975, 0.0861, 4.9983, 3.3920, 0.0000, 0.4046, 0.0000,\n",
            "        3.1546, 5.1329, 0.0000, 0.0000, 0.0000, 1.9759, 5.0855, 5.7219, 0.0000,\n",
            "        0.0000, 0.0000, 3.1505, 0.0000, 3.8802, 0.0000, 5.5441, 3.5428, 0.0000,\n",
            "        0.0000, 1.0321, 4.5818, 3.9813, 0.0000, 2.4254, 2.4611, 0.0000, 0.0000,\n",
            "        0.0000, 2.1925, 1.0022, 3.2478, 0.4587, 0.0000, 0.0000, 4.0352, 0.1414,\n",
            "        1.4998, 1.5152, 0.0000, 6.2905, 3.7535, 0.5182, 0.0000, 7.5661, 0.5010,\n",
            "        3.6528, 0.0000, 0.0000, 0.0000, 4.4355, 2.4847, 3.7786, 0.0000, 1.1494,\n",
            "        0.0000, 3.4114, 4.1344, 0.5531, 3.9847, 0.5256, 4.1130, 0.0000, 0.0000,\n",
            "        0.0000, 4.8637, 0.0000, 0.0000, 3.4309, 6.1952, 0.0000, 5.3465, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 2.1243, 0.0000, 2.3169,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0207, 0.0000, 0.0000,\n",
            "        0.0000, 1.3937, 2.9200, 2.8864, 0.0000, 2.9566, 4.7681, 4.3834, 0.0000,\n",
            "        3.8327, 0.0000, 2.7730, 0.0000, 0.0000, 0.0000, 1.9347, 0.0000, 3.0489,\n",
            "        0.0000, 3.6456, 0.3959, 0.9540, 0.7408, 0.0000, 2.3888, 0.0000, 0.0000,\n",
            "        3.9351, 6.5380, 2.6271, 3.5375, 1.1685, 3.4818, 3.9505, 5.0886, 0.0000,\n",
            "        1.2227, 2.0743, 0.0000, 5.5541, 0.0000, 8.0288, 1.9825, 0.0000, 0.5315,\n",
            "        1.6196, 0.0000, 5.9271, 0.0000, 2.7949, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 7.7634, 0.0000, 6.1825], grad_fn=<ReluBackward0>)\n",
            "x fc_pi output tensor([ 45.0009, -29.3090,   5.2618, -32.3599], grad_fn=<AddBackward0>)\n",
            "x F.softmax(x, dim=softmax_dim) tensor([ 45.0009, -29.3090,   5.2618, -32.3599], grad_fn=<AddBackward0>)\n",
            "prob tensor([1.0000e+00, 5.3410e-33, 5.5149e-18, 2.5272e-34],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "step 데이터 : [5 5 5 0] -1 -5 False False\n",
            "put_data    : [6 5 5 0] 0 -1 [5 5 5 0] False\n",
            "step 데이터 : [5 4 5 0] -100 -105 True False\n",
            "put_data    : [5 5 5 0] 2 -100 [5 4 5 0] True\n",
            "input x tensor([[9., 4., 5., 0.],\n",
            "        [8., 4., 5., 0.],\n",
            "        [8., 5., 5., 0.],\n",
            "        [7., 5., 5., 0.],\n",
            "        [6., 5., 5., 0.],\n",
            "        [5., 5., 5., 0.]])\n",
            "x F.relu output tensor([[0.0000, 2.5224, 3.1124,  ..., 7.8567, 0.0000, 7.1173],\n",
            "        [0.0000, 2.1616, 2.7709,  ..., 7.6400, 0.0000, 6.6316],\n",
            "        [0.0000, 2.4693, 3.2376,  ..., 8.1969, 0.0000, 7.1538],\n",
            "        [0.0000, 2.1084, 2.8961,  ..., 7.9802, 0.0000, 6.6681],\n",
            "        [0.0000, 1.7476, 2.5546,  ..., 7.7634, 0.0000, 6.1825],\n",
            "        [0.0000, 1.3867, 2.2131,  ..., 7.5467, 0.0000, 5.6968]],\n",
            "       grad_fn=<ReluBackward0>)\n",
            "x fc_pi output tensor([[ 54.5687, -34.9421,   4.4726, -37.2986],\n",
            "        [ 50.3626, -32.3899,   4.5929, -35.0373],\n",
            "        [ 53.2655, -34.2594,   4.9809, -36.8483],\n",
            "        [ 49.0882, -31.7527,   5.1064, -34.6016],\n",
            "        [ 45.0009, -29.3090,   5.2618, -32.3599],\n",
            "        [ 40.9067, -26.8811,   5.4357, -30.1616]], grad_fn=<AddmmBackward0>)\n",
            "x F.softmax(x, dim=softmax_dim) tensor([[ 54.5687, -34.9421,   4.4726, -37.2986],\n",
            "        [ 50.3626, -32.3899,   4.5929, -35.0373],\n",
            "        [ 53.2655, -34.2594,   4.9809, -36.8483],\n",
            "        [ 49.0882, -31.7527,   5.1064, -34.6016],\n",
            "        [ 45.0009, -29.3090,   5.2618, -32.3599],\n",
            "        [ 40.9067, -26.8811,   5.4357, -30.1616]], grad_fn=<AddmmBackward0>)\n",
            "prob tensor([[1.0000e+00, 1.3365e-39, 1.7521e-22, 1.2664e-40],\n",
            "        [1.0000e+00, 1.1510e-36, 1.3258e-20, 8.1531e-38],\n",
            "        [1.0000e+00, 9.7367e-39, 1.0722e-21, 7.3130e-40],\n",
            "        [1.0000e+00, 7.7848e-36, 7.9242e-20, 4.5082e-37],\n",
            "        [1.0000e+00, 5.3409e-33, 5.5149e-18, 2.5272e-34],\n",
            "        [1.0000e+00, 3.6320e-30, 3.9370e-16, 1.3659e-31]],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "\n",
            "\n",
            "▶▶▶ 3832  : max cum reward :  1887  epsilon = 0.6167900000000422\n",
            "\n",
            "\n",
            "▶▶▶3833번째 에피소드 시작, env 초기화 완료.\n",
            "가져와야 할 아이템 : ['A', 'D', 'F', 'J', 'K', 'Q']\n",
            "\n",
            "현재 state         :  [9 4 5 0]\n",
            "step 데이터 : [9 5 5 0] -100 -100 True False\n",
            "put_data    : [9 4 5 0] 3 -100 [9 5 5 0] True\n",
            "input x tensor([[9., 4., 5., 0.]])\n",
            "x F.relu output tensor([[0.0000, 2.5237, 3.1134, 3.8433, 0.3831, 0.0000, 0.0000, 0.8732, 0.0000,\n",
            "         0.0000, 4.1858, 2.3682, 2.9129, 0.0000, 0.9189, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 4.5328, 0.0000, 0.0000, 4.2743, 6.0863, 4.2672, 5.9483, 2.2069,\n",
            "         4.9350, 0.0000, 5.4227, 0.0000, 2.5858, 1.6206, 1.8122, 3.9036, 3.1713,\n",
            "         2.9015, 4.3818, 5.3388, 0.0000, 1.0799, 4.3684, 0.0000, 0.0000, 5.0820,\n",
            "         1.6728, 0.0000, 4.8409, 0.0000, 0.0000, 0.9285, 0.0000, 6.2928, 3.5078,\n",
            "         0.0000, 0.0000, 4.2431, 0.1184, 4.8837, 0.0000, 5.7393, 1.3838, 4.3612,\n",
            "         2.9046, 2.1160, 1.2263, 0.0000, 0.7782, 0.0000, 0.0000, 0.0000, 2.4735,\n",
            "         0.0000, 0.0339, 1.6126, 0.0000, 1.8003, 0.0000, 3.8621, 0.2669, 5.7028,\n",
            "         2.6009, 0.0000, 5.6456, 0.0000, 5.3074, 0.7291, 6.8468, 0.0000, 0.0000,\n",
            "         0.0000, 2.7283, 0.0000, 5.2717, 0.0000, 5.0662, 0.0000, 0.8113, 3.7804,\n",
            "         0.0000, 0.0000, 5.0082, 0.0000, 6.0288, 3.4392, 0.0000, 0.4893, 0.0000,\n",
            "         2.5219, 5.3457, 0.0000, 0.0000, 0.0000, 2.2802, 4.6012, 5.7643, 0.0000,\n",
            "         0.0000, 0.0000, 2.8609, 0.0000, 3.4713, 0.0000, 5.6232, 3.6480, 0.0000,\n",
            "         0.0000, 0.0000, 5.2536, 4.6880, 0.0000, 2.4645, 2.9474, 0.0000, 0.0000,\n",
            "         0.0000, 3.3853, 2.1377, 3.6724, 1.5306, 0.0000, 0.0000, 3.9219, 0.0000,\n",
            "         1.2142, 2.7519, 0.0000, 7.3192, 3.9442, 1.5380, 0.0000, 8.0913, 0.0000,\n",
            "         5.3494, 0.0000, 0.0000, 0.0000, 5.0389, 2.0771, 5.0435, 0.0000, 2.5615,\n",
            "         0.0000, 4.5004, 3.2394, 0.0429, 3.8201, 0.0000, 4.7551, 0.0000, 0.0908,\n",
            "         0.0000, 4.9902, 0.0000, 0.0000, 3.8976, 7.1460, 0.0000, 6.7322, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 2.4651, 0.0000, 2.6866,\n",
            "         0.0000, 0.0000, 1.1430, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 2.5831, 4.0953, 3.2748, 0.0000, 3.2497, 5.6296, 4.0884, 0.0000,\n",
            "         4.7495, 0.0000, 2.7651, 0.0000, 0.0000, 0.0000, 1.3227, 0.0000, 3.0925,\n",
            "         0.0000, 3.4706, 0.0000, 0.4181, 0.7966, 0.0000, 2.4122, 0.0000, 0.0000,\n",
            "         5.7535, 7.5383, 3.2540, 5.3690, 2.4769, 4.2904, 5.1975, 5.7546, 0.0000,\n",
            "         1.1594, 1.4312, 0.0000, 6.0011, 0.0000, 9.3212, 2.3468, 0.0000, 1.6007,\n",
            "         2.3896, 0.0000, 5.9054, 0.0000, 4.3350, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 7.8580, 0.0000, 7.1184]], grad_fn=<ReluBackward0>)\n",
            "x fc_pi output tensor([[ 54.6061, -34.9812,   4.4783, -37.3231]], grad_fn=<AddmmBackward0>)\n",
            "x F.softmax(x, dim=softmax_dim) tensor([[ 54.6061, -34.9812,   4.4783, -37.3231]], grad_fn=<AddmmBackward0>)\n",
            "prob tensor([[1.0000e+00, 1.2379e-39, 1.6973e-22, 1.1902e-40]],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "\n",
            "\n",
            "▶▶▶ 3833  : max cum reward :  1887  epsilon = 0.6166900000000423\n",
            "\n",
            "\n",
            "▶▶▶3834번째 에피소드 시작, env 초기화 완료.\n",
            "가져와야 할 아이템 : ['A', 'C', 'E', 'I', 'J']\n",
            "\n",
            "현재 state         :  [9 4 5 0]\n",
            "tensor([9, 4, 5, 0])\n",
            "tensor([9., 4., 5., 0.])\n",
            "end input\n",
            "input x tensor([9., 4., 5., 0.])\n",
            "x F.relu output tensor([0., nan, nan, nan, nan, 0., 0., nan, 0., 0., nan, nan, nan, 0., nan, 0., 0., 0., 0., nan, 0., 0., nan, nan,\n",
            "        nan, nan, nan, nan, 0., nan, 0., nan, nan, nan, nan, nan, nan, nan, nan, 0., nan, nan, 0., 0., nan, nan, 0., nan,\n",
            "        0., 0., nan, 0., nan, nan, 0., 0., nan, nan, nan, 0., nan, nan, nan, nan, nan, nan, 0., nan, 0., 0., 0., nan,\n",
            "        0., nan, nan, 0., nan, 0., nan, nan, nan, nan, 0., nan, 0., nan, nan, nan, 0., 0., 0., nan, 0., nan, 0., nan,\n",
            "        0., nan, nan, 0., 0., nan, 0., nan, nan, 0., nan, 0., nan, nan, 0., 0., 0., nan, nan, nan, 0., 0., 0., nan,\n",
            "        0., nan, 0., nan, nan, 0., 0., 0., nan, nan, 0., nan, nan, 0., 0., 0., nan, nan, nan, nan, 0., 0., nan, 0.,\n",
            "        nan, nan, 0., nan, nan, nan, 0., nan, 0., nan, 0., 0., 0., nan, nan, nan, 0., nan, 0., nan, nan, nan, nan, 0.,\n",
            "        nan, 0., nan, 0., nan, 0., 0., nan, nan, 0., nan, 0., 0., 0., 0., 0., 0., 0., nan, 0., nan, 0., 0., nan,\n",
            "        0., 0., 0., 0., 0., 0., 0., nan, nan, nan, 0., nan, nan, nan, 0., nan, 0., nan, 0., 0., 0., nan, 0., nan,\n",
            "        0., nan, 0., nan, nan, 0., nan, 0., 0., nan, nan, nan, nan, nan, nan, nan, nan, 0., nan, nan, 0., nan, 0., nan,\n",
            "        nan, 0., nan, nan, 0., nan, 0., nan, 0., 0., 0., 0., 0., nan, 0., nan],\n",
            "       grad_fn=<ReluBackward0>)\n",
            "x fc_pi output tensor([nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
            "x F.softmax(x, dim=softmax_dim) tensor([nan, nan, nan, nan], grad_fn=<AddBackward0>)\n",
            "prob tensor([nan, nan, nan, nan], grad_fn=<SoftmaxBackward0>)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/content/drive/MyDrive/agileSoda/\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     44\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'end input'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m                 \u001b[0mprob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m                 \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCategorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m                 \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/distributions/categorical.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, probs, logits, validate_args)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_events\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_param\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mbatch_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_param\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_param\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndimension\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCategorical\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_args\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_instance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/distributions/distribution.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch_shape, event_shape, validate_args)\u001b[0m\n\u001b[1;32m     54\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mvalid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m                     raise ValueError(\n\u001b[0;32m---> 56\u001b[0;31m                         \u001b[0;34mf\"Expected parameter {param} \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m                         \u001b[0;34mf\"({type(value).__name__} of shape {tuple(value.shape)}) \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m                         \u001b[0;34mf\"of distribution {repr(self)} \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Expected parameter probs (Tensor of shape (4,)) of distribution Categorical(probs: torch.Size([4])) to satisfy the constraint Simplex(), but found invalid values:\ntensor([nan, nan, nan, nan], grad_fn=<DivBackward0>)"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "\n",
        "n_rollout=10\n",
        "\n",
        "# main\n",
        "# if __name__ == \"__main__\":\n",
        "\n",
        "files = pd.read_csv('./data/factory_order_train.csv')\n",
        "episodes = len(files)\n",
        "\n",
        "sim = Simulator()\n",
        "model = TD_ActorCritic()\n",
        "\n",
        "max_cum_reward = -99999\n",
        "\n",
        "########################################################\n",
        "# 액션 저장하는 txt파일 만들기\n",
        "actions_file_name='epsilon_tdac'+str(move_reward)+'_'+str(obs_reward)+'_'+str(goal_reward)+'.txt'\n",
        "f = open(actions_file_name, 'w')\n",
        "########################################################\n",
        "\n",
        "for epi in range(episodes):\n",
        "    sim.reset(epi)\n",
        "    state = sim.get_current_state()\n",
        "    print('\\n\\n▶▶▶{}번째 에피소드 시작, env 초기화 완료.'.format(epi))\n",
        "\n",
        "    # 아이템 리스트 확인\n",
        "    items = list(files.iloc[epi])[0]\n",
        "    print('가져와야 할 아이템 : ' + list(files.iloc[epi])[0] + '\\n')\n",
        "    print('현재 state         : ', str(state))\n",
        "    \n",
        "    done = False\n",
        "\n",
        "    while done == False:\n",
        "        for t in range(n_rollout):\n",
        "            coin = random.random()\n",
        "            if coin <= epsilon:\n",
        "                action = random.randint(0,3)\n",
        "                # action = 2\n",
        "            else :\n",
        "                print(torch.from_numpy(state))\n",
        "                print(torch.from_numpy(state).float())\n",
        "                print('end input')\n",
        "                prob = model.pi(torch.from_numpy(state).float())\n",
        "                m = Categorical(prob)\n",
        "                action = m.sample().item()\n",
        "\n",
        "            state_prime, reward, cumul ,done, goal_ob_reward = sim.step(action)\n",
        "            print('step 데이터 :', state_prime, reward, cumul ,done, goal_ob_reward)\n",
        "            # s_prime, r, done, info = env.step(a) # 그 action을 env로 보내서 다음 s, a, r 추출\n",
        "            model.put_data((state, action, reward, state_prime, done)) # s, a, r, s' 데이터 수집\n",
        "            print('put_data    :',state, action, reward, state_prime, done)\n",
        "\n",
        "            state = state_prime\n",
        "\n",
        "            if done:\n",
        "                break\n",
        "        model.train_net()\n",
        "        print('\\n\\n▶▶▶', epi, ' : max cum reward : ', max_cum_reward, ' epsilon =', epsilon )\n",
        "    epsilon = update_epsilon(epsilon)\n",
        "    max_cum_reward = max_cum_reward if max_cum_reward > cumul else cumul\n",
        "\n",
        "    #########################################    \n",
        "    if len(sim.actions) > 10:\n",
        "        f.write(str(epi)+'/'+str(items)+'/'+str(cumul)+'\\n')\n",
        "        f.write(str(sim.actions))\n",
        "        f.write('\\n')\n",
        "\n",
        "f.close()\n",
        "#########################################\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "4iyLj4LeLkrY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}